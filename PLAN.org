* DONE [#A] Unified event architecture with generic event bus
  Goal: Refactor disparate event systems (EventHub, Broadcaster, LogHub) into a single reusable generic event bus, then extend event-driven patterns throughout Gestalt for agent lifecycle, config changes, terminal events, and workflow state.
  Notes:
  - Current state: 3 separate event implementations (watcher/EventHub, terminal/Broadcaster, logging/LogHub)
  - Pattern overlap: all implement subscribe/publish/fan-out, but with different APIs
  - New approach: single generic event.Bus[T] with type safety (Go 1.18+ generics)
  - Benefits: DRY, consistent patterns, easier testing, better observability
  - Core events to support: filesystem, terminal I/O, agent lifecycle, config changes, workflow state, logs
  - Event bus features: typed events, filtering, async delivery, backpressure handling, metrics
  - Migration strategy: create new package, migrate existing systems, add new event sources
  - Backward compatibility: maintain existing APIs during migration, deprecate gradually
  - Architecture: event.Bus[T] is core, specialized buses (TerminalBus, AgentBus) wrap it
  - Testing: event bus must be mockable, events must be deterministic for tests
  Sequencing recommendation: DO THIS BEFORE CONFIG REFACTOR
  - Rationale: Config refactor will need events (config changes, extraction progress, conflicts)
  - If event system exists first, config refactor naturally emits events
  - Otherwise, config refactor reinvents event patterns or uses inconsistent approach
  - Event system is foundational; config is a consumer of events
  Key architectural decisions (LOCKED IN):
  - Bus[T] is concrete struct (not interface) for simplicity and generic compatibility
  - Bus is passive (no goroutines): callers own threading, Publish is synchronous fanout
  - Bus integrates with metrics.Registry for observability (OpenTelemetry-ready)
  - Terminal I/O uses Bus for code reuse but is semantically a stream (not discrete events)
  - Logs NEVER drop (BlockOnFull=true), events can drop (BlockOnFull=false)
  - Storage (LogBuffer, OutputBuffer) stays separate from Bus (fanout only)
  - Frontend/backend ship together: no event versioning, use contract tests instead
  - Breaking changes OK (pre-production), but frontend must never break
  Date: 2026-01-11

** [#A] Design unified event bus architecture
   Why: Need clear architecture before implementation to avoid over-engineering or under-designing
   Change:
   - Design event.Bus[T any] generic interface
   - Core operations: Subscribe, Unsubscribe, Publish, Close
   - Subscribe returns: (<-chan T, func()) for receive channel + cancel function
   - Publish is non-blocking: drops events if all subscribers are slow (configurable)
   - Thread-safety: concurrent Subscribe/Publish/Unsubscribe safe
   - Event interface: all events implement Type() string, Timestamp() time.Time
   - Consider: filtered subscriptions (subscribe to event types), event history (last N events)
   - Consider: synchronous vs asynchronous publish (default async for non-blocking)
   - Consider: subscriber priorities (critical subscribers never drop events)
   - Design metrics: events published, dropped, active subscribers per event type
   - Design error handling: what happens on channel send failure, subscriber panic
   - Decide on buffering: per-subscriber buffer size (default 128), configurable
   - Document: when to use event bus vs direct function calls (events = decoupling, async, fanout)
   Tests: None (design only)
   Done when: Architecture documented with interfaces, patterns, and usage guidelines

** [#B] Create internal/event package with generic Bus implementation
   Why: Core reusable event bus that all systems can use
   Change:
   - Create internal/event/bus.go with concrete Bus[T any] struct (NOT interface)
   - Implement Subscribe() (<-chan T, func()) with unique subscription IDs
   - Implement Publish(event T) with synchronous fan-out (passive, no goroutines)
   - Publish iterates subscribers, does non-blocking send (default) or blocking send (if BlockOnFull)
   - Implement Close() to shut down bus and close all subscriber channels
   - Use sync.Mutex for thread-safe subscriber map
   - Use buffered channels per subscriber (default 128, configurable)
   - BusOptions.BlockOnFull: false (drop) for events/logs, true (block with timeout) for terminal I/O
   - Context-aware: accept optional context for cancellation, close on context.Done()
   - Add NewBus[T](ctx context.Context, opts BusOptions) *Bus[T] constructor
   - BusOptions: SubscriberBufferSize, BlockOnFull, WriteTimeout (if blocking), MaxSubscribers
   - Integrate with metrics.Registry: report published, dropped, subscriber counts
   - Handle edge cases: nil event, closed bus, subscriber cleanup on cancel
   - Document: Bus is passive (no goroutines), callers own threading model
   Tests: Unit tests for concurrent subscribe/publish, slow subscribers, metrics, drop vs block modes
   Done when: Generic Bus[T] works, fully tested, metrics integrated, ready to use

** [#B] Create typed event interfaces and base types
   Why: Establish event type conventions before migrating systems
   Change:
   - Create internal/event/types.go with Event interface
   - Event interface: Type() string, Timestamp() time.Time
   - Create base event types for common patterns:
     - FileEvent: path, operation, timestamp
     - TerminalEvent: terminal_id, event_type (created/closed/resized), data
     - AgentEvent: agent_id, agent_name, event_type (started/stopped/error), context
     - ConfigEvent: config_type (agent/skill/prompt), path, change_type (added/modified/removed)
     - WorkflowEvent: workflow_id, session_id, event_type (paused/resumed/completed)
     - LogEvent: level, message, context (wraps LogEntry)
   - Each type implements Event interface
   - Add helper constructors: NewFileEvent(path, op), NewTerminalEvent(id, type), etc
   - Use time.Now().UTC() for all timestamps (consistency)
   - Events are immutable: all fields read-only after construction
   - Document event type naming: lowercase, underscore-separated (terminal_created, agent_started)
   Tests: Unit tests for event construction, interface satisfaction
   Done when: Event types defined, tested, documented

** [#B] Add filtered subscription support
   Why: Subscribers often care about specific event types, not all events
   Change:
   - Extend Bus[T] to support filtered subscriptions
   - Add SubscribeFiltered(filter func(T) bool) (<-chan T, func())
   - Filter evaluated on each Publish before sending to subscriber
   - If filter returns false, event is not sent (no buffer usage)
   - Optimize: if no filter, skip filter check (direct send)
   - For Event interface types, add convenience: SubscribeType(eventType string)
   - SubscribeType creates filter: event.Type() == eventType
   - Consider: multiple type subscription SubscribeTypes(types ...string)
   - Update metrics to track filtered vs unfiltered subscriptions
   Tests: Unit tests for filtered subscriptions, type-based filtering
   Done when: Filtered subscriptions work, type-based helpers available

** [#B] Migrate watcher EventHub to generic event bus
   Why: Validate event bus design with real-world usage, remove duplicate code
   Change:
   - Replace internal/watcher/hub.go EventHub with event.Bus[Event]
   - EventHub.Subscribe(eventType, callback) → bus.SubscribeType(eventType, callback)
   - EventHub.Publish(event) → bus.Publish(event)
   - Keep WatchFile/UnwatchFile methods (higher-level abstractions)
   - Update event type constants: keep existing names for compatibility
   - Migrate tests: update to use new Bus API
   - Verify /ws/events WebSocket handler still works
   - Verify PLAN.org watching still works
   - Update main.go to use new EventHub (should be minimal API changes)
   - Keep backward compatibility: deprecated aliases if needed
   Tests: All watcher tests pass, integration tests for PLAN.org watching
   Done when: EventHub uses generic event bus, no functionality lost

** [#B] Migrate terminal Broadcaster to generic event bus
   Why: Unify terminal output streaming with event architecture (code reuse, not semantic unification)
   Change:
   - Replace internal/terminal/broadcaster.go with event.Bus[[]byte]
   - Broadcaster.Subscribe() → bus.Subscribe()
   - Broadcaster.Broadcast(chunk) → bus.Publish(chunk)
   - CRITICAL: Use BlockOnFull=false with generous buffer (256+) for terminal I/O
   - Terminal I/O is a STREAM, not discrete events: order matters, cannot be dropped safely
   - Keep OutputBuffer separate (history storage, not event delivery)
   - Session.broadcastLoop() stays (goroutine reads s.output channel, calls bus.Publish)
   - Update Session to use event bus for output fan-out (replace bcast field)
   - Update WebSocket terminal handler: subscribe to terminal output bus
   - Verify terminal output streaming still works after migration
   - Check: no output corruption, no latency increase, handles multiple subscribers
   - Document: terminal I/O uses Bus for implementation, but semantically is streaming not eventing
   Tests: Terminal output tests pass, WebSocket streaming works, no data loss under load
   Done when: Terminal output uses event bus, Broadcaster code removed, streaming semantics preserved

** [#B] Migrate logging to generic event bus
   Why: Unify log streaming with event architecture
   Change:
   - Replace LogHub in internal/logging with event.Bus[LogEntry]
   - Logger.Subscribe() → logBus.Subscribe()
   - Logger.log() → logBus.Publish(entry) after writing to buffer
   - CRITICAL: Use BlockOnFull=true for logs - NEVER drop log entries (loss of observability)
   - Use reasonable timeout (100ms) to prevent indefinite blocking
   - Keep LogBuffer separate (persistent log storage, only bus does fanout)
   - Update /ws/logs WebSocket handler to use event bus
   - Maintain level filtering: use SubscribeFiltered for log level filtering
   - Remove duplicate LogHub struct
   - Verify log streaming still works (WebSocket + tests)
   - Add test: verify no logs dropped under high load
   Tests: Logging tests pass, log WebSocket streaming works, no dropped logs
   Done when: Log streaming uses event bus, LogHub code removed, observability preserved

** [#B] Add agent lifecycle events
   Why: New capability enabled by event bus - track agent state changes
   Change:
   - Create AgentBus in Manager: event.Bus[AgentEvent]
   - Emit events: agent_started, agent_stopped, agent_error
   - Manager.Create(): publish AgentEvent{Type: "agent_started", AgentID, AgentName}
   - Manager.Delete(): publish AgentEvent{Type: "agent_stopped", AgentID}
   - Session error handling: publish AgentEvent{Type: "agent_error", AgentID, Error}
   - Add GET /api/agents/events WebSocket endpoint for live agent events
   - Frontend: subscribe to agent events, update dashboard in real-time
   - Document agent event types and payloads
   - Consider: emit agent_prompt_injected, agent_bell events for workflow integration
   Tests: Unit tests for agent event emission, WebSocket integration test
   Done when: Agent lifecycle observable via events, dashboard updates live

** [#B] Add terminal lifecycle events
   Why: Separate terminal events from terminal I/O for better observability
   Change:
   - Create TerminalBus in Manager: event.Bus[TerminalEvent]
   - Emit events: terminal_created, terminal_closed, terminal_resized, terminal_error
   - Manager.Create(): publish TerminalEvent{Type: "terminal_created", TerminalID}
   - Manager.Delete(): publish TerminalEvent{Type: "terminal_closed", TerminalID}
   - Session resize: publish TerminalEvent{Type: "terminal_resized", Cols, Rows}
   - Keep terminal I/O separate (uses Bus[[]byte] for output streaming)
   - Add GET /api/terminals/events WebSocket for terminal lifecycle events
   - Frontend: subscribe to terminal events, show toast on terminal_error
   - Document terminal event types and when they're emitted
   Tests: Unit tests for terminal event emission, verify event timing
   Done when: Terminal lifecycle observable via events, not mixed with I/O

** [#B] Add config change events for future config refactor
   Why: Enable reactive config updates, needed for config refactor L1
   Change:
   - Create ConfigBus: event.Bus[ConfigEvent]
   - Event types: config_extracted, config_modified, config_conflict, config_validated
   - Emit during config extraction: publish after each file extracted/backed up
   - Emit on config validation: publish validation_error events with file path
   - Emit on runtime config changes (future: hot reload agents/skills)
   - Add GET /api/config/events WebSocket endpoint
   - Frontend: subscribe to config events, show extraction progress, conflicts
   - Document: this sets up infrastructure for config refactor L1
   - Config refactor L1 will consume these events for progress reporting
   Tests: Unit tests for event emission during extraction (mock extraction)
   Done when: Config events defined, infrastructure ready for config refactor

** [#C] Add workflow state events for Temporal integration
   Why: Better observability of workflow pauses/resumes, bell handling
   Change:
   - Create WorkflowBus: event.Bus[WorkflowEvent]
   - Event types: workflow_started, workflow_paused, workflow_resumed, workflow_completed, workflow_error
   - Emit from Temporal activities: publish after state changes
   - Emit on bell detection: workflow_paused with bell context
   - Add GET /api/workflows/events WebSocket endpoint
   - Frontend Flow tab: subscribe to workflow events, update status live
   - Document workflow event types and payloads
   - Consider: unify with Temporal's built-in event history vs custom events
   Tests: Integration test with mock workflow, verify event emission
   Done when: Workflow state changes observable via events

** [#B] Add event bus metrics and monitoring
   Why: Observability into event system health and performance
   Change:
   - Integrate Bus[T] with existing internal/metrics package
   - Bus reports to metrics.Registry on Publish: increment counters for published, dropped
   - Registry should be extended to track event bus metrics (not just Temporal)
   - Track per-bus-type metrics: filesystem events, agent events, terminal I/O, logs
   - Metrics exposed via existing /api/metrics endpoint
   - Future: metrics.Registry will support OpenTelemetry (not just Prometheus)
   - Keep metrics integration simple: Registry.IncEventPublished(busType), Registry.IncEventDropped(busType)
   - Log warnings when drop rate exceeds threshold (e.g., >1% of events)
   - Add /api/events/debug endpoint: list all active buses, subscriber counts
   - Document: metrics design accommodates future OpenTelemetry migration
   Tests: Verify metrics accuracy, test metric aggregation
   Done when: Event bus health observable via metrics.Registry, OTel-ready

** [#B] Create event bus testing utilities
   Why: Make it easy to test event-driven code
   Change:
   - Create internal/event/testing.go with test helpers
   - MockBus[T]: synchronous bus for deterministic tests
   - EventCollector[T]: captures published events for assertion
   - Example: collector := NewEventCollector[AgentEvent](); bus.Subscribe(collector.Collect)
   - TimeoutSubscriber: fails test if event not received within duration
   - EventMatcher: fluent assertions for event properties
   - Document testing patterns: how to test event publishers, subscribers
   - Add examples in test files
   Tests: Test the test utilities (meta-testing)
   Done when: Testing utilities make event testing easy and reliable

** [#C] Add event replay and debugging features
   Why: Help developers debug event-driven flows
   Change:
   - Add optional event history to Bus[T]: keep last N events
   - NewBus option: WithHistory(size int) enables event replay
   - Add ReplayLast(n int, subscriber chan T) to resend recent events
   - Add DumpHistory() []T for debugging
   - Consider: event tracing (assign trace IDs, track event chains)
   - Add GESTALT_EVENT_DEBUG env var: log all events at debug level
   - Document debugging workflow: capture history, replay, trace chains
   Tests: Test history buffer, replay correctness
   Done when: Event system is debuggable in development

** [#B] Update documentation for event-driven architecture
   Why: Developers need to understand when and how to use events
   Change:
   - Add "Event-Driven Architecture" section to AGENTS.md
   - Document: what events are, when to use them vs direct calls
   - Document: core event types and their payloads
   - Document: how to publish events (Bus.Publish)
   - Document: how to subscribe (Bus.Subscribe, SubscribeFiltered)
   - Document: event bus lifecycle and cleanup
   - Document: testing patterns for event-driven code
   - Add architecture diagram: event flows (filesystem → agent → terminal → UI)
   - Update README.md: mention event-driven architecture as core feature
   - Add examples: subscribing to agent events, filtering terminal events
   Tests: None (documentation only)
   Done when: Event architecture fully documented with examples

** [#B] Add integration tests for event flows
   Why: Verify end-to-end event propagation across system boundaries, prevent frontend breakage
   Change:
   - Test scenario: file change → EventHub → WebSocket → frontend
   - Test scenario: agent start → AgentBus → dashboard update
   - Test scenario: terminal output → TerminalBus → WebSocket → xterm
   - Test scenario: config extraction → ConfigBus → progress UI
   - Test scenario: workflow pause → WorkflowBus → Flow tab update
   - Use real components (not mocks) for integration tests
   - Verify event timing: events arrive in correct order
   - Verify event delivery: no lost events under load
   - Stress test: many subscribers, high event rate
   - CRITICAL: Add WebSocket message format contract tests
   - Test: JSON shape of events matches frontend expectations (eventStore.js, terminalStore.js)
   - Test: WebSocket reconnection logic still works after event bus migration
   - Document WebSocket contracts: message formats, event types, expected fields
   - Frontend and backend ship together: no versioning needed, just contract tests
   Tests: Integration test suite for event flows, WebSocket contract tests prevent frontend breakage
   Done when: Event propagation works reliably end-to-end, frontend guaranteed compatible

** TODO [#C] Consider event persistence for audit trail (OPTIONAL - DEFER)
   Why: Events are valuable for debugging, compliance, analytics
   Change:
   - This is OPTIONAL and can be deferred to future work
   - Design optional event persistence: write events to disk/DB
   - Use case: audit trail (who started which agent when)
   - Use case: replay for debugging (what happened before crash)
   - Use case: analytics (event frequency, patterns)
   - Decide: SQLite for local storage, or structured log files
   - Decide: which events to persist (all vs high-value only)
   - Add EventStore interface: Append(event), Query(filters), Replay()
   - Make persistence opt-in: GESTALT_EVENT_STORE_ENABLED
   - Document retention policy: keep last N days or M events
   - Consider: OpenTelemetry already provides tracing/spans, may overlap with event persistence
   - Decision: DEFER this step, focus on core event bus first, add persistence later if needed
   Tests: Test event store implementation, verify persistence and replay (if implemented)
   Done when: Event persistence available as opt-in feature (OPTIONAL - can skip for now)

** [#B] Deprecate old event implementations
   Why: Remove duplicate code after successful migration
   Change:
   - Mark EventHub as deprecated (in comments and docs)
   - Mark Broadcaster as deprecated
   - Mark LogHub as deprecated
   - Add deprecation warnings in code: "Use event.Bus instead"
   - Set deprecation timeline: remove in 2.0.0 (major version bump)
   - Update all internal code to use event.Bus directly
   - Keep deprecated APIs as thin wrappers during transition
   - Document migration guide for external users (if any)
   Tests: Verify deprecated APIs still work (backward compatibility)
   Done when: Old implementations deprecated, migration path clear

** [#C] Performance optimization and benchmarking
   Why: Ensure event bus doesn't become bottleneck under load
   Change:
   - Benchmark Bus[T] operations: Subscribe, Publish, Unsubscribe
   - Target: Publish should be <1µs for non-blocking mode
   - Target: Support 10k+ events/sec with 100+ subscribers
   - Optimize hot paths: reduce allocations, use sync.Pool for channels
   - Optimize locking: consider lock-free data structures for metrics
   - Profile under load: identify bottlenecks, optimize
   - Add benchmark suite: go test -bench -benchmem
   - Document performance characteristics and limits
   Tests: Benchmark suite, load tests with many subscribers
   Done when: Event bus meets performance targets, benchmarked

** [#A] Validate event architecture before config refactor
   Why: Ensure event system is stable before building on top of it
   Change:
   - Run full test suite: all tests must pass
   - Run integration tests: verify event flows work end-to-end
   - Manual testing: trigger all event types, observe in UI
   - Code review: ensure Bus[T] API is clean and ergonomic
   - Documentation review: ensure examples are clear and correct
   - Performance review: ensure benchmarks meet targets
   - Decision point: is event architecture ready for config refactor to use?
   - If yes: proceed with config refactor L1 (which will emit config events)
   - If no: identify gaps, create follow-up L2 tasks, re-validate
   Tests: Full test suite, integration tests, manual testing
   Done when: Event architecture is validated, ready for production use

** [#B] Isolate dev proxy per instance
   Why: Multiple Gestalt instances on one machine should not share backend state unintentionally
   Change:
   - Make Vite dev proxy target configurable via environment (default remains localhost:8080)
   - Document how to point each frontend at its own backend port
   - Ensure /api and /ws proxy targets are derived from the configured backend URL
   Tests: Frontend tests and backend tests pass
   Done when: Running two instances with distinct backend ports shows isolated status

** [#B] Fix make dev shell compatibility
   Why: `make dev` should work under /bin/sh with custom env overrides
   Change:
   - Avoid heredoc command substitutions in GNUmakefile dev target
   - Keep port selection behavior unchanged
   Tests: Backend and frontend tests pass
   Done when: `GESTALT_BACKEND_PORT=9090 make dev` runs without shell errors

** [#B] Move make dev port logic into script
   Why: Keep Makefile readable and avoid inline scripting
   Change:
   - Move backend URL/port resolution into `scripts/` (prefer JS)
   - Keep selection behavior unchanged for GESTALT_BACKEND_PORT/GESTALT_BACKEND_URL
   - Make GNUmakefile call the script for env setup
   Tests: Backend and frontend tests pass
   Done when: `make dev` works with overrides without python in GNUmakefile


** [#B] Remove deprecated EventHub wrapper
   Why: Deprecated wrappers should be removed now that breaking changes are acceptable
   Change:
   - Remove internal/watcher/hub.go (EventHub) and all references
   - Replace EventHub usage with event.Bus[watcher.Event] and direct subscriptions
   - Update watcher helpers (git watcher, plan watcher) to accept bus
   - Update /ws/events handler to accept event bus directly
   - Adjust tests to use event.Bus instead of EventHub
   - Update docs to remove EventHub references
   Tests: Update event flow tests to use bus, ensure /ws/events still works
   Done when: EventHub is removed and filesystem events flow through event.Bus

* DONE [#B] Separate frontend and backend ports
  Goal: Allow multiple Gestalt instances by decoupling UI and API ports.

** [#B] Randomize backend port for multi-instance runs
   Why: Allow multiple released Gestalt binaries to run without port collisions
   Change:
   - Pick a free port automatically when no backend port is specified
   - Respect GESTALT_BACKEND_PORT/--backend-port when set
   - Keep GESTALT_PORT/--port for frontend/UI bind
   - Proxy /api and /ws from the frontend server to the backend
   - Log backend and frontend listen addresses
   - Update docs/tests for the new default behavior
   Tests: Backend and frontend tests pass
   Done when: Multiple binaries start on distinct backend ports by default and env overrides still work

** [#B] Multi-instance daemon ports
  Goal: Ensure all per-instance daemons bind safely for multi-instance use.

** [#B] Fix Temporal dev bind and UI link
   Why: Temporal dev server should bind publicly for sharing and the UI link should match the random port
   Change:
   - Bind Temporal dev server to 0.0.0.0 by default
   - Expose the actual Temporal UI port in /api/status (or equivalent)
   - Update frontend "View in Temporal" link to use the reported UI URL
   Tests: Backend and frontend tests pass
   Done when: Temporal dev UI is reachable on the reported port and the link matches the active port

** Temporal dev server bind + UI link
   - Bind Temporal dev server to 0.0.0.0 with random gRPC/UI ports.
   - Expose Temporal UI URL in /api/status and use it for the Flow "View in Temporal" link.
* WIP [#B] Fix terminal natural touch scrolling
  Goal: Enable natural touch scrolling anywhere on the terminal (not just scrollbar) while preserving mouse text selection for clipboard copy.
  Notes:
  - Current state: touch scroll code EXISTS in terminalStore.js (setupTouchScroll, lines 257-326) but DOES NOT WORK
  - Problem analysis: code is implemented but has multiple architectural and interaction issues
  - Root cause 1: xterm.js intercepts touch events for its own text selection before our handlers fire
  - Root cause 2: passive:true on touchstart prevents preventDefault coordination with touchmove
  - Root cause 3: xterm viewport scrolling conflicts with our manual scrollTop manipulation
  - Root cause 4: no pointer type detection (touch vs mouse) leads to conflicting behaviors
  - Root cause 5: touch-action: pan-y on terminal-shell__body may be insufficient for xterm internals
  - Desired behavior: Touch = scroll anywhere, Mouse = text selection (current behavior preserved)
  - Browser touch API: touchstart (identify gesture) → touchmove (scroll) → touchend (cleanup)
  - Pointer Events API alternative: unifies mouse/touch/pen with pointerType detection
  - xterm.js version: 6.0.0 (latest) - uses own touch handlers for text selection
  - Previous attempts failed: likely due to event ordering, passive listeners, xterm conflicts
  - Solution approach: Pointer Events API + proper event capture ordering + xterm mode coordination
  - Testing requirements: manual touch device testing (no good automated touch simulation)
  Date: 2026-01-11

** DONE [#A] Research and analyze why current touch scroll fails
   Why: Must understand root cause before designing solution, avoid repeating past mistakes
   Change:
   - Document current implementation: setupTouchScroll in terminalStore.js (lines 257-326)
   - Current approach: Touch Events API (touchstart/touchmove/touchend) with capture:true
   - Issue 1: touchstart uses passive:true, cannot call preventDefault in touchmove (browser error)
   - Issue 2: xterm.js has own touch handlers that fire first (even with capture:true on our side)
   - Issue 3: Manual viewport.scrollTop manipulation conflicts with xterm's scroll manager
   - Issue 4: No way to distinguish mouse (selection) from touch (scroll) in current code
   - Issue 5: getViewportElement() gets .xterm-viewport but xterm may recreate/replace it
   - Research xterm.js touch handling: check if options exist to disable touch selection
   - Research xterm.js scroll API: term.scrollLines(), term.scrollToLine() vs direct scrollTop
   - Research Pointer Events: pointerType property distinguishes 'mouse', 'touch', 'pen'
   - Test current code: add console.log to handlers, verify if they even fire on touch
   - Test hypothesis: touch events never reach our handlers due to xterm interception
   Findings:
   - setupTouchScroll is attached to `term.element` (the `.xterm` root), with `touchstart` passive true
     and `touchmove` passive false, using `viewport.scrollTop` deltas and `syncScrollState()`.
   - The CSS `touch-action: pan-y` is applied to `.terminal-shell__body`, not `.xterm`/`.xterm-viewport`,
     so browser default scrolling/selection can still win inside xterm.
   - xterm owns touch handling for selection and can call `stopPropagation` in its handlers; since our
     listener is registered after xterm, its capture handler can still preempt ours.
   - Direct `viewport.scrollTop` manipulation bypasses xterm's scroll APIs; xterm maintains its own
     viewport state, so manual scrolling risks desync (and uses `.xterm-viewport` that can be rebuilt).
   - There is no pointer type detection, so any non-touch gestures cannot be separated from selection.
   Evidence/notes:
   - `setupTouchScroll` in `frontend/src/lib/terminalStore.js` uses `event.touches` averaging and
     updates `.xterm-viewport` scrollTop; `touchstart` is passive so the gesture is likely already
     claimed by the browser/xterm before `touchmove` can prevent default in Safari/iOS.
   - Terminal CSS sets `touch-action` only on `.terminal-shell__body` and uses
     `-webkit-overflow-scrolling: touch` on `.xterm-viewport`, encouraging native scroll over JS.
   - Manual device testing was not possible in this environment; confirm on a real touch device.
   Open questions:
   - xterm does not expose a stable "disable touch selection" option in our current config; will use
     pointer events with `pointerType === 'touch'` and stop propagation in capture phase instead.
   Tests: Manual touch testing with logging, document exact event flow
   Done when: Root cause documented with evidence, solution approach validated

** DONE [#B] Choose between Touch Events vs Pointer Events API
   Why: Pointer Events unify mouse/touch/pen and provide pointerType detection
   Change:
   - Compare Touch Events API (touchstart/move/end) vs Pointer Events API (pointerdown/move/up)
   - Touch Events pros: explicit touch-only, no mouse interference
   - Touch Events cons: separate from mouse events, harder to coordinate, passive issues
   - Pointer Events pros: single API, pointerType='touch'/'mouse', better preventDefault control
   - Pointer Events cons: need to filter by pointerType, slightly more complex
   - Decision factors: browser support (Pointer Events supported everywhere modern), xterm compatibility
   - Recommendation: Use Pointer Events API with pointerType filtering
   - Pointer Events allow: pointerdown (identify touch), pointermove (scroll), pointerup (end)
   - Check event.pointerType === 'touch' to distinguish from mouse clicks
   - Pointer Events have better passive/active coordination (can preventDefault in move after checking type)
   - Document decision with rationale for future reference
   Decision:
   - Use Pointer Events API with `pointerType === 'touch'` filtering.
   - Rationale: single unified API, reliable pointer type detection, fewer passive listener pitfalls,
     and easier capture-phase interception before xterm handlers while leaving mouse/pen selection intact.
   - Browser support is sufficient for target browsers (modern Safari/Chrome/Edge/Firefox).
   Tests: None (design decision)
   Done when: API choice documented with technical justification

** TODO [#B] Design pointer-based scroll architecture
   Why: Clear architecture prevents implementation mistakes
   Change:
   - Architecture: Pointer Events on term.element with capture:true and passive:false
   - Flow: pointerdown → check pointerType → if touch, track start position → pointermove → scroll
   - Mouse flow: pointerdown (mouse) → ignore, let xterm handle selection
   - Touch flow: pointerdown (touch) → track, pointermove → manual scroll, pointerup → cleanup
   - Prevent xterm interference: call event.stopPropagation() for touch pointers in capture phase
   - This intercepts touch before xterm sees it, but lets mouse through
   - Scroll mechanism: use term.scrollLines(delta) instead of viewport.scrollTop (cleaner API)
   - Or use viewport.scrollTop but wrap in term.refresh() call (force xterm to sync state)
   - Inertial scrolling: track pointer velocity, continue scroll after pointerup (optional, defer)
   - Edge cases: multi-touch (use primary pointer only), touch-and-hold (threshold before scroll)
   - State machine: idle → tracking → scrolling → idle
   - Add touch-action: none to xterm element (disable browser touch gestures, we handle all)
   - Update CSS: remove touch-action: pan-y, add touch-action: none to .xterm
   - Consider: threshold distance before activating scroll (avoid accidental scroll on tap)
   Tests: None (design only)
   Done when: Architecture documented with event flow diagram, edge cases identified

** TODO [#B] Implement pointer event handlers with type detection
   Why: Core of the solution - pointer handlers that distinguish touch from mouse
   Change:
   - Replace setupTouchScroll with setupPointerScroll in terminalStore.js
   - Register pointerdown/pointermove/pointerup/pointercancel on term.element
   - All handlers: { capture: true, passive: false } (need preventDefault control)
   - Track state: isScrolling (bool), pointerId (number), startY (number), lastY (number)
   - pointerdown handler:
     - if (event.pointerType !== 'touch') return (let mouse through to xterm)
     - if (isScrolling) return (prevent multi-touch conflicts)
     - event.preventDefault(), event.stopPropagation() (intercept before xterm)
     - capture pointer: event.target.setPointerCapture(event.pointerId)
     - track: pointerId, startY, lastY, isScrolling=false
   - pointermove handler:
     - if (event.pointerId !== tracked pointerId) return
     - if (event.pointerType !== 'touch') return
     - calculate deltaY: event.clientY - lastY
     - if (!isScrolling && Math.abs(deltaY) < threshold) return (avoid accidental scroll)
     - isScrolling = true
     - scroll terminal: term.scrollLines(-Math.round(deltaY / pixelsPerLine))
     - or: viewport.scrollTop -= deltaY; term.refresh()
     - update lastY
     - event.preventDefault() (prevent browser scroll)
   - pointerup/pointercancel handler:
     - if (event.pointerId !== tracked pointerId) return
     - release pointer capture
     - reset state: isScrolling=false, pointerId=null
   - Return cleanup function: remove all event listeners, release capture if active
   Tests: Unit test pointer type filtering, state machine transitions (mock PointerEvents)
   Done when: Pointer handlers implemented, mouse ignored, touch captured and scrolled

** TODO [#B] Integrate pointer scroll into attach/detach lifecycle
   Why: Ensure handlers are properly registered and cleaned up with terminal lifecycle
   Change:
   - In terminalStore.js attach() function (line ~328):
   - Replace setupTouchScroll call with setupPointerScroll
   - Target remains: term.element (xterm's root element)
   - Ensure term.element exists before calling setupPointerScroll
   - Store cleanup function in disposeTouchHandlers (rename to disposePointerHandlers for clarity)
   - In dispose() function: call disposePointerHandlers if it exists
   - In detach() function: call disposePointerHandlers if it exists
   - Handle edge case: term.element recreated (e.g., on reconnect) → re-setup handlers
   - Add defensive checks: if (!term.element) return in setupPointerScroll
   - Update variable names: touchTarget → pointerTarget, disposeTouchHandlers → disposePointerHandlers
   Tests: Integration test: attach → handlers active, detach → handlers removed, no leaks
   Done when: Pointer scroll integrated into terminal lifecycle, cleanup verified

** TODO [#C] Add CSS touch-action: none to xterm element
   Why: Disable browser default touch gestures so we fully control touch behavior
   Change:
   - In Terminal.svelte <style> section (line ~369):
   - Add: :global(.xterm) { touch-action: none; }
   - Remove or update: .terminal-shell__body { touch-action: pan-y; } → { touch-action: none; }
   - touch-action: none tells browser "don't do pinch-zoom, pull-to-refresh, etc"
   - We handle all touch interactions via pointer events
   - Note: this disables ALL browser touch gestures on terminal (intended)
   - Alternative: touch-action: pan-x pan-y (allow scroll but prevent zoom) - test both
   - Document: touch-action: none is required for custom touch handling to work correctly
   Tests: Manual test: verify no browser gestures interfere with custom scroll
   Done when: CSS updated, browser touch gestures disabled on terminal

** TODO [#B] Calculate scroll sensitivity (deltaY to scrollLines conversion)
   Why: Touch scroll needs to feel natural, not too fast or too slow
   Change:
   - Determine pixels-per-line for terminal: term.element.offsetHeight / term.rows
   - Or use fixed value: ~20 pixels per line (typical terminal line height)
   - Convert pointer deltaY (pixels) to scroll lines: deltaLines = deltaY / pixelsPerLine
   - Round or floor deltaLines to avoid fractional scrolling (term.scrollLines takes integer)
   - Add sensitivity multiplier: configurable value (default 1.0) to adjust scroll speed
   - Expose in Terminal.svelte props: scrollSensitivity (number, default 1.0)
   - Pass to terminalStore via options or direct call: state.setScrollSensitivity(value)
   - Test different sensitivities: 0.5 (slow), 1.0 (normal), 1.5 (fast)
   - Consider: momentum scrolling (track velocity, continue after pointerup) - OPTIONAL, defer
   - Document recommended sensitivity range: 0.5 to 2.0
   Tests: Manual testing with various sensitivity values, document optimal range
   Done when: Scroll sensitivity feels natural, configurable, documented

** TODO [#B] Add scroll activation threshold to prevent accidental scrolling
   Why: Small touch movements (taps, jitters) shouldn't trigger scroll
   Change:
   - In pointermove handler: track cumulative movement from pointerdown
   - Don't activate scrolling until |totalDeltaY| > threshold (e.g., 10 pixels)
   - State: isScrolling starts false, becomes true when threshold exceeded
   - Once isScrolling=true, all subsequent pointermove events scroll
   - Threshold prevents: accidental scroll on tap, jitter during touch, small hand movements
   - Recommended threshold: 8-15 pixels (test on real device)
   - Also add time threshold (optional): must move AND hold for 100ms before scrolling
   - This further prevents accidental scroll on quick taps
   - Document: threshold values chosen based on mobile UI best practices
   Tests: Manual test: tap without scrolling, small movements ignored, deliberate scroll works
   Done when: Threshold implemented, accidental scrolls prevented, feels responsive

** TODO [#B] Preserve xterm text selection for mouse
   Why: Mouse users must still be able to select text for clipboard copy
   Change:
   - Verify mouse behavior: pointerType === 'mouse' events are NOT intercepted
   - Our handlers return early for mouse, xterm sees events normally
   - Test: click-drag with mouse → text selection works (selection highlight appears)
   - Test: double-click with mouse → word selection works
   - Test: triple-click with mouse → line selection works
   - Test: Ctrl+C / Cmd+C → copies selected text to clipboard
   - If selection breaks: ensure mouse pointers skip preventDefault/stopPropagation
   - Edge case: stylus/pen (pointerType === 'pen') → treat as mouse or touch?
   - Decision: treat pen as mouse (allow selection) - pens are precise like mice
   - Update handler: if (event.pointerType !== 'touch') return (allows mouse + pen)
   Tests: Manual test with real mouse, verify selection works exactly as before
   Done when: Mouse selection verified working, no regression in mouse behavior

** TODO [#B] Test on real touch devices (phone, tablet)
   Why: Touch behavior cannot be reliably simulated, must test on hardware
   Change:
   - Test devices: iOS (Safari), Android (Chrome), tablet (both)
   - Test scenarios:
     1. Single-finger scroll up/down → terminal scrolls smoothly
     2. Tap (no movement) → no scroll, no selection (just focus)
     3. Small drag (<threshold) → no scroll (threshold works)
     4. Fast swipe → scrolls, no overscroll or jank
     5. Multi-touch (accidental) → ignored, no crashes
     6. Scroll while typing → input not interrupted
     7. Scroll near edges (top/bottom) → stops at buffer limits, no overscroll
     8. Long terminal output (>1000 lines) → scrolls through all history
   - Test with mouse on same devices (if available): selection still works
   - Document any device-specific issues (iOS Safari vs Android Chrome differences)
   - Check for jank, lag, unresponsive touches, unexpected jumps
   - Adjust sensitivity/threshold based on real device feel
   Tests: Manual testing on physical devices, document results per device/browser
   Done when: Touch scroll works smoothly on iOS and Android, no device-specific bugs

** TODO [#C] Add visual feedback for touch scroll (optional)
   Why: Users may want visual indication that touch is active (not strictly required)
   Change:
   - Optional: add subtle visual cue during touch scroll (e.g., fade in scroll indicator)
   - Show scrollbar on touch, hide when idle (like mobile apps)
   - CSS transition: scrollbar opacity 0 → 1 on touch, fade out after 1s idle
   - Or: add touch ripple effect at touch point (very subtle, doesn't obscure text)
   - Or: do nothing - natural scrolling doesn't need extra feedback (iOS/Android style)
   - Recommendation: DEFER this step, test without visual feedback first
   - If users request it later, add minimal scrollbar fade animation
   - Document: visual feedback is optional enhancement, not core requirement
   Tests: Manual test with and without visual feedback, gather user preference
   Done when: Visual feedback decision made, implemented if desired (optional)

** TODO [#B] Add touch scroll integration tests (automated)
   Why: Prevent regressions, document expected behavior in code
   Change:
   - Create frontend/src/lib/terminalStore.test.js (if doesn't exist)
   - Use Vitest + jsdom + mock PointerEvent API
   - Test suite: "Touch Scroll"
   - Test 1: setupPointerScroll registers event listeners on element
   - Test 2: pointerdown with type='touch' activates tracking
   - Test 3: pointerdown with type='mouse' is ignored
   - Test 4: pointermove scrolls terminal after threshold
   - Test 5: pointerup cleans up state
   - Test 6: cleanup function removes all listeners
   - Test 7: multi-pointer scenario (second touch ignored)
   - Mock: term.scrollLines or verify viewport.scrollTop changes
   - Mock: term.element, PointerEvent constructor
   - Challenge: PointerEvent not fully supported in jsdom (may need polyfill)
   - Alternative: manual testing + detailed documentation if mocking too complex
   - Document: "Touch scroll tested manually on iOS/Android, see TESTING.md"
   Tests: Automated test suite (preferred) or manual test checklist (fallback)
   Done when: Touch scroll behavior covered by tests or documented test procedure

** TODO [#B] Update documentation for touch scroll feature
   Why: Users and developers need to know touch scroll exists and how it works
   Change:
   - Update README.md: add "Touch Scrolling" section under Terminal features
   - Document: "Terminal supports natural touch scrolling on mobile devices"
   - Document: "Touch anywhere on terminal to scroll, mouse selection preserved"
   - Document: "Works on iOS Safari, Android Chrome, and tablets"
   - Update AGENTS.md: mention touch scroll implementation for LLM context
   - Technical details: Pointer Events API, pointerType detection, scroll sensitivity
   - Add to TESTING.md: touch scroll test checklist for manual QA
   - Troubleshooting: "Touch scroll not working? Check browser supports Pointer Events"
   - Known limitations: "No momentum scrolling (tap to stop), may add in future"
   - Document scroll sensitivity config (if exposed as prop): default 1.0
   Tests: None (documentation only)
   Done when: Touch scroll documented in user and developer docs

** TODO [#A] Validate with user testing before marking done
   Why: Ensure solution actually solves the problem, not just technically correct
   Change:
   - User testing: hand device to non-technical user, ask them to scroll terminal
   - Observe: do they naturally try to scroll? does it work? any confusion?
   - Ask: "Does scrolling feel natural compared to other apps?"
   - Test with previous failed attempts: ensure this solution actually works (not just theory)
   - Compare to native apps: iOS Terminal app, Android Termux, etc.
   - Acceptance criteria:
     1. Touch scroll works immediately without instruction
     2. No conflicts with typing or other interactions
     3. Feels smooth and responsive (no lag or jank)
     4. Mouse selection still works for desktop users
     5. No regressions in existing terminal features
   - If issues found: iterate on sensitivity, threshold, or pointer handling
   - Document any edge cases or limitations discovered in user testing
   - Sign-off: get confirmation from original requester that problem is solved
   Tests: User acceptance testing, real-world usage scenarios
   Done when: User confirms touch scroll works as expected, problem solved
* DONE [#A] Config extraction refactor with hash verification and version tracking
  Goal: Refactor config/ handling to always extract embedded resources to .gestalt/config/ on startup with SHA-256 hash verification, semantic version compatibility checks, backup on conflicts, and relocate PLAN.org to .gestalt/.
  Notes:
  - Current state: config/ is embedded, optional override from ./gestalt/config/
  - New behavior: always extract embedded config/* to .gestalt/config/ on startup
  - Hash verification: store SHA-256 hashes of embedded files at compile time
  - Version tracking: .gestalt/version.json with semantic version and build date
  - Version compatibility: major mismatch=error, minor=warning, patch=info log
  - Conflict resolution: if existing file differs, warn + backup (.bck suffix) + overwrite
  - If hash matches: skip extraction (file already up-to-date)
  - Efficient hash storage: embed single manifest file (JSON or binary) with paths→hashes
  - PLAN.org relocation: move from workdir root to .gestalt/PLAN.org
  - Update all PLAN.org references: API endpoints, watchers, UI, documentation
  - Benefits: consistent config state, upgrade path, user customization with safety, version compatibility enforcement
  - Extract-config flag becomes no-op (extraction happens automatically)
  - Preserve user overrides: hash check prevents accidental overwrites
  Date: 2026-01-11

** TODO [#B] Research and design version.json and manifest formats
   Why: Need efficient compile-time hash storage, runtime lookup, and version compatibility tracking
   Change:
   - Design version.json format for .gestalt/ directory
   - Version structure: {"version": "1.2.3", "major": 1, "minor": 2, "patch": 3, "built": "2026-01-11T12:34:56Z", "git_commit": "abc123..."}
   - Optional fields: git_commit (short SHA), build_host, go_version for debugging
   - Design manifest format: JSON or binary for embedded hash map
   - Manifest structure: {"path/to/file.json": "sha256hex", ...}
   - Consider: single manifest.json vs separate hash files per resource type
   - Research: Go crypto/sha256 for hash generation at build time
   - Research: embed.FS walking pattern to enumerate all files
   - Decision: JSON manifest for simplicity (human-readable, easy to generate)
   - Manifest location: embedded as config/manifest.json or separate
   - Build-time generation: script or Makefile target to compute hashes and version
   Tests: None (design only)
   Done when: Version and manifest formats designed, documented in this L2

** TODO [#B] Create build-time manifest and version generator
   Why: Need to compute SHA-256 hashes and embed version info at compile time
   Change:
   - Create scripts/generate-config-manifest.go or shell script
   - Walk config/agents/, config/prompts/, config/skills/ directories
   - Compute SHA-256 hash of each file content
   - Output manifest JSON: {"agents/copilot.json": "abc123...", ...}
   - Use relative paths from config/ root for portability
   - Handle nested directories (skills with subdirectories)
   - Deterministic output: sort keys for reproducible builds
   - Write to config/manifest.json (embedded with other resources)
   - Generate version template from VERSION env var or git describe
   - Parse semantic version: extract major, minor, patch components
   - Capture build date as RFC3339 timestamp
   - Optional: capture git commit SHA (git rev-parse --short HEAD)
   - Write template version data to be embedded (or use ldflags for version fields)
   - Integrate into Makefile: run before go build, pass VERSION
   Tests: Run script, verify manifest.json and version data generated correctly
   Done when: Build generates manifest.json with hashes and version metadata

** TODO [#B] Embed manifest and version metadata
   Why: Manifest and version info must be available at runtime for verification
   Change:
   - Update cmd/gestalt/embed.go or root embed.go
   - Add manifest.json to embedded configFS
   - Ensure manifest is included in binary at compile time
   - Create internal/version package with embedded version data
   - Use ldflags to inject: Version, Major, Minor, Patch, Built, GitCommit
   - Add function LoadManifest(fs embed.FS) (map[string]string, error)
   - Parse manifest JSON into path→hash map
   - Handle missing manifest gracefully: warn and proceed without verification
   - Add function GetVersionInfo() VersionInfo to return structured version data
   Tests: Build binary, verify manifest and version accessible at runtime
   Done when: Manifest and version embedded and loadable at runtime

** TODO [#B] Implement hash verification logic
   Why: Core of extraction safety - verify existing files before overwriting
   Change:
   - Create internal/config/extractor.go with Extractor struct
   - Method: Extractor.Extract(sourceFS embed.FS, destDir string, manifest map[string]string) error
   - For each file in manifest:
     1. Compute destination path: destDir + relative path
     2. Check if destination exists
     3. If exists: compute SHA-256 of existing file
     4. Compare hashes: if match, skip (log at debug level)
     5. If differ: warn, rename existing to .bck, extract new
     6. If not exists: extract new
   - Handle directories: create parent dirs as needed
   - Preserve file permissions from embedded FS
   - Use atomic writes: write to temp, rename (avoid partial writes)
   - Structured logging: log each action (skip/backup/extract)
   Tests: Unit tests with temp directories, various conflict scenarios
   Done when: Extractor safely extracts with hash verification and backups

** TODO [#A] Implement version compatibility checking
   Why: Prevent running incompatible Gestalt versions on existing .gestalt/ directories
   Change:
   - Create internal/config/version.go with version compatibility logic
   - Function: CheckVersionCompatibility(installed, current VersionInfo) error
   - Compare major versions: if differ, return error "Incompatible major version"
   - Compare minor versions: if differ, log warning "Minor version mismatch"
   - Compare patch versions: if differ, log info "Patch version difference"
   - Error message must guide user: "Breaking changes detected. Backup .gestalt/ and run with --force-upgrade"
   - Warning message: "Config may be outdated. Review .bck files after startup."
   - Info message: "Config updated from X.Y.Z to X.Y.W"
   - Add --force-upgrade flag to bypass major version check (dangerous)
   Tests: Unit tests for all version comparison scenarios
   Done when: Version checking prevents incompatible upgrades

** TODO [#B] Integrate version tracking and extraction into startup
   Why: Ensure config and version are always checked and extracted on start
   Change:
   - Modify cmd/gestalt/main.go startup sequence
   - After flag parsing, before agent/skill loading:
     1. Create .gestalt/ directory if missing
     2. Check for existing .gestalt/version.json
     3. If exists: load and compare with current version
     4. Run version compatibility check (may error/warn/info)
     5. Load manifest from embedded FS
     6. Extract config/* to .gestalt/config/ with verification
     7. Write/update .gestalt/version.json with current version
     8. Log summary: version check result, N files extracted, M skipped, K backed up
   - Update agent/skill loaders to read from .gestalt/config/
   - Remove fallback to embedded FS (always use .gestalt/config/)
   - Handle extraction errors: log and exit if critical failure
   - Add env var: GESTALT_CONFIG_DIR (default .gestalt/config) for testing
   Tests: Integration test: start server, verify .gestalt/config/ and version.json
   Done when: Startup always checks version and extracts config

** TODO [#C] Handle backup file cleanup policy
   Why: Prevent accumulation of .bck files over time
   Change:
   - Add cleanup logic: keep only latest .bck per file
   - On backup creation: check for existing .bck, replace if older
   - Optional: keep timestamped backups (file.json.bck.YYYYMMDD-HHMMSS)
   - Add env var: GESTALT_CONFIG_BACKUP_LIMIT (default 1, 0=disable backups)
   - Log cleanup actions at debug level
   - Document backup behavior in README
   Tests: Test backup replacement logic
   Done when: Backup policy prevents unbounded file accumulation

** TODO [#B] Relocate PLAN.org to .gestalt/PLAN.org
   Why: Centralize all Gestalt state in .gestalt/ directory
   Change:
   - Update all PLAN.org references to .gestalt/PLAN.org
   - Backend: internal/watcher/watcher.go - update watched path
   - Backend: internal/api/rest.go - GET /api/plan endpoint path
   - Backend: cmd/gestalt/main.go - startup PLAN.org check
   - Frontend: views/PlanView.svelte - API still works (backend handles path)
   - Documentation: README.md, AGENTS.md - update PLAN.org references
   - On startup: if workdir/PLAN.org exists, offer to migrate to .gestalt/
   - Migration: copy PLAN.org to .gestalt/, optionally rename original
   Tests: Manual test: create PLAN.org, verify .gestalt/PLAN.org watched
   Done when: All code references .gestalt/PLAN.org, migration path documented

** TODO [#C] Add migration helper for existing installations
   Why: Users with existing PLAN.org in workdir need smooth transition
   Change:
   - On startup, check if workdir/PLAN.org exists
   - If yes and .gestalt/PLAN.org doesn't exist: auto-migrate (copy)
   - If both exist: warn user, use .gestalt/PLAN.org
   - Log migration action: "Migrated PLAN.org to .gestalt/"
   - Optional: add --migrate-plan CLI flag for manual control
   - Document migration behavior in README
   Tests: Test migration scenarios with various file states
   Done when: Existing installations migrate smoothly

** TODO [#C] Update --extract-config flag behavior
   Why: Flag becomes less relevant with automatic extraction
   Change:
   - Option 1: Remove flag entirely (extraction always happens)
   - Option 2: Keep flag, make it force re-extraction (ignore hashes)
   - Option 3: Rename to --force-config-extract or --reset-config
   - Document new behavior: extraction happens automatically
   - Update --help text to reflect automatic extraction
   - Consider: add --skip-config-extract for fast startup (advanced users)
   Tests: Test flag behavior matches documentation
   Done when: Flag behavior clear and documented

** TODO [#B] Update documentation for new config behavior
   Why: Users and contributors need to understand config extraction
   Change:
   - Update README.md "Embedded Resources" section
   - Document: config always extracted to .gestalt/config/ on startup
   - Document: hash verification prevents accidental overwrites
   - Document: .bck files created on conflicts, include resolution steps
   - Document: PLAN.org now lives in .gestalt/PLAN.org
   - Document: migration behavior for existing installations
   - Add troubleshooting section: conflicts, backup files, manual overrides
   - Update AGENTS.md with new config locations
   Tests: None (documentation only)
   Done when: Config extraction fully documented

** TODO [#B] Add config validation on extraction
   Why: Detect malformed config files early in startup
   Change:
   - After extraction, validate all config files
   - Agents: parse and validate all JSON files
   - Prompts: check .txt files are readable text
   - Skills: validate SKILL.md frontmatter and structure
   - Log validation warnings/errors with file paths
   - Continue startup on non-critical validation failures
   - Critical failures: malformed manifest, extraction I/O errors
   Tests: Test with invalid config files, verify warnings logged
   Done when: Startup includes config validation step

** TODO [#C] Optimize extraction performance
   Why: Minimize startup time impact of extraction
   Change:
   - Skip hash computation for unchanged files (check mtime first)
   - Parallel extraction: goroutines for independent files
   - Buffered I/O for hash computation and file writes
   - Cache manifest in memory: single parse per startup
   - Measure: log extraction duration at debug level
   - Add benchmark: compare cold start vs warm start (all skipped)
   Tests: Benchmark extraction with large config sets
   Done when: Extraction completes in <100ms for typical configs

** TODO [#B] Expose version info in API and logs
   Why: Users and monitoring tools need to see Gestalt version
   Change:
   - Update /api/status to include version object
   - Response format: {"version": "1.2.3", "major": 1, "minor": 2, "patch": 3, "built": "...", "git_commit": "..."}
   - Log version at startup: "Gestalt version X.Y.Z (built YYYY-MM-DD, commit abc123)"
   - Log config version compatibility check results
   - Include version in startup banner/splash
   - Document version fields in API documentation
   Tests: Verify version appears in /api/status and startup logs
   Done when: Version fully visible in API, logs, and UI

** TODO [#B] Update frontend for .gestalt/PLAN.org
   Why: Ensure UI correctly fetches PLAN.org from new location
   Change:
   - Verify GET /api/plan still works (backend handles path change)
   - No frontend changes needed if backend path abstracted correctly
   - Update any hardcoded PLAN.org references in comments/docs
   - Test PlanView.svelte with new backend path
   - Verify filesystem watcher events still trigger UI updates
   Tests: Manual test Plan tab, verify content loads and updates
   Done when: Frontend works seamlessly with .gestalt/PLAN.org

** TODO [#C] Add developer mode for config override
   Why: Developers may want to bypass extraction for faster iteration
   Change:
   - Add env var: GESTALT_DEV_MODE=true
   - In dev mode: skip extraction, read directly from config/ directory
   - Or: add --dev flag to skip extraction and validation
   - Document dev mode in TESTING.md or CONTRIBUTING.md
   - Only for development; production always extracts
   Tests: Test dev mode skips extraction
   Done when: Dev mode documented and functional

** TODO [#B] Add integration tests for config extraction flow
   Why: Critical path needs comprehensive test coverage
   Change:
   - Test scenarios:
     1. Fresh start: .gestalt/ doesn't exist
     2. Warm start: files unchanged (all skipped)
     3. Conflict: file modified (backup + overwrite)
     4. Migration: PLAN.org in workdir
     5. Partial extraction: some files exist, some don't
   - Use temp directories for isolation
   - Mock embedded FS with test data
   - Verify file contents, hashes, backups
   - Verify logs contain expected messages
   Tests: Integration test suite for extraction
   Done when: All extraction scenarios covered by tests

** TODO [#B] Document upgrade path and version compatibility
   Why: Users need to understand version compatibility and upgrade behavior
   Change:
   - Add "Upgrading Gestalt" section to README.md
   - Explain semantic versioning: major (breaking), minor (features), patch (fixes)
   - Explain version compatibility checks:
     - Major version mismatch: error, must backup and migrate
     - Minor version mismatch: warning, review .bck files
     - Patch version difference: automatic, logged at info level
   - Explain: new versions may update config files
   - Explain: hash verification detects changes
   - Explain: .bck files preserve customizations
   - Provide merge instructions: diff .bck vs new file
   - Document: how to keep customizations across upgrades
   - Document --force-upgrade flag (use with caution)
   - Example workflow: update binary → check version compatibility → review .bck files → merge changes
   - Document .gestalt/version.json format and purpose
   Tests: None (documentation only)
   Done when: Upgrade path and version compatibility clearly documented

** TODO [#C] Add telemetry for config extraction metrics
   Why: Monitor extraction behavior in production (if telemetry exists)
   Change:
   - Log metrics: files extracted, skipped, backed up
   - Track extraction duration and success rate
   - Log to structured logger for aggregation
   - Optional: expose in /api/metrics if metrics endpoint exists
   - Help diagnose config-related issues in the field
   Tests: Verify metrics appear in logs
   Done when: Extraction metrics logged and observable
* DONE [#B] Prompt templating system with include directives
  Goal: Support .tmpl prompt files that can include .txt fragments, rendering templates at agent start before injection into terminal.
  Notes:
  - Current system: prompts are plain .txt files read directly from config/prompts/ and injected to agent terminals
  - New capability: .tmpl files can use include directives to compose prompts from reusable .txt fragments
  - Template rendering happens backend-side before prompt injection (not at read time)
  - Include syntax: simple directive like {{include filename}} or <!-- include: filename --> (decision needed)
  - Failed includes: fail silently (no error, just skip the line) to allow optional fragments
  - Agent configs remain unchanged: prompt names can reference .tmpl or .txt (backward compatible)
  - Benefits: DRY principle for prompts, shared fragments (e.g., common "Workplan structure" section), easier maintenance
  Date: 2026-01-10

** [#C] Research and decide include directive syntax
   Why: Need clear, unambiguous syntax that doesn't conflict with existing prompt content
   Research needed:
   - Current prompt content analysis: check if any existing prompts contain syntax we might choose
   - Syntax options to evaluate:
     1. {{include filename}} - Handlebars/Mustache style (simple, widely recognized)
     2. <!-- include: filename --> - HTML comment style (safe, won't render if not processed)
     3. @include filename - Simple directive (clean, but might appear in natural text)
     4. #include "filename" - C preprocessor style (familiar to developers)
   - Consider: should includes be on their own line, or inline? (recommend: own line for clarity)
   - Consider: should we strip the include line from output, or leave a marker? (recommend: strip entirely)
   - Consider: should includes support .txt extension auto-append? (recommend: yes, try with/without .txt)
   Change:
   - Review all existing .txt prompts in config/prompts/ for potential syntax conflicts
   - Document findings in this L2 "Implementation details" section below
   - Make recommendation with rationale
   - Get user confirmation before proceeding to implementation
   Tests: Manual review of all prompt files
   Done when: Include syntax decided, documented, and approved by user
   Implementation details:
   Findings:
   - Reviewed config/prompts/*.txt (architect, coder, fixer, reviewer, tmux).
   - No occurrences of {{include ...}}, <!-- include: ... -->, @include, or #include.
   - No {{ or <!-- markers at all; low risk of accidental collisions.
   Recommendation:
   - Use {{include filename}} as the only directive, on its own line.
   - Strip the include line entirely during rendering.
   - Rationale: concise, familiar templating syntax, easy to parse, and safe with current prompt content.

** [#C] Create prompt template parser module
   Why: Separate concern from terminal manager; reusable and testable
   Architecture decision:
   - New package: internal/prompt for template parsing logic
   - Single responsibility: read prompt file, resolve includes, return rendered content and metadata
   Current state:
   - internal/terminal/manager.go line 516: readPromptFile(promptName) reads .txt files directly
   - Returns raw bytes, no processing
   - Used during agent terminal creation (line 450)
   Change:
   - Create internal/prompt/parser.go with:
     - type Parser struct with fields: fs fs.FS, dir string
     - func NewParser(promptFS fs.FS, promptDir, includeRoot string) *Parser
     - type RenderResult struct with fields:
       - Content []byte (rendered prompt content)
       - Files []string (ordered list: first the main .tmpl or .txt, then all successfully included files)
     - func (p *Parser) Render(promptName string) (*RenderResult, error)
   - Render logic:
     1. Try to read promptName.tmpl first; if not found, try promptName.txt
     2. Track all files in order: main file goes first in Files slice
     3. If .tmpl found, parse line-by-line for include directives
     4. For each include directive: recursively call Render() with included filename
     5. Append successfully included files to Files slice (in order of inclusion)
     6. Concatenate results and return final rendered content + file list
     7. Failed includes: silently skip, do NOT add to Files list
   - Include resolution:
     - Strip include directive line from output (don't leave markers)
     - For includes without extensions, try .tmpl, .md, then .txt (e.g., "common" → "common.tmpl")
     - If the include uses a path (contains / or starts with ./), load that exact path from the workdir root
     - Resolve bare includes from config/prompts first, then fall back to .gestalt/prompts
     - Deduplicate includes by canonical file path within a render to avoid repeated injection
     - Skip includes that are binary or non-text
     - Cycle detection: track include stack, return error if depth > 3 or if filename already in stack
   - Error handling:
     - Top-level prompt not found: return error (same as current behavior)
     - Included file not found: silently skip (per requirements)
     - Cycle detected: return error (prevent infinite loops)
   - File list metadata:
     - Preserve order: main template first, then includes in order of appearance
     - Use relative paths (relative to promptDir) for consistency
     - Example: ["architect.tmpl", "common-project-docs.txt", "common-workplan.txt"]
   Tests:
   - Unit tests in internal/prompt/parser_test.go:
     - Basic .txt file (no includes) - verify Files list has one entry
     - .tmpl with single include - verify Files list has two entries in order
     - .tmpl with multiple includes - verify Files list preserves order
     - Nested includes (include within include) - verify all files tracked
     - Failed include (file not found) - verify skipped file NOT in Files list
     - Cycle detection
     - Include with and without .txt extension
   Done when: Parser module exists, returns RenderResult with content + file list, fully tested

** [#C] Integrate template parser into terminal manager with file list logging
   Why: Replace direct file reads with template rendering; expose prompt composition metadata to agent
   Current state:
   - internal/terminal/manager.go line 450: calls readPromptFile(promptName)
   - Returns raw bytes directly from fs.ReadFile() or os.ReadFile()
   - No template processing, no metadata
   - Agent profiles have Skills field but prompts are invisible
   Change:
   - File: internal/terminal/manager.go
   - Add field to Manager struct: promptParser *prompt.Parser
   - In NewManager() (line ~150-200):
     - After setting m.promptFS and m.promptDir
     - Initialize: m.promptParser = prompt.NewParser(promptFS, promptDir, ".")
   - Replace readPromptFile() implementation (line 516):
     - Old: fs.ReadFile(m.promptFS, promptPath) or os.ReadFile(promptPath)
     - New: result, err := m.promptParser.Render(promptName); return result.Content, result.Files, err
     - Update signature: ([]byte, []string, error) to return file list
   - Update caller at line 450:
     - Old: data, promptPath, err := m.readPromptFile(promptName)
     - New: data, files, err := m.readPromptFile(promptName)
   - Add logging after successful render (line ~470, after prompt injection):
     - m.logger.Info("agent prompt rendered", map[string]string{
         "agent_id": request.AgentID,
         "agent_name": profile.Name,
         "prompt_files": strings.Join(files, ", "),
         "file_count": strconv.Itoa(len(files)),
       })
   - Store file list in session for UI exposure:
     - Add PromptFiles []string field to Session struct
     - Set session.PromptFiles = files after successful render
     - Update SessionInfo struct (for /api/terminals response) to include prompt_files field
   - Error handling: parser errors bubble up same as before (logged at line 453-457)
   - No changes needed to prompt injection logic - already handles byte slices
   Backward compatibility:
   - Existing .txt prompts work unchanged (parser tries .tmpl first, falls back to .txt)
   - Agent configs unchanged (prompt names remain the same)
   - SessionInfo gains new prompt_files field (additive, no breaking change)
   Data flow:
   - Parser renders template → returns RenderResult{Content, Files}
   - Manager logs file list at Info level
   - Manager stores Files in Session.PromptFiles
   - Session serializes to SessionInfo with prompt_files for API
   - Frontend can display prompt composition (see next L2)
   Tests:
   - Integration test: create test .tmpl file with includes, verify:
     - Content injected correctly
     - File list logged at Info level
     - Session.PromptFiles populated
     - /api/terminals response includes prompt_files
   - Regression test: existing .txt prompts still work, file list has one entry
   Done when: Template parser integrated, file list logged and stored, tests pass
   Implementation details:
   - After skill metadata injection, insert a prompt separator line before prompts.

** [#C] Display prompt file list in agent terminal header
   Why: Prompt composition is more interesting than skills; shows what instructions the agent received
   Current state:
   - frontend/src/components/Terminal.svelte shows skills in terminal header (if agent has skills)
   - Skills are loaded via /api/skills?agent=<id>
   - No visibility into prompt composition
   - Session API response includes skills array but no prompt metadata
   Architecture decision: Replace skills display with prompt files display in terminal header
   Change:
   - Backend (already done in previous L2):
     - SessionInfo includes prompt_files []string field
     - /api/terminals response serializes prompt_files for each terminal
   - Frontend: frontend/src/components/Terminal.svelte
     - Current: line ~12 shows skills prop (array of skill names)
     - Change: add promptFiles prop from terminal data
     - Terminal header currently shows skills (if any) below title
     - Replace or augment skills display with prompt files display
   - Frontend: update terminal store to include prompt_files
     - File: frontend/src/lib/terminalStore.js (if it fetches terminal info)
     - Or: ensure /api/terminals response includes prompt_files field
   - UI display decision (architect to specify):
     - Option A: Replace "Skills: X, Y, Z" with "Prompts: file1.tmpl, file2.txt, file3.txt"
     - Option B: Show both skills and prompt files as separate lines
     - Recommendation: Replace skills display with prompt files (per user: "more interesting than skills")
   - Terminal header location:
     - File: frontend/src/components/Terminal.svelte (displays terminal metadata)
     - Current: shows skills if present (check line ~30-50)
     - New: replace or augment with prompt_files display
   Tests:
   - Backend test: verify SessionInfo.PromptFiles serializes correctly
   - Frontend test: verify terminal header shows prompt file list
   Done when: Prompt file list visible in terminal header instead of/alongside skills

** [#B] Comprehensive test coverage for prompt templating
   Why: Template system is foundational; must be robust and well-tested
   Scope: Unit tests, integration tests, edge cases, error conditions
   Change:
   - File: internal/prompt/parser_test.go (unit tests)
     - Test file reading:
       - .txt file (no templating)
       - .tmpl file with no includes
       - Non-existent file (error case)
     - Test include directives:
       - Single include
       - Multiple includes (sequential)
       - Nested includes (include within include)
       - Include with explicit .txt extension
       - Include without extension (auto-append)
       - Include with wrong extension (should fail silently)
       - Include non-existent file (silent fail, not in Files list)
     - Test cycle detection:
       - Direct cycle (A includes A)
       - Indirect cycle (A includes B, B includes A)
       - Deep cycle (A → B → C → A)
       - Max depth limit (depth > 10)
     - Test file list metadata:
       - Order preserved (main file first, then includes in order)
       - Failed includes not in list
       - Nested includes all tracked
       - Deduplicate or allow repeats? (architect to decide)
     - Test whitespace and formatting:
       - Include directive with extra whitespace
       - Include directive with tabs
       - Include directive at start/middle/end of file
       - Empty lines around includes
     - Test error messages:
       - Top-level file not found (descriptive error)
       - Cycle detected (clear error with cycle path)
   - File: internal/terminal/manager_test.go (integration tests)
     - Test prompt injection with templates:
       - Agent with .tmpl prompt (verify rendered content)
       - Agent with .txt prompt (verify backward compat)
       - Agent with .tmpl using includes (verify all files tracked)
       - Verify Session.PromptFiles populated correctly
       - Verify SessionInfo serialization includes prompt_files
     - Test logging:
       - Verify Info log emitted with prompt_files
       - Verify file_count logged correctly
       - Verify log format matches expectations
   - File: internal/prompt/parser_integration_test.go (filesystem integration)
     - Test with real filesystem (not just embed.FS):
       - Create temp dir with .tmpl and .txt files
       - Verify includes resolve correctly
       - Verify file list uses relative paths
     - Test with embed.FS:
       - Verify embedded prompts work
       - Verify override behavior (local files override embedded)
   Test data setup:
   - Create test fixtures in internal/prompt/testdata/:
     - simple.txt (plain file)
     - basic.tmpl (single include)
     - nested.tmpl (multi-level includes)
     - cycle-a.tmpl, cycle-b.tmpl (circular includes)
     - missing-include.tmpl (references non-existent file)
     - common-fragment.txt (reusable fragment)
   Tests: Run go test -v ./internal/prompt/... and verify >90% coverage
   Done when: All test cases implemented, pass consistently, coverage >90%

** [#C] Update AGENTS.md with templating documentation
   Why: Document new capability for future LLMs and developers
   Change:
   - File: AGENTS.md
   - Add new section: "## Prompt templating"
   - Content:
     - Prompt files can be .txt (plain) or .tmpl (templated)
     - Include directive syntax: (syntax from L2 #1)
     - Include resolution: tries .tmpl first, then .txt; tries with/without .txt extension
     - Failed includes are silent (no error)
     - Templates render at agent start, before injection
     - Use cases: shared fragments, DRY prompts, easier maintenance
   - Update "Agent profiles" section:
     - Note that prompt names can reference .tmpl or .txt
     - Backward compatible (existing .txt prompts work unchanged)
   Tests: Manual review of documentation
   Done when: AGENTS.md documents prompt templating clearly

* DONE [#B] UI/UX polish and visual identity improvements
  Goal: Improve user experience with human-readable timestamps, better terminal state feedback, streamlined tab management, branded visual identity, and improved close confirmation.
  Notes:
  - Scope: Frontend only (Svelte components, stores, and static assets)
  - Changes affect: Dashboard, Terminal view, TabBar, App header, timestamp displays
  - New assets: Dyne.org logos (icon + logotype), Gestalt typography logo
  - Backend: no changes required (all REST/WS endpoints already provide necessary data)
  - Visual identity: replace generic UI elements with branded logos from Dyne.org
  - User safety: add confirmation dialog for terminal close to prevent accidental data loss
  - Real-time feedback: ensure terminal state (running/stopped) updates immediately without page refresh
  Date: 2026-01-10

** [#C] Remove unused Tailwind CSS dependency
   Why: Tailwind is installed but never used (~0% adoption); adds 6MB to node_modules and build complexity for no benefit
   Change:
   - Uninstall packages: `npm uninstall tailwindcss autoprefixer postcss`
   - Remove config files: `tailwind.config.js`, `postcss.config.js`
   - Update `frontend/src/app.css`: remove `@tailwind` directives, keep custom CSS
   - Verify build still works: `npm run build`
   - Check bundle size (should be unchanged since utilities aren't used)
   - Update package.json: verify devDependencies are clean
   Notes:
   - Current approach (scoped component styles) is working well and more maintainable
   - Custom CSS is readable, consistent (BEM-ish naming), and performant (38KB / 7.78KB gzipped)
   - Zero Tailwind utilities in codebase (only custom classes like `.agent-grid`)
   Tests: Run `npm run build` and verify CSS bundle size unchanged
   Done when: Tailwind removed, build works, no regressions

** [#C] Add human-readable timestamp formatting utility
   Why: Absolute timestamps (ISO 8601) are hard to scan; relative times (1 minute ago, 2 hours ago) improve readability
   Change:
   - Create `frontend/src/lib/timeUtils.js` with `formatRelativeTime(timestamp)` function
   - Logic:
     - < 1 minute: "just now"
     - < 60 minutes: "X minutes ago"
     - < 24 hours: "X hours ago"
     - < 7 days: "X days ago"
     - >= 7 days: fall back to short date format (e.g., "Jan 8, 2026")
   - Handle both ISO 8601 strings and Date objects
   - Add unit tests in `frontend/src/lib/timeUtils.test.js`
   Tests: Unit tests for edge cases (now, 1 sec, 59 sec, 1 min, 59 min, 1 hour, 23 hours, 1 day, 6 days, 7+ days)
   Done when: Utility function exists, tested, and ready to import

** [#C] Apply human-readable timestamps throughout UI
   Why: Consistency across all views; easier scanning of temporal information
   Change:
   - Import `formatRelativeTime` from timeUtils in relevant components
   - Update timestamp displays in:
     - Dashboard: agent status timestamps, system status
     - FlowView (Status): workflow start/end times, last event times
     - LogsView: log entry timestamps
     - TerminalView: session start time (if displayed)
     - WorkflowCard/WorkflowDetail: all temporal fields
   - Add title attribute with full ISO timestamp for hover tooltip (best of both worlds)
   - Keep backend responses unchanged (ISO 8601); transform in frontend only
   Tests: Visual inspection of all views; verify tooltips show full timestamp
   Done when: All timestamp displays use relative format with hover tooltips

** [#C] Change agent terminal buttons to start or switch (remove stop action)
   Why: Closing terminals from dashboard is error-prone; terminals should only close from terminal view with confirmation
   Root cause analysis:
   - Dashboard.svelte maintains `terminals` array as local state (line 23)
   - Agent running state comes from `/api/agents` response (agent.running field)
   - Dashboard calls `loadAgents()` after stop/create, which re-fetches `/api/agents`
   - Problem: App.svelte also maintains separate `terminals` array from `/api/terminals`
   - These two sources are not synchronized in real-time when terminals close
   Behavioral change:
   - Current: button toggles between "Start" and "Stop", clicking "Stop" closes terminal
   - New: button shows "Start" or "Open", clicking always navigates to terminal (start if stopped, switch if running)
   - Terminal closure: only via close button in TerminalView with confirmation dialog (see L2 #6)
   Change:
   - File: `frontend/src/views/Dashboard.svelte`
   - Add new prop: `export let onSelect = () => {}` (for switching to terminal tabs)
   - Modify `loadAgents()` to cross-reference `terminals` prop (passed from App.svelte)
   - Agent running state logic: `agent.running = terminals.some(t => t.agent_id === agent.id)`
   - Update agent card button (lines 261-272):
     - Current: `agent.running ? stopTerminal(agent.terminal_id) : createTerminal(agent.id)`
     - New: `agent.running ? switchToTerminal(agent.terminal_id) : createTerminal(agent.id)`
     - Button label: `agent.running ? 'Open' : 'Start'`
     - Button class: remove `.agent-button--running` / `.agent-button--stopped` distinction (both are positive actions now)
   - Add `switchToTerminal(terminalId)` function: calls `onSelect(terminalId)` to switch active tab
   - Remove `stopTerminal()` function (no longer needed in Dashboard)
   - Update button styling: both states use same positive action style (no destructive red for "running")
   - File: `frontend/src/App.svelte`
   - Pass `onSelect={handleSelect}` prop to Dashboard component (add to Dashboard component invocation)
   - No terminalStore changes needed (terminalStore manages xterm state, not agent button state)
   Data flow:
   - App.svelte terminals → Dashboard.svelte prop → agent.running computed property
   - Dashboard agent button click → App.svelte onSelect(terminalId) → tab switches to terminal
   Tests:
   - Manual test: agent not running → click "Start" → terminal created and opened
   - Manual test: agent running → click "Open" → switches to existing terminal tab (no close action)
   - Manual test: close terminal via terminal view close button → agent button returns to "Start" state
   Done when: Agent buttons show "Start"/"Open", clicking navigates to terminal, no stop action in dashboard

** [#C] Remove close (X) buttons from terminal tabs
   Why: Accidental clicks cause data loss; tabs are for navigation, not lifecycle management
   Change:
   - Edit `frontend/src/components/TabBar.svelte`
   - Remove X button from each terminal tab (keep tab label clickable for navigation)
   - Tabs become read-only indicators of running terminals (click to switch, but no inline close)
   - Non-terminal tabs (Dashboard, Status, Plan, Logs) stay as-is (no X buttons already)
   Tests: Visual inspection; verify tabs are clickable for navigation but have no X buttons
   Done when: Terminal tabs have no close buttons, remain clickable

** [#B] Add close button with confirmation dialog to terminal view
   Why: Users still need a way to close terminals, but with intentional action and confirmation
   Architecture decision: Use native `<dialog>` element (best accessibility, zero dependencies)
   Change:
   - File: `frontend/src/views/TerminalView.svelte`
   - Add "Close Terminal" button at top-right of terminal view (before Terminal component)
   - Add `<dialog>` element with:
     - `id="close-confirm-dialog"`
     - Title: "Close Terminal?"
     - Message: "This will stop the terminal session. Any unsaved work will be lost."
     - Two buttons: "Close" (autofocus, destructive style) and "Cancel" (secondary style)
   - Button click handler: `dialog.showModal()` to display
   - Focus management: `autofocus` attribute on "Close" button so Enter immediately confirms
   - Keyboard: native dialog handles Escape (closes without action), Enter on focused button
   - Close button handler: emit event to parent or call onDelete callback prop
   - Terminal closure flow: TerminalView receives `onDelete` prop from App.svelte → calls it → App.svelte.deleteTerminal(id)
   - After deletion: App.svelte already navigates to dashboard (line 122: `activeId = 'dashboard'`)
   Styling approach:
   - Scoped `<style>` block in TerminalView.svelte
   - Match existing design system (similar to NotificationSettings modal overlay)
   - Destructive button: red background, white text
   - Cancel button: secondary style (border, transparent bg)
   Tests: Manual test: click close → dialog opens with focus on "Close" → press Enter → terminal closes and navigates to dashboard
   Done when: Close button exists, native dialog works, keyboard navigation correct, terminal closes on confirm

** [#C] Download and add Dyne.org logo assets
   Why: Replace generic "Notifications" button with branded logos for visual identity
   Change:
   - Download logos from dyne.org:
     - Black/transparent icon: https://dyne.org/images/logos/black-transparent-Icon.svg
     - White logotype: https://dyne.org/images/logos/white-Logotype.svg
   - Save to `frontend/src/assets/` (create directory if needed)
   - Name files clearly: `dyne-icon-black.svg`, `dyne-logotype-white.svg`
   - Verify SVGs are valid and render correctly (open in browser)
   Tests: Visual inspection of downloaded SVGs in browser
   Done when: Logo files exist in `frontend/src/assets/`

** [#C] Copy Gestalt typography logo to assets
   Why: Replace "Gestalt" text title with branded SVG logo
   Change:
   - Copy `logosvg/typography/t_glogo_greyonwhite.svg` to `frontend/src/assets/gestalt-logo.svg`
   - Verify SVG renders correctly (check viewBox, width/height attributes)
   - Optional: optimize SVG if it has unnecessary metadata (use svgo or manual cleanup)
   Tests: Visual inspection of logo in browser
   Done when: Gestalt logo exists in `frontend/src/assets/`

** [#C] Replace notifications button with Dyne.org logos in header
   Why: Visual identity; logos are more recognizable than generic button
   Architecture decision: Remove notification settings button entirely (preferences are persisted in localStorage, rarely changed)
   Current state:
   - Notifications button at line 44 in TabBar.svelte (`.tabbar__actions` → `.tabbar__settings`)
   - Button triggers `onOpenSettings()` callback → App.svelte shows NotificationSettings modal
   - NotificationSettings is fully functional but rarely used by users
   Change:
   - File: `frontend/src/components/TabBar.svelte`
   - Replace `.tabbar__actions` section (lines 43-47) with `.tabbar__logos`
   - Add two `<a>` links with external logos:
     - Dyne icon (black): `/assets/dyne-icon-black.svg`, size 28px, link to https://dyne.org, target="_blank"
     - Dyne logotype (white): `/assets/dyne-logotype-white.svg`, height 20px, link to https://dyne.org, target="_blank"
   - Style logos: `display: flex; align-items: center; gap: 1.2rem; margin-left: auto;`
   - Hover effect: `opacity: 0.7` on hover, `transition: opacity 160ms ease`
   - Logo colors: keep as-is (black icon + white logotype work on light background)
   - Remove `onOpenSettings` prop from TabBar (line 8)
   - File: `frontend/src/App.svelte`
   - Remove `showSettings` state variable (line 27)
   - Remove `openSettings` and `closeSettings` functions (lines 149-156)
   - Remove `onOpenSettings={openSettings}` prop from TabBar (line 173)
   - Remove `<NotificationSettings>` component (line 175)
   - Keep NotificationSettings.svelte file (users can still open via browser devtools or future settings page)
   Notification preferences remain functional:
   - notificationStore and notificationPreferences persist in localStorage
   - Toast behavior continues working with saved preferences
   - Advanced users can edit localStorage directly if needed
   Tests: Visual inspection; verify logos render correctly, link to dyne.org, open in new tab
   Done when: Notifications button removed, logos visible and clickable, no console errors

** [#C] Replace "Gestalt" text title with typography logo
   Why: Consistent visual branding; professional appearance
   Current state:
   - Brand area is in TabBar.svelte (lines 12-20)
   - `.tabbar__brand` button contains `.tabbar__brand-title` (text "Gestalt") and `.tabbar__brand-by` (version)
   - Button already clickable and navigates to dashboard via `onSelect('dashboard')`
   Change:
   - File: `frontend/src/components/TabBar.svelte`
   - Replace line 18 (`<span class="tabbar__brand-title">Gestalt</span>`) with:
     `<img src="/assets/gestalt-logo.svg" alt="Gestalt" class="tabbar__brand-logo" />`
   - Update CSS `.tabbar__brand-title` → `.tabbar__brand-logo`:
     - `height: 24px;` (matches text height)
     - `width: auto;`
     - `display: block;`
     - Remove font-size, font-weight, letter-spacing, text-transform
   - Keep `.tabbar__brand-by` (version) as-is for visual balance
   - Keep button behavior (click → dashboard) unchanged
   - Verify logo SVG has proper viewBox for scaling
   Tests: Visual inspection; verify logo renders at correct size, aligns with version text, click navigates to dashboard
   Done when: Text title replaced with SVG logo, button still functional, visual alignment correct

** [#C] Rename "Flow" tab to "Status"
   Why: "Status" is clearer and more descriptive of workflow monitoring content
   Current state:
   - Tab defined in App.svelte line 19: `{ id: 'flow', label: 'Flow', isHome: true }`
   - Also in `syncTabs` function line 43 (duplicate definition)
   - Tab ID 'flow' used in routing logic (lines 32-37)
   - Component import: FlowView (line 4)
   Change:
   - File: `frontend/src/App.svelte`
   - Line 19: change `label: 'Flow'` to `label: 'Status'`
   - Line 43: change `label: 'Flow'` to `label: 'Status'`
   - Keep `id: 'flow'` unchanged (internal routing ID, no user-facing impact)
   - Keep FlowView component name unchanged (internal, no user-facing impact)
   - No URL changes needed (activeId drives routing, not labels)
   Rationale for keeping id='flow':
   - Changing IDs would require localStorage migration (if any saved state uses it)
   - Label is user-facing; ID is internal implementation detail
   - Minimal change principle: only touch what users see
   Tests: Visual inspection; verify tab label shows "Status", click navigates to workflow view
   Done when: Tab label displays "Status", routing unchanged, no regressions

** [#C] Enlarge header logotype
   Why: The brand mark should match the header height for stronger visual presence.
   Change:
   - Increase the Gestalt logotype height in `frontend/src/components/TabBar.svelte`
   Tests: Manual visual check
   Done when: The logotype matches the header height

** [#B] Fix dashboard running-state and remove workflow toggle
   Why: Running agents should show a live state indicator and workflow tracking is always on.
   Change:
   - Restore running-state highlighting for running agents in `frontend/src/views/Dashboard.svelte`
   - Sync running state using agent terminal IDs instead of terminal agent IDs
   - Remove the "Enable workflow tracking" checkbox and related state, always using default workflow behavior
   Tests: Manual smoke check
   Done when: Running agents highlight correctly and the workflow toggle is gone

** [#B] Fix terminal view resizing and PTY fit
   Why: Narrow layouts clip header controls and input actions, and the PTY needs correct sizing.
   Change:
   - Update terminal header layout to wrap without clipping in `frontend/src/components/Terminal.svelte`
   - Update command input layout to keep actions visible on narrow widths in `frontend/src/components/CommandInput.svelte`
   - Add a ResizeObserver to trigger `scheduleFit()` when the terminal container width changes
   Tests: Manual resize smoke check; verify PTY resizes (columns) and controls remain visible
   Done when: Header/actions remain accessible and terminal content fits after resizing

** [#C] Stop terminal-created toasts and log the event
   Why: Terminal creation should not interrupt users with a toast, but still be traceable in logs.
   Change:
   - Remove the info toast emitted after terminal creation in `frontend/src/App.svelte`
   - Log the creation event to the console with terminal id/name
   Tests: Manual smoke check; no toast appears when starting a terminal
   Done when: Terminal create no longer triggers a toast; a console log entry records it

** [#C] Restore dashboard running-state styling
   Why: Users need an immediate visual indicator when an agent is running.
   Change:
   - Reintroduce a running-state class for agent cards in `frontend/src/views/Dashboard.svelte`
   - Keep button action as Start/Open only (no stop action)
   Tests: Manual smoke check; running agents show the highlighted state
   Done when: Agent buttons visibly indicate running state again

** [#B] Move terminal close control into terminal header
   Why: The close action should live inside the terminal canvas next to the Bell indicator.
   Change:
   - Remove the standalone header/close button in `frontend/src/views/TerminalView.svelte`
   - Add a close button in `frontend/src/components/Terminal.svelte` positioned to the right of Bell
   - Wire the button to open the existing confirmation dialog in TerminalView
   Tests: Manual smoke check; close button appears in terminal header and opens the dialog
   Done when: Close button sits in the terminal header and triggers confirmation

** [#C] Fix header logo asset loading
   Why: Header SVGs should load reliably in Vite builds.
   Change:
   - Import logo assets in `frontend/src/components/TabBar.svelte` instead of using `/assets/...` URLs
   Tests: Manual smoke check; header logos render in dev and build
   Done when: Logos render correctly without broken asset URLs

** [#C] Add make dev target for live preview
   Why: Provide a single command to run the Go backend and Vite dev server with live UI updates.
   Change:
   - Add a `dev` target in `GNUmakefile` that runs the Go server and `npm run dev` concurrently
   - Ensure the backend runs on port 8080 to match the Vite proxy
   Tests: Manual smoke check; edits in `frontend/src` hot-reload in the GUI
   Done when: `make dev` starts both servers and the UI updates live

* TODO [#A] Comprehensive architecture and code quality review
  Goal: Conduct a thorough review of the entire Gestalt codebase (backend + frontend) to identify opportunities for simplification, improved maintainability, better readability, dependency reduction, and architectural improvements.
  Notes:
  - Scope: Every internal package, command, frontend component, and external dependency
  - Current state: ~14k LOC backend (Go), ~4.4k LOC frontend (Svelte), 67% avg test coverage
  - Dependencies: Minimal (4 Go deps, 2 npm deps) - good foundation to maintain
  - Focus areas: code clarity, separation of concerns, reducing coupling, eliminating redundancy
  - Approach: component-by-component analysis with concrete improvement proposals
  - Changes can range from small refactors to full component rewrites if justified
  - Preserve: existing functionality, test coverage, backward compatibility where possible
  - Outcome: prioritized list of improvements with effort estimates and impact assessment
  - This is a planning and analysis L1; implementation will be separate follow-up work
  Date: 2026-01-08

  Context for implementation:
  - Gestalt is a multi-terminal dashboard with AI agent profiles and skills
  - Core value: orchestrate multiple terminal sessions with agent coordination
  - Architecture: Go HTTP/WS server + Svelte SPA frontend
  - Key components: PTY management, WebSocket streaming, agent profiles, skill system
  - Recent additions: filesystem watching, input history, org-mode viewer, logging system
  - Quality baseline: good test coverage, minimal deps, modular structure
  - Pain points to investigate: coupling, complexity, unclear boundaries, potential over-engineering

** TODO [#A] Review and document current architecture
   Why: Need complete understanding before proposing changes; establish baseline
   Change:
   - Document current architecture in detail:
     - Backend: 9 internal packages (agent, api, logging, orchestrator, skill, terminal, version, watcher, plus root)
     - Frontend: 4 views, 8 components, 5 lib modules
     - Data flow: REST API, WebSocket streams, embedded resources, config files
     - State management: backend (Manager holds sessions), frontend (Svelte stores)
   - Create architecture diagram (text-based or mermaid) showing:
     - Component dependencies and communication paths
     - Data flow: user → frontend → API → terminal → PTY
     - WebSocket fan-out pattern (broadcaster → multiple subscribers)
     - Config loading: embedded → external override → env vars
   - Identify architectural patterns in use:
     - Manager pattern (terminal.Manager), Hub pattern (watcher.EventHub)
     - Circular buffers (output/input buffers)
     - Fan-out/broadcast (WebSocket, event hub)
     - Embedded resources with override (embed.FS)
   - Document key design decisions and their rationale
   - List implicit coupling and hidden dependencies
   - Measure: lines of code per component, cyclomatic complexity (if tools available)
   Tests: None (documentation only)
   Done when: Complete architecture documented with diagrams and metrics

** TODO [#B] Analyze internal/terminal package (850 LOC, core domain)
   Why: Largest and most complex internal package; core business logic
   Change:
   - Review files: session.go, manager.go, pty.go, broadcaster.go, input_buffer.go, output_buffer.go, persistence.go, input_logger.go
   - Session struct: 20+ fields, 3 goroutines - is this too complex?
   - Manager: CRUD for sessions + agent tracking - single responsibility?
   - Broadcaster: fan-out pattern - could be extracted to reusable utility?
   - Buffers: circular buffer pattern repeated twice (input/output) - DRY opportunity?
   - Persistence: async file logging - is this pattern reusable for other logs?
   - PTY handling: OS-specific (pty_unix.go, pty_windows.go) - stub on Windows, document or implement ConPTY?
   - Questions to answer:
     - Can Session be split into smaller types? (SessionState, SessionIO, SessionLifecycle?)
     - Is Manager doing too much? (session registry vs lifecycle vs agent tracking)
     - Are the 3 goroutines per session necessary? Can any be combined?
     - Should Broadcaster be promoted to internal/broadcast package?
     - Can input/output buffers share a generic circular buffer implementation?
   - Coverage: 74.2% - identify untested paths and why
   - Proposed improvements: extract, simplify, reduce goroutine count, clearer boundaries
   Tests: Ensure refactoring maintains coverage
   Done when: Detailed analysis with concrete improvement proposals documented

** TODO [#B] Analyze internal/api package (1100+ LOC, HTTP/WS layer)
   Why: Second largest package; handles all HTTP and WebSocket traffic
   Change:
   - Review files: routes.go, rest.go, terminal_handler.go, logs_handler.go, events_handler.go, spa.go, middleware.go
   - Current structure: handlers mixed with routing, validation, and business logic
   - REST endpoints: ~15 endpoints in rest.go - is this file too large?
   - WebSocket handlers: 3 separate files (terminal, logs, events) - consistent pattern?
   - Middleware: auth middleware in separate file - good, but is it sufficient?
   - SPA handler: custom fallback logic - could this be simpler?
   - Questions to answer:
     - Should REST handlers be split by domain? (terminals.go, agents.go, skills.go, logs.go, plan.go)
     - Is error handling consistent across all endpoints?
     - Are validation patterns repeated? Extract to shared validators?
     - Do WebSocket handlers share common patterns? Extract base WebSocket handler?
     - Is middleware testable in isolation?
   - Dependencies: gorilla/websocket - is this necessary or can stdlib x/net/websocket suffice?
   - Coverage: 64.9% - lower than average, why? Handler testing complexity?
   - Proposed improvements: split by domain, extract validators, reduce duplication
   Tests: Add integration tests for missing coverage
   Done when: API layer analyzed with refactoring proposals

** TODO [#B] Analyze internal/watcher package (1426 LOC, filesystem monitoring)
   Why: Recent addition, significant size, uses fsnotify, complex coordination
   Change:
   - Review files: watcher.go (550 LOC!), hub.go, git.go, types.go + tests
   - Watcher.go is largest single file - is it doing too much?
   - EventHub: pub/sub pattern - clean design or over-engineered for current needs?
   - Git watching: branch detection - is this separate concern from file watching?
   - Questions to answer:
     - Can watcher.go be split? (WatcherCore, WatcherCoordination, WatcherCleanup?)
     - Is EventHub necessary or could simpler callback pattern work?
     - Should git watching be separate package? (internal/git)
     - Is debouncing logic complex? Could it be simplified?
     - Are 100 max watches sufficient? Is this limit well-enforced?
   - Dependency: fsnotify (only ~9k lines) - well-justified for cross-platform
   - Coverage: 63.9% - lowest backend coverage, integration test heavy?
   - Proposed improvements: split large file, simplify if over-designed, better tests
   Tests: Unit tests for watcher logic separate from integration tests
   Done when: Watcher package analyzed with simplification opportunities identified

** TODO [#C] Analyze internal/agent package (400 LOC, agent profiles)
   Why: Core domain model, high coverage (85%), well-tested
   Change:
   - Review files: agent.go, loader.go + tests
   - Agent struct: simple data model with validation - clean design
   - Loader: reads JSON files, validates, returns map - straightforward
   - Questions to answer:
     - Is validation complete and correct?
     - Is error handling helpful for users?
     - Should agent name uniqueness be enforced at load or elsewhere?
     - Is prompt name resolution in the right place?
   - Coverage: 85% - excellent, what's missing?
   - Proposed improvements: likely minimal, validate completeness
   Tests: Review test quality, add edge cases if needed
   Done when: Agent package reviewed, minor improvements identified if any

** TODO [#C] Analyze internal/skill package (350 LOC, Agent Skills)
   Why: Domain model for skills, YAML parsing, prompt generation
   Change:
   - Review files: skill.go, loader.go, prompt.go + tests
   - Skill struct: YAML frontmatter + markdown body - clean
   - Loader: scans directories, parses SKILL.md files - similar to agent loader
   - Prompt generation: XML output for LLM context - is format optimal?
   - Questions to answer:
     - Is YAML parsing robust? (using gopkg.in/yaml.v3)
     - Should skill/agent loaders share common base code? (both scan dirs, parse, validate)
     - Is XML generation testable? Are there edge cases?
     - Is skill metadata complete for agentskills.io spec?
   - Dependency: gopkg.in/yaml.v3 - well-justified for YAML parsing
   - Coverage: 80.5% - good, what's untested?
   - Proposed improvements: extract common loader pattern if beneficial
   Tests: Ensure YAML edge cases covered
   Done when: Skill package reviewed with improvement proposals

** TODO [#C] Analyze internal/logging package (200 LOC, structured logging)
   Why: Recent addition, circular buffer, WebSocket streaming
   Change:
   - Review files: logger.go, buffer.go + tests
   - LogBuffer: circular buffer pattern (same as terminal buffers) - DRY opportunity?
   - Logger: structured fields (map[string]string) - sufficient or needs types?
   - WebSocket streaming: integrated with api package - clean separation?
   - Questions to answer:
     - Should circular buffer be extracted to internal/buffer package?
     - Is structured logging interface sufficient for all use cases?
     - Should log levels be enum/constants instead of strings?
     - Is buffer size (1000 entries) appropriate?
   - Coverage: 73% - what's missing?
   - Proposed improvements: extract buffer, strengthen types
   Tests: Concurrent logging tests
   Done when: Logging package analyzed with reuse opportunities identified

** TODO [#C] Analyze internal/orchestrator package (empty stub)
   Why: Placeholder for future inter-terminal communication
   Change:
   - Review: currently empty, only doc.go with intent
   - Questions to answer:
     - Is this needed now? Should it be removed?
     - What will orchestrator do? (design future features)
     - Will it become complex? Plan for simplicity early
   - Proposed improvements: remove if unused, or sketch minimal design
   Tests: None currently
   Done when: Decision made on orchestrator future (keep stub or remove)

** TODO [#C] Analyze internal/version package (5 LOC, version string)
   Why: Minimal package, check if necessary
   Change:
   - Review: single var Version string for ldflags injection
   - Questions to answer:
     - Does this need to be a separate package?
     - Could version be in main package?
   - Proposed improvements: keep as-is (clean separation) or inline
   Tests: None needed
   Done when: Version package reviewed (likely no changes)

** TODO [#B] Analyze cmd/gestalt (910 LOC, main entrypoint)
   Why: Largest command file, wires everything together
   Change:
   - Review files: main.go, completion.go, extract.go, config_fs.go + tests
   - Main.go: config loading, agent/skill loading, manager creation, server start
   - Questions to answer:
     - Is main.go too long? Should initialization be extracted?
     - Config loading: is loadConfig() function clear and testable?
     - Should config have its own package? (internal/config)
     - Are subcommands (validate-skill, extract-config, completion) well-organized?
     - Is flag parsing clean? (will improve in CLI L1)
   - Coverage: 54.3% - low for main, acceptable or improve?
   - Proposed improvements: extract initialization, clarify config, simplify main flow
   Tests: More config loading tests
   Done when: Main entrypoint analyzed with simplification proposals

** TODO [#B] Analyze cmd/gestalt-send (761 LOC, CLI tool)
   Why: Separate binary, client-side tool, moderate complexity
   Change:
   - Review files: main.go, completion support, agent resolution, HTTP client
   - Main.go: flag parsing, agent resolution, HTTP POST, completion generation
   - Agent resolution: fetches /api/agents, matches name/id - is caching robust?
   - Questions to answer:
     - Is error handling clear and helpful?
     - Are exit codes consistent with conventions?
     - Is agent resolution logic too complex for CLI tool?
     - Should HTTP client logic be extracted to package?
     - Is completion generation maintainable?
   - Coverage: 48.9% - lowest, is this acceptable for CLI?
   - Proposed improvements: simplify agent resolution, improve error messages
   Tests: More CLI integration tests
   Done when: gestalt-send analyzed with UX improvement proposals

** TODO [#B] Analyze frontend architecture (4357 LOC, Svelte SPA)
   Why: Entire frontend needs review for consistency and simplicity
   Change:
   - Review structure:
     - Views: Dashboard, PlanView, LogsView, TerminalView (4 main views)
     - Components: Terminal, TabBar, Toast, OrgViewer, CommandInput, etc (8 components)
     - Libs: api.js, terminalStore.js, eventStore.js, notificationStore.js, orgParser.js, terminalTabs.js (6 modules)
   - Questions to answer:
     - Is component hierarchy clear? Are responsibilities well-defined?
     - Do views mix too much logic? Should business logic move to stores?
     - Are Svelte stores used consistently? (writable, readable, derived)
     - Is terminalStore.js too large (660 LOC)? Can it be split?
     - Are there repeated patterns that could be extracted?
     - Is error handling consistent across components?
     - Are API calls centralized properly?
   - State management: is it clear where state lives and how it flows?
   - Proposed improvements: extract logic from views, simplify stores, reduce component size
   Tests: Frontend has tests but coverage unknown, identify gaps
   Done when: Frontend architecture analyzed with refactoring proposals

** TODO [#B] Analyze frontend/src/lib (store and utility modules)
   Why: Core frontend logic, state management, API client
   Change:
   - Review files:
     - api.js (63 LOC): HTTP/WS URL building, fetch wrapper - clean and minimal
     - terminalStore.js (660 LOC): HUGE - xterm management, WebSocket, input handling
     - eventStore.js (144 LOC): filesystem event WebSocket - clean
     - notificationStore.js (185 LOC): toast notifications - clean
     - orgParser.js (85 LOC): Org-mode parsing - minimal parser, good
     - terminalTabs.js (7 LOC): unused? just exports writable, may be obsolete
   - terminalStore.js deep dive:
     - Manages xterm instance, WebSocket, input modes, history, focus, scrolling
     - Is this too much? Split into: xtermManager.js, terminalWebSocket.js, terminalInput.js?
     - Can WebSocket reconnection logic be shared with eventStore?
     - Is input mode toggle (direct vs command box) too complex?
   - Questions to answer:
     - Should terminal state be split into multiple stores?
     - Can WebSocket connection logic be extracted to wsClient.js?
     - Is terminalTabs.js used? Remove if not
     - Are stores reactive enough? Any unnecessary re-renders?
   - Proposed improvements: split terminalStore, extract WebSocket client, remove dead code
   Tests: Add unit tests for store logic
   Done when: Frontend lib modules analyzed with refactoring plan

** TODO [#B] Analyze frontend components (largest: Terminal 347 LOC, CommandInput 332 LOC)
   Why: Components are UI building blocks, need to be maintainable
   Change:
   - Review each component:
     - Terminal.svelte (347 LOC): xterm rendering, WebSocket connection, input handling
     - CommandInput.svelte (332 LOC): multiline input, history navigation, direct input toggle
     - OrgViewer.svelte (244 LOC): org-mode rendering, filtering, expanding
     - OrgNode.svelte (208 LOC): recursive org-mode node rendering
     - NotificationSettings.svelte (182 LOC): toast preferences UI
     - TabBar.svelte (157 LOC): tab navigation, close buttons
     - Toast.svelte (137 LOC): individual toast notification
     - ToastContainer.svelte (46 LOC): toast positioning and stacking
     - TerminalView.svelte (44 LOC): thin wrapper for Terminal component
   - Questions to answer:
     - Is Terminal.svelte doing too much? (WebSocket + xterm + layout)
     - Should Terminal be split into Terminal (layout) + XtermCanvas (xterm only)?
     - Is CommandInput too complex? Can it be simplified?
     - Are OrgViewer/OrgNode well-factored? (recursive component pattern)
     - Can any components be further decomposed?
     - Is component communication clean? (props down, events up)
     - Are there repeated patterns? (WebSocket connection, error handling)
   - Proposed improvements: simplify large components, extract sub-components
   Tests: Component tests for complex logic
   Done when: All components reviewed with simplification proposals

** TODO [#B] Analyze frontend views (4 main views, thin layer over components)
   Why: Views coordinate components, should be minimal
   Change:
   - Review each view:
     - Dashboard.svelte: agent list, skills display, recent logs, status
     - PlanView.svelte: OrgViewer wrapper, refresh button, event subscription
     - LogsView.svelte: log filtering, auto-refresh, log list rendering
     - TerminalView.svelte: thin wrapper, just passes props to Terminal
   - Questions to answer:
     - Are views thin enough? (ideally < 100 LOC)
     - Do views have business logic that should move to stores?
     - Is Dashboard too complex? (shows agents, skills, logs)
     - Can view logic be extracted to composable functions?
   - Proposed improvements: move logic to stores, simplify views
   Tests: View rendering tests
   Done when: Views analyzed, logic extraction opportunities identified

** TODO [#B] Analyze Go dependencies (4 external, all justified?)
   Why: Minimize dependencies for maintainability and security
   Change:
   - Review each dependency:
     - github.com/creack/pty v1.1.21 (REQUIRED: cross-platform PTY, no stdlib alternative)
     - github.com/gorilla/websocket v1.5.3 (QUESTION: can we use golang.org/x/net/websocket or stdlib?)
     - github.com/fsnotify/fsnotify v1.9.0 (REQUIRED: cross-platform fs watching, stdlib has none)
     - gopkg.in/yaml.v3 v3.0.1 (REQUIRED: YAML parsing for skills, no stdlib alternative)
   - Deep dive on gorilla/websocket:
     - What features does gestalt use? (control frames, origin checking, binary/text messages)
     - Can stdlib (removed) or x/net/websocket provide these?
     - Is migration effort worth the dependency reduction?
     - Decision: likely keep gorilla (production-ready, widely used), but verify
   - Transitive deps: golang.org/x/sys (from pty/fsnotify, acceptable)
   - Proposed improvements: investigate gorilla alternatives, document decisions
   Tests: No changes unless migration happens
   Done when: Dependencies reviewed, justified, migration assessed

** TODO [#C] Analyze frontend dependencies (2 + dev deps)
   Why: Frontend is already minimal, but verify necessity
   Change:
   - Production dependencies:
     - @xterm/xterm (REQUIRED: terminal emulator, core feature)
     - @xterm/addon-fit (CONVENIENCE: 10 lines of math, could inline but not worth it)
   - Dev dependencies: vite, svelte, testing-library, vitest, tailwind, postcss (all justified for dev)
   - Questions to answer:
     - Is addon-fit worth keeping? (yes, 10 lines but tested and maintained)
     - Are all tailwind utilities used? (yes, recently added)
     - Any unused dev deps? (check for obsolete testing or build tools)
   - Proposed improvements: likely none, already minimal
   Tests: No changes
   Done when: Frontend deps reviewed and justified

** TODO [#B] Identify code duplication and extraction opportunities
   Why: DRY principle - reduce maintenance burden
   Change:
   - Search for duplication patterns:
     - Circular buffers: OutputBuffer, InputBuffer, LogBuffer - extract generic Buffer[T]?
     - Async file loggers: SessionLogger, InputLogger - extract generic AsyncFileLogger?
     - Config loading: agent loader, skill loader - extract common dirScanner/jsonLoader?
     - WebSocket patterns: terminal, logs, events handlers - extract base wsHandler?
     - Frontend WebSocket clients: terminalStore, eventStore - extract wsClient?
     - Error handling: repeated patterns in API handlers - extract errorResponder?
   - Measure duplication:
     - Identify repeated code blocks (>10 lines similar)
     - Calculate potential LOC reduction
   - Assess extraction value:
     - Will abstraction simplify or complicate?
     - Is pattern used 3+ times? (rule of three)
     - Will it reduce bugs or increase cognitive load?
   - Proposed improvements: prioritize high-value extractions
   Tests: Ensure extracted code is well-tested
   Done when: Duplication catalog created with extraction proposals

** TODO [#B] Review error handling consistency
   Why: Poor error handling leads to unclear failures and debugging difficulty
   Change:
   - Backend error handling review:
     - Are errors wrapped with context? (fmt.Errorf with %w)
     - Are errors logged at appropriate levels?
     - Are HTTP error responses consistent? (status codes, JSON structure)
     - Are panics avoided? (use recover only in critical goroutines)
     - Are errors tested? (error paths have test coverage)
   - Frontend error handling review:
     - Are API errors caught and displayed to user?
     - Are network errors retried appropriately?
     - Are WebSocket disconnections handled gracefully?
     - Are errors logged to console for debugging?
     - Do users see helpful error messages?
   - Questions to answer:
     - Should we use pkg/errors for error wrapping? (stdlib %w is sufficient)
     - Should API errors have error codes? (for programmatic handling)
     - Should frontend have centralized error handler?
   - Proposed improvements: consistent error patterns, better user messages
   Tests: Error path test coverage
   Done when: Error handling reviewed, consistency proposals documented

** TODO [#B] Review testing strategy and coverage gaps
   Why: Tests prevent regressions and document behavior
   Change:
   - Current coverage analysis:
     - cmd/gestalt: 54.3% - low, but main is hard to test
     - cmd/gestalt-send: 48.9% - low for CLI, integration-heavy
     - internal/agent: 85.0% - excellent
     - internal/api: 64.9% - acceptable, integration tests exist
     - internal/logging: 73.0% - good
     - internal/skill: 80.5% - good
     - internal/terminal: 74.2% - good
     - internal/watcher: 63.9% - low, complex integration tests
   - Identify untested paths:
     - What's not covered in each package?
     - Are tests integration-heavy or unit-heavy?
     - Are error paths tested?
     - Are edge cases covered?
   - Review test quality:
     - Are tests readable and maintainable?
     - Do tests use table-driven patterns?
     - Are tests isolated or do they share state?
     - Are integration tests reliable?
   - Frontend testing:
     - Are components tested?
     - Are stores tested?
     - Are API mocks used?
     - Is coverage measured?
   - Proposed improvements: target 80% coverage, add missing tests
   Tests: This is meta-testing review
   Done when: Coverage gaps identified, test improvement plan created

** TODO [#A] Create prioritized improvement roadmap
   Why: Consolidate all analysis into actionable plan
   Change:
   - Compile all findings from previous L2 steps
   - Categorize improvements:
     - Quick wins: <1 day effort, high impact (rename, extract small function, add test)
     - Medium refactors: 1-3 days, medium-high impact (split large file, extract pattern)
     - Large refactors: 1+ weeks, high impact (redesign component, migrate dependency)
   - Prioritize by:
     - Impact: simplification, maintainability, readability, performance
     - Risk: breaking changes, test coverage, complexity
     - Effort: time to implement and test
   - Create matrix: Impact (H/M/L) x Effort (H/M/L) → priority
   - Propose implementation order:
     - Phase 1: Quick wins and high-impact/low-effort improvements
     - Phase 2: Medium refactors with clear value
     - Phase 3: Large refactors if justified
   - Document each improvement:
     - What: specific change
     - Why: problem it solves
     - How: implementation approach
     - Effort: estimated time
     - Risk: what could break
     - Tests: what tests to add/modify
   - Create follow-up L1 work plans for top priorities
   Tests: N/A (planning)
   Done when: Prioritized roadmap with detailed improvement proposals ready for implementation

* DONE [#B] Improve CLI tools with proper flags and help
  Goal: Add comprehensive --help documentation and command-line flags to gestalt, gestalt-desktop, and gestalt-send, with flags named after env vars (lowercase) and CLI flags overriding env vars.
  Notes:
  - Current state: gestalt has no CLI flags (only env vars), gestalt-send has minimal flags
  - Desired: all three tools have consistent CLI flag interface
  - Flag naming: lowercase version of env vars (GESTALT_PORT → --port)
  - Priority: CLI flags override env vars override defaults
  - Use Go stdlib flag package (already in use) for consistency
  - Help text: --help shows all flags, env var names, defaults, descriptions
  - Version flag: --version prints version and exits
  - Subcommands: gestalt validate-skill, gestalt completion (for shell completion)
  - Error handling: clear error messages, proper exit codes
  - Testing: add CLI flag parsing tests, verify env var override behavior
  - Documentation: update README with CLI flag examples
  - Keep backward compatibility: existing env var usage unchanged
  - Future: consider cobra/viper for richer CLI (defer unless needed)
  Date: 2026-01-08

** [#B] Define consistent CLI flag structure and conventions
   Why: Need unified approach across all three binaries before implementation
   Change:
   - Document flag naming convention: GESTALT_FOO_BAR → --foo-bar
   - Document priority: CLI flag > env var > default
   - Define help text format: "Description (env: GESTALT_FOO, default: value)"
   - Define common flags for all tools: --help, --version, --verbose
   - Define tool-specific flags: gestalt (server config), gestalt-send (client config)
   - Define exit codes: 0 (success), 1 (usage error), 2 (runtime error), 3 (network error)
   - Decide on subcommand structure: keep gestalt validate-skill, add gestalt completion
   - Document in internal notes or TESTING.md
   Tests: None (documentation only)
   Done when: CLI conventions documented and agreed upon

** [#B] Add flag package and help infrastructure to gestalt
   Why: gestalt currently has no CLI flag parsing, only env vars
   Change:
   - Update cmd/gestalt/main.go to use flag.FlagSet
   - Create flags for all GESTALT_* env vars:
     - --port (GESTALT_PORT, default: 8080)
     - --shell (GESTALT_SHELL, default: system shell)
     - --token (GESTALT_TOKEN, default: empty)
     - --session-persist (GESTALT_SESSION_PERSIST, default: true)
     - --session-dir (GESTALT_SESSION_DIR, default: .gestalt/sessions)
     - --session-buffer-lines (GESTALT_SESSION_BUFFER_LINES, default: 1000)
     - --session-retention-days (GESTALT_SESSION_RETENTION_DAYS, default: 7)
     - --input-history-persist (GESTALT_INPUT_HISTORY_PERSIST, default: true)
     - --input-history-dir (GESTALT_INPUT_HISTORY_DIR, default: .gestalt/input-history)
     - --max-watches (GESTALT_MAX_WATCHES, default: 100)
   - Add common flags: --help, --version, --verbose
   - Parse flags before env vars in loadConfig()
   - Update Config struct to track source (flag vs env vs default) for debugging
   - Keep existing env var behavior as fallback
   Tests: Unit tests for flag parsing, priority order
   Done when: gestalt accepts all config via CLI flags

** [#B] Implement comprehensive --help for gestalt
   Why: Users need to discover available options without reading README
   Change:
   - Implement custom flag.Usage function for gestalt
   - Help format:
     ```
     Usage: gestalt [options]

     Gestalt multi-terminal dashboard with agent profiles

     Options:
       --port PORT                  HTTP server port (env: GESTALT_PORT, default: 8080)
       --shell SHELL                Default shell command (env: GESTALT_SHELL, default: system shell)
       --token TOKEN                Auth token for REST/WS (env: GESTALT_TOKEN, default: none)
       --session-persist            Persist terminal sessions to disk (env: GESTALT_SESSION_PERSIST, default: true)
       --session-dir DIR            Session log directory (env: GESTALT_SESSION_DIR, default: .gestalt/sessions)
       ...
       --help                       Show this help message
       --version                    Print version and exit

     Subcommands:
       gestalt validate-skill PATH  Validate an Agent Skill directory or SKILL.md file
       gestalt completion SHELL     Generate shell completion script (bash, zsh)

     Environment variables override defaults; CLI flags override environment variables.
     ```
   - Show defaults and env var names for each flag
   - Group related flags (server config, session config, etc)
   - Add examples section at bottom (optional)
   Tests: Manual test --help output, verify formatting
   Done when: gestalt --help shows comprehensive documentation

** [#B] Add --version flag to gestalt
   Why: Users need to check installed version easily
   Change:
   - Add --version flag to gestalt flag set
   - If --version specified: print version and exit 0
   - Version format: "gestalt version X.Y.Z" or "gestalt dev" (if not built with VERSION)
   - Print to stdout (not stderr) for scripting
   - Handle --version before other processing (early exit)
   Tests: Test --version output matches version.Version
   Done when: gestalt --version prints version and exits

** [#B] Refactor gestalt-send to use consistent flag naming
   Why: gestalt-send uses --url/--token, should match naming convention
   Change:
   - Rename flags to match env vars (already close):
     - Keep --url (env: GESTALT_URL)
     - Keep --token (env: GESTALT_TOKEN)
     - Keep --start, --verbose, --debug (no env equivalent)
   - Add --help flag with comprehensive documentation
   - Add --version flag
   - Update flag descriptions to include env var names and defaults
   - Update fs.Usage function with better formatting
   Tests: Update gestalt-send tests for new flag behavior
   Done when: gestalt-send flags follow conventions

** [#B] Implement comprehensive --help for gestalt-send
   Why: gestalt-send help is minimal, needs improvement
   Change:
   - Expand fs.Usage function with full documentation
   - Help format:
     ```
     Usage: gestalt-send [options] <agent-name-or-id>

     Send stdin to a running Gestalt agent terminal

     Options:
       --url URL        Gestalt server URL (env: GESTALT_URL, default: http://localhost:8080)
       --token TOKEN    Auth token (env: GESTALT_TOKEN, default: none)
       --start          Auto-start agent if not running
       --verbose        Show request/response details
       --debug          Show detailed debug info (implies --verbose)
       --help           Show this help message
       --version        Print version and exit

     Arguments:
       agent-name-or-id  Agent name or ID to send input to

     Examples:
       cat file.txt | gestalt-send copilot
       echo "status" | gestalt-send --start architect
       gestalt-send --url http://remote:8080 --token abc123 agent-id

     Exit codes:
       0  Success
       1  Usage error
       2  Agent not running
       3  Network or server error
     ```
   - Include examples and exit codes
   - Show env var names and defaults
   Tests: Manual test --help output
   Done when: gestalt-send --help shows comprehensive documentation

** [#B] Add --version flag to gestalt-send
   Why: Consistency with gestalt, users need version info
   Change:
   - Add --version flag to gestalt-send
   - Version comes from internal/version.Version (already compiled in)
   - Handle --version before other processing
   - Version format: "gestalt-send version X.Y.Z"
   Tests: Test --version output
   Done when: gestalt-send --version prints version and exits

** [#B] Create gestalt-desktop CLI with same flag structure
   Why: Desktop app needs same CLI interface as web mode for consistency
   Change:
   - When implementing cmd/gestalt-desktop, use same flag structure as gestalt
   - All GESTALT_* env vars become CLI flags
   - Additional desktop-specific flags:
     - --window-width (default: 1400)
     - --window-height (default: 900)
     - --no-window (run headless with server only, for testing)
   - Same --help, --version flags
   - Same subcommands: validate-skill, completion
   - Same Config struct and loadConfig pattern
   - This step is for the Wails L1 implementation
   Tests: gestalt-desktop --help shows all options
   Done when: Desktop CLI matches web CLI conventions (defer to Wails L1)

** [#C] Add shell completion subcommand to gestalt
   Why: Improve CLI UX with tab-completion for flags and subcommands
   Change:
   - Add "gestalt completion bash|zsh" subcommand
   - Generate completion script for flag names, subcommands
   - Reuse pattern from gestalt-send completion (already implemented)
   - Completion for flag values where possible (e.g., --shell lists available shells)
   - Installation instructions in help text
   - This is optional enhancement; low priority
   Tests: Manual test completion installation
   Done when: gestalt completion generates working scripts (optional)

** [#C] Add verbose/debug logging flags to gestalt
   Why: Help users and developers troubleshoot issues
   Change:
   - Add --verbose flag: increase log level to debug
   - Add --quiet flag: decrease log level to warning
   - Default: info level (current behavior)
   - Override default logger level based on flags
   - Show flag values at startup when verbose: "starting with --port 8080 --verbose"
   - This is optional enhancement; defer if complexity is high
   Tests: Test log output at different verbosity levels
   Done when: Verbosity flags control log output (optional)

** [#B] Add CLI flag parsing tests
   Why: Ensure flag parsing and priority order work correctly
   Change:
   - Create cmd/gestalt/flags_test.go with tests for:
     - Default values (no flags, no env)
     - Env var values (env set, no flags)
     - Flag values (flags set, override env)
     - Invalid flag values (error handling)
     - --help and --version early exits
   - Create cmd/gestalt-send/flags_test.go with similar tests
   - Test priority: flag > env > default
   - Test all flag types: string, int, bool
   - Use table-driven tests for coverage
   Tests: go test ./cmd/gestalt ./cmd/gestalt-send
   Done when: Flag parsing has comprehensive test coverage

** [#B] Update README with CLI flag documentation
   Why: Users need to know about new CLI flag interface
   Change:
   - Add "Command-Line Interface" section to README.md
   - Document all flags for gestalt and gestalt-send
   - Show examples of CLI usage:
     - gestalt --port 9090 --token abc123
     - gestalt-send --url http://remote:8080 agent-name
   - Explain priority: CLI > env > default
   - Update "Configuration" section to mention CLI flags first, env vars second
   - Add note: env vars still work (backward compatible)
   - Document --help and --version flags
   - Document subcommands: validate-skill, completion
   Tests: None (documentation only)
   Done when: README documents CLI flags with examples

** [#C] Consider migrating to cobra for richer CLI (future)
   Why: stdlib flag is limited; cobra provides better UX and structure
   Change:
   - Research cobra/viper for CLI and config management
   - Benefits: better help formatting, nested subcommands, config files, env var binding
   - Drawbacks: additional dependency, migration effort
   - Decision: defer unless CLI complexity grows significantly
   - Current stdlib flag approach is sufficient for gestalt's needs
   - Document decision and future migration path
   Tests: None (research only)
   Done when: Decision documented on CLI framework (defer migration)
* TODO [#A] Wails desktop application packaging
  Goal: Package Gestalt as a native desktop application using Wails v3, providing a standalone executable for macOS, Windows, and Linux while preserving the existing web server mode as default.
  Notes:
  - Dual-mode architecture: web server (default) + desktop app (opt-in build target)
  - Desktop mode: Wails v3 wraps existing Gestalt server with native window
  - Hybrid approach: keep HTTP/WebSocket server, Wails bindings call it
  - Desktop app starts embedded server on random port, frontend connects via localhost
  - Separate binaries: `gestalt` (web mode, current) + `gestalt-desktop` (Wails app)
  - PTY/terminal handling unchanged (works in desktop apps)
  - Frontend: reuse existing Svelte app, minimal Wails-specific changes
  - Wails bindings: thin wrapper over HTTP API for native features (file dialogs, etc)
  - Build system: extend Makefile with wails targets
  - Svelte adapter: use static adapter (SPA mode), output to build/ directory
  - Embed frontend build/ in Wails app (not dist/, separate from web mode)
  - Desktop-specific features (optional): native menus, tray icon, better window management
  - Keep configuration compatible: same env vars, same config files
  - Distribution: single binary per platform (gestalt-desktop.app, gestalt-desktop.exe, gestalt-desktop)
  - Documentation: separate desktop build/run instructions in README
  - Testing: desktop app should pass same test suite as web mode
  Date: 2026-01-08
  Ref: Wails v3 docs, agentskills.io packaging patterns

** TODO [#B] Research Wails v3 architecture and requirements
   Why: Understand Wails v3 capabilities, limitations, and integration patterns before committing
   Change:
   - Read Wails v3 documentation: application structure, binding patterns, build process
   - Understand differences from v2: breaking changes, new features, migration path
   - Research Svelte + Wails v3 integration: does v3 have Svelte template/examples?
   - Investigate frontend build output requirements: static SPA vs other modes
   - Check Wails CLI capabilities: dev mode, build targets, cross-compilation
   - Understand Wails runtime: how Go functions are bound, TypeScript generation
   - Research window management: native menus, system tray, multi-window support
   - Check PTY compatibility: any known issues with terminal apps in Wails?
   - Review Wails licensing: MIT (compatible with AGPL)
   - Document findings and any potential blockers
   Tests: None (research only)
   Done when: Wails v3 architecture understood, integration approach validated

** TODO [#B] Install Wails v3 CLI and create skeleton project
   Why: Need Wails tooling and project structure to build desktop app
   Change:
   - Install Wails CLI: `go install github.com/wailsapp/wails/v3/cmd/wails3@latest`
   - Verify installation: `wails3 version`
   - Create skeleton in separate directory first (experiment): `wails3 init -n gestalt-desktop -t svelte`
   - Study generated structure: main.go, wails.json, frontend setup
   - Compare skeleton with Gestalt structure: identify differences
   - Document Wails project structure requirements in internal notes
   - Test skeleton builds: `wails3 dev` and `wails3 build`
   - Verify dev mode works: hot reload, frontend/backend communication
   - Clean up experimental skeleton after study
   Tests: Skeleton app builds and runs successfully
   Done when: Wails CLI installed, skeleton studied, requirements understood

** TODO [#B] Create cmd/gestalt-desktop for Wails application
   Why: Separate entrypoint for desktop mode to avoid mixing web/desktop logic
   Change:
   - Create cmd/gestalt-desktop/main.go as Wails application entrypoint
   - Copy structure from cmd/gestalt/main.go as starting point
   - Add Wails application initialization: wails.Run(&options.App{...})
   - Configure embedded server: start on random port (e.g., localhost:0)
   - Pass server URL to frontend via Wails config or environment
   - Bind Go struct with methods for Wails frontend to call
   - Initial bindings (minimal): GetServerURL() string, OpenExternal(url string) error
   - Wire up existing Manager, agent loader, skill loader (reuse all internal packages)
   - Add graceful shutdown: close Wails app → stop server → cleanup sessions
   - Desktop-specific config: window size (1280x800), title ("Gestalt"), resizable
   Tests: gestalt-desktop compiles; go build ./cmd/gestalt-desktop
   Done when: Desktop entrypoint exists with Wails initialization

** TODO [#B] Configure Svelte frontend for Wails compatibility
   Why: Wails requires static SPA build; ensure Vite config produces correct output
   Change:
   - Frontend already uses Vite + Svelte (not SvelteKit), perfect for Wails
   - Verify vite.config.js build.outDir: keep as 'dist' for web, add 'build' for desktop
   - Add separate build command for desktop: "build:desktop" in package.json
   - Desktop build: `vite build --outDir build --base ./` (relative paths for file:// protocol)
   - Ensure no hardcoded localhost:8080 URLs in frontend code (use relative paths)
   - Update API client (api.js): detect Wails mode, use dynamic server URL
   - Add Wails detection: `window.wails !== undefined`
   - If Wails mode: fetch server URL via Wails binding (e.g., `window.wails.GetServerURL()`)
   - If web mode: use relative paths (current behavior)
   - Keep WebSocket connection logic compatible (ws://localhost:RANDOM_PORT)
   - Test build output: verify build/ contains static SPA assets
   Tests: npm run build:desktop produces clean SPA in build/
   Done when: Frontend builds for both web and desktop modes

** TODO [#B] Create wails.json configuration file
   Why: Wails CLI requires configuration for build, dev mode, and bindings
   Change:
   - Create wails.json in project root
   - Set name: "gestalt-desktop"
   - Set frontend:build: "cd frontend && npm run build:desktop"
   - Set frontend:install: "cd frontend && npm install"
   - Set frontend:dev:build: same as build
   - Set frontend:dev:serverUrl: "auto" (Vite dev server)
   - Set wailsjsdir: "./frontend/src/lib/wails" (generated bindings)
   - Set outputfilename: "gestalt-desktop" (per-platform extension added by Wails)
   - Set debounceMS: 100 (rebuild debounce)
   - Configure build targets: darwin/amd64, darwin/arm64, windows/amd64, linux/amd64
   - Set icon paths (optional, use default for now)
   - Document wails.json fields inline with comments (JSON5 if supported, else separate doc)
   Tests: wails3 dev reads config correctly
   Done when: wails.json exists and Wails CLI uses it

** TODO [#B] Implement Wails bindings for core operations
   Why: Desktop frontend needs Go bindings for native operations and server coordination
   Change:
   - Create internal/desktop/app.go with App struct for Wails bindings
   - App struct holds: server URL, Manager reference, shutdown channel
   - Bind methods (exported, Wails auto-generates JS/TS):
     - GetServerURL() string - returns localhost:PORT of embedded server
     - GetVersion() string - returns version.Version
     - OpenExternal(url string) error - opens URL in system browser
     - SelectDirectory() (string, error) - native directory picker (future feature)
     - Quit() - graceful shutdown
   - Register App struct in cmd/gestalt-desktop main.go: app.Bind(appInstance)
   - Start embedded Gestalt server before Wails window opens
   - Capture dynamic port from listener: `ln, _ := net.Listen("tcp", "127.0.0.1:0")`
   - Pass server URL to App struct for GetServerURL binding
   - Implement startup lifecycle: server → Wails → frontend connects
   - Implement shutdown lifecycle: Wails close → stop server → cleanup
   Tests: Bindings generate correctly; wails3 dev shows methods in console
   Done when: Frontend can call bound Go methods via window.wails

** TODO [#B] Update frontend to detect and use Wails mode
   Why: Frontend must adapt behavior for desktop vs web mode
   Change:
   - Update frontend/src/lib/api.js to detect Wails
   - Detection: `const isWails = typeof window !== 'undefined' && window.wails !== undefined`
   - Export isWails flag for other components to check
   - Update buildApiUrl(): if Wails mode, fetch server URL via window.wails.GetServerURL()
   - Update buildWebSocketUrl(): use server URL from Wails binding
   - Cache server URL on first fetch to avoid repeated binding calls
   - Handle binding call errors: fallback to localhost:8080 with warning
   - Update App.svelte: show "Desktop Mode" indicator in UI (optional)
   - Ensure all HTTP/WebSocket connections use dynamic URL in desktop mode
   - Keep web mode behavior unchanged (relative URLs)
   Tests: Frontend connects to embedded server in desktop mode; go test ./...
   Done when: Desktop frontend communicates with embedded Gestalt server

** TODO [#B] Wire embedded server into desktop app lifecycle
   Why: Desktop app must start/stop server cleanly with window lifecycle
   Change:
   - In cmd/gestalt-desktop/main.go, start server before wails.Run()
   - Use same server initialization as cmd/gestalt/main.go (share code if possible)
   - Start on random port: listener := net.Listen("tcp", "127.0.0.1:0")
   - Extract port: serverURL := "http://" + listener.Addr().String()
   - Pass serverURL to App struct for bindings
   - Add OnStartup hook: ensure server is ready before showing window
   - Add OnShutdown hook: gracefully stop server, close all terminals
   - Add OnBeforeClose hook: confirm if terminals are running (optional UX)
   - Handle server start failures: show error dialog, exit gracefully
   - Log server URL at startup (desktop app log location)
   Tests: Desktop app starts server on random port, frontend connects
   Done when: Server lifecycle synchronized with desktop app

** TODO [#C] Extend Makefile with Wails build targets
   Why: Developers need simple commands to build desktop app
   Change:
   - Add wails-dev target: `wails3 dev` (runs dev mode)
   - Add gestalt-desktop target: `wails3 build -clean` (production build)
   - Add wails-deps target: install Wails CLI if missing
   - Desktop build depends on frontend build:desktop
   - Consider: make install-desktop (copy to /Applications on macOS, etc)
   - Add clean target for desktop artifacts: build/bin/gestalt-desktop*
   - Document desktop build in Makefile comments
   - Add platform-specific targets (optional): gestalt-desktop-darwin, gestalt-desktop-windows
   Tests: make gestalt-desktop produces working binary
   Done when: Desktop app builds via Makefile

** TODO [#C] Add desktop-specific window configuration
   Why: Native desktop app needs proper window sizing, title, and behavior
   Change:
   - Configure initial window size: 1400x900 (accommodate dashboard + terminal)
   - Set minimum window size: 800x600 (prevent unusable small windows)
   - Set window title: "Gestalt" (shows in title bar, taskbar)
   - Enable window resize, maximize, minimize (standard desktop behavior)
   - Disable fullscreen initially (can add later if desired)
   - Configure window position: center on startup
   - Consider: save/restore window size and position (future feature)
   - macOS specific: set window role, subtitle if needed
   - Windows specific: set app ID for taskbar grouping
   - Linux specific: set WM_CLASS for desktop integration
   Tests: Window appears with correct size and title
   Done when: Desktop window has proper size, title, and behavior

** TODO [#C] Add desktop-specific native menus (optional)
   Why: Desktop apps typically have native menu bar (File, Edit, etc)
   Change:
   - Use Wails menu API to create native menus
   - File menu: New Terminal, Quit (Cmd+Q / Ctrl+Q)
   - Edit menu: Copy, Paste (standard shortcuts)
   - View menu: Toggle Developer Tools (Wails built-in)
   - Help menu: About, Documentation (opens in browser)
   - macOS: standard macOS menu structure (app menu, etc)
   - Bind menu actions to Wails methods or frontend events
   - This is optional enhancement; can defer if complexity is high
   Tests: Menus appear and actions work
   Done when: Desktop app has native menus (optional, can defer)

** TODO [#C] Handle desktop-specific file paths and resources
   Why: Desktop app bundle has different resource locations than web server
   Change:
   - Ensure config/agents, config/prompts, config/skills load correctly
   - Desktop app: resources relative to executable or app bundle
   - Use embedded resources (already done) with external override in ~/.gestalt/ or user home
   - Update path resolution in cmd/gestalt-desktop to check:
     1. ~/.gestalt/config/ (user customization)
     2. Embedded resources (compiled into binary)
   - Document desktop config location in README
   - macOS: support ~/Library/Application Support/Gestalt/config/ (optional)
   - Windows: support %APPDATA%/Gestalt/config/ (optional)
   - Linux: support ~/.config/gestalt/ (optional, XDG standard)
   Tests: Desktop app loads config from correct locations
   Done when: Desktop app finds config in user-specific locations

** TODO [#C] Add system tray icon (optional enhancement)
   Why: Desktop apps often minimize to system tray for background operation
   Change:
   - Use Wails system tray API to add tray icon
   - Tray menu: Show Window, Quit
   - Click tray icon: restore window if minimized
   - Show notification count badge (optional, if terminals have alerts)
   - macOS: proper retina icon support
   - Windows: proper icon sizes
   - Linux: works with various desktop environments
   - This is optional enhancement; low priority
   Tests: Tray icon appears, click actions work
   Done when: System tray integration works (optional, defer if complex)

** TODO [#B] Test desktop app on all target platforms
   Why: Ensure desktop app works correctly on macOS, Windows, Linux
   Change:
   - Build for macOS (amd64 and arm64): verify app bundle structure
   - Build for Windows (amd64): verify .exe runs, no console window appears
   - Build for Linux (amd64): verify binary runs, window appears correctly
   - Test core functionality on each platform: create terminal, connect, send input
   - Test agent profiles: load, execute, prompt injection
   - Test skills loading and display
   - Test window management: resize, minimize, maximize, close
   - Test graceful shutdown: close window → server stops → terminals cleaned up
   - Document any platform-specific issues or workarounds
   Tests: Desktop app fully functional on macOS, Windows, Linux
   Done when: Desktop app passes smoke tests on all platforms

** TODO [#C] Update CI/CD for desktop builds (optional)
   Why: Automate desktop app builds for releases
   Change:
   - Extend .github/workflows to build desktop binaries
   - Add matrix build for platforms: darwin/amd64, darwin/arm64, windows/amd64, linux/amd64
   - Install Wails CLI in CI environment
   - Build desktop app: wails3 build -platform <platform>
   - Upload build artifacts to GitHub releases
   - Sign macOS app (requires Apple Developer account and certificates)
   - Notarize macOS app (for Gatekeeper compatibility)
   - Windows: consider code signing (requires certificate)
   - Linux: no signing required (provide checksums)
   - Add desktop binaries to release notes
   - This is optional; manual builds acceptable initially
   Tests: CI builds produce working binaries
   Done when: CI automatically builds desktop releases (optional, defer if complex)

** TODO [#B] Document desktop build and usage
   Why: Users and contributors need desktop-specific documentation
   Change:
   - Add "Desktop Application" section to README.md
   - Document installation: download gestalt-desktop binary for your platform
   - Document building from source: make gestalt-desktop
   - Document Wails CLI installation (prerequisite for building)
   - Explain dual-mode architecture: web server (default) vs desktop app
   - Document desktop app features: native window, system integration
   - Document configuration: where desktop app looks for config files
   - Document differences from web mode (if any)
   - Add troubleshooting section: common issues, logs location
   - macOS: explain Gatekeeper warning on first run (unsigned app)
   - Windows: explain SmartScreen warning (unsigned app)
   - Linux: explain permission requirements
   - Add screenshots of desktop app (optional)
   Tests: None (documentation only)
   Done when: Desktop app fully documented in README

** TODO [#C] Consider desktop-specific enhancements (future work)
   Why: Desktop apps can leverage native features unavailable in web
   Change:
   - Native file pickers: SelectFile, SelectDirectory via Wails bindings
   - Drag-and-drop files into terminal (future)
   - Native notifications: use OS notification system instead of toasts
   - Global keyboard shortcuts: Cmd+N for new terminal (Wails GlobalShortcuts)
   - Multiple windows: separate window per terminal (advanced)
   - Dock/taskbar integration: show running terminal count (macOS dock badge)
   - Auto-update mechanism: Wails update framework (complex, defer)
   - URL scheme handler: gestalt:// URLs to open terminals (advanced)
   - These are future enhancements; document ideas, implement later
   Tests: None (future planning)
   Done when: Enhancement ideas documented for future work

* DONE [#A] Event-based filesystem monitoring with WebSocket notifications
  Goal: Replace polling with an event-driven filesystem monitoring component that uses fsnotify to watch files and notify the frontend via WebSocket when changes occur.
  Notes:
  - Core component: internal/watcher package with reusable Watch service
  - Use github.com/fsnotify/fsnotify (de-facto standard, cross-platform, stable, actively maintained)
  - Architecture: Watch service → event hub → WebSocket broadcaster
  - WebSocket endpoint: /ws/events for real-time notifications to frontend
  - Event types: file_changed, git_branch_changed (extensible for future events)
  - First use case: PLAN.org live updates (replace 5s polling in PlanView)
  - Second use case: git branch monitoring (live updates in Dashboard)
  - Internal API: watcher.Watch(path, callback) returns handle for cleanup
  - Frontend: single WebSocket connection handles all filesystem events
  - Thread-safe: concurrent watchers, multiple subscribers, graceful shutdown
  - Error handling: log warnings on watch failures, auto-restart watcher on error
  - Resource limits: max watched files (configurable), cleanup on unsubscribe
  - Git branch detection: watch .git/HEAD + .git/refs/heads/* for branch changes
  - Event payload: {"type": "file_changed", "path": "PLAN.org", "timestamp": "..."}
  - Minimize dependencies: fsnotify only (stdlib for everything else)
  - Testing: mock fsnotify for unit tests, integration tests with real files
  Date: 2026-01-08

** [#B] Evaluate and add fsnotify dependency
   Why: Need cross-platform filesystem watching; fsnotify is the standard Go library for this
   Change:
   - Research: fsnotify vs alternatives (stdlib has none, inotify is Linux-only, kqueue is BSD-only)
   - fsnotify abstracts platform differences (inotify/kqueue/ReadDirectoryChangesW)
   - Mature library: v1.7.0, 9k+ stars, used by Docker/Kubernetes/etc
   - Add dependency: go get github.com/fsnotify/fsnotify@latest
   - Document in README: why fsnotify chosen (cross-platform, stable, standard)
   - Check license: BSD 3-Clause (compatible with AGPL)
   Tests: go mod tidy; verify module resolves
   Done when: fsnotify added as dependency with justification documented

** [#B] Create internal/watcher package structure
   Why: Need reusable abstraction for filesystem watching
   Change:
   - Create internal/watcher/ package with doc.go documenting purpose
   - Define Watch interface: Watch(path string, callback func(Event)) (Handle, error)
   - Define Event struct: Path, Op (create/write/remove/rename/chmod), Timestamp
   - Define Handle interface: Close() error for cleanup
   - Create Watcher struct wrapping fsnotify.Watcher
   - Thread-safe design: mutex protecting watched paths and callbacks
   - Support multiple callbacks per path (fan-out pattern)
   - Document design: event delivery guarantees, error handling, cleanup
   Tests: Package structure compiles; interfaces defined
   Done when: Watcher package structure exists with documented interfaces

** [#B] Implement core Watcher with fsnotify integration
   Why: Bridge fsnotify events to Gestalt's callback architecture
   Change:
   - Implement New() (*Watcher, error) that creates fsnotify.Watcher
   - Implement Watch(path, callback) that calls fsnotify.Add(path)
   - Start event loop goroutine reading from fsnotify.Events channel
   - On fsnotify event: look up registered callbacks, invoke each
   - Handle fsnotify.Errors channel: log warnings, attempt recovery
   - Implement Close() that stops fsnotify watcher and event loop
   - Add WatchDir option for recursive directory watching (future)
   - Debounce rapid events: 100ms window to collapse duplicate events
   - Tests: Unit tests with mock filesystem (os.CreateTemp, write, remove)
   Done when: Watcher receives fsnotify events and dispatches to callbacks

** [#B] Add event hub for centralized event management
   Why: Decouple watchers from WebSocket broadcasting
   Change:
   - Create internal/watcher/hub.go with EventHub struct
   - EventHub maintains: map of watched paths, registered listeners
   - Method: Subscribe(eventType string, listener func(Event)) → subscription ID
   - Method: Unsubscribe(id string) for cleanup
   - Method: Publish(Event) to notify all subscribers for event type
   - Event types: file_changed, git_branch_changed, (extensible)
   - EventHub wraps Watcher and translates low-level fs events to domain events
   - Add context support for graceful shutdown
   - Tests: Unit tests for subscribe/publish/unsubscribe
   Done when: EventHub can manage subscriptions and fan-out events

** [#B] Implement WebSocket /ws/events endpoint
   Why: Frontend needs real-time event notifications
   Change:
   - Add /ws/events WebSocket endpoint in internal/api/routes.go
   - On connect: subscribe client to EventHub
   - On event: send JSON message to WebSocket client
   - Message format: {"type": "file_changed", "path": "PLAN.org", "timestamp": "2026-01-08T12:00:00Z"}
   - Support client-side filtering: client sends {"subscribe": ["file_changed", "git_branch_changed"]}
   - Handle client disconnect: unsubscribe from EventHub
   - Reuse existing WebSocket auth pattern (token in query param)
   - Add rate limiting: max 100 events/minute per client (prevent abuse)
   - Tests: WebSocket connection test, event delivery test
   Done when: /ws/events streams filesystem events to connected clients

** [#B] Implement PLAN.org file watching
   Why: First use case - live updates for Plan tab
   Change:
   - In cmd/gestalt/main.go: watch PLAN.org file on startup
   - Register callback with EventHub to publish file_changed events
   - Handle PLAN.org creation/deletion gracefully (re-watch if recreated)
   - Add GET /api/plan ETag header (hash of file content) for efficient polling fallback
   - Log watch activation: "Watching PLAN.org for changes"
   - Tests: Integration test: modify PLAN.org, verify event fired
   Done when: PLAN.org changes trigger file_changed events

** [#B] Update PlanView to use WebSocket events
   Why: Replace polling with event-based updates
   Change:
   - Remove 5s polling interval in frontend/src/views/PlanView.svelte
   - Connect to /ws/events on component mount
   - Subscribe to file_changed events for PLAN.org
   - On event: fetch updated content via GET /api/plan
   - Show subtle notification: "Plan updated" (auto-dismiss)
   - Handle WebSocket disconnection: reconnect with exponential backoff
   - Fallback: if WebSocket unavailable, revert to 10s polling (degraded mode)
   - Tests: Manual test: edit PLAN.org, verify UI updates immediately
   Done when: Plan tab updates instantly when PLAN.org changes

** [#B] Implement git branch monitoring
   Why: Second use case - live git branch updates in Dashboard
   Change:
   - Create internal/watcher/git.go with GitWatcher
   - Watch .git/HEAD file for branch changes
   - Parse .git/HEAD: "ref: refs/heads/main" → extract branch name
   - Handle detached HEAD state (HEAD contains commit SHA)
   - Watch .git/refs/heads/* for new branches (optional, future)
   - On change: publish git_branch_changed event with branch name
   - Add to EventHub on startup if .git directory exists
   - Handle non-git repos gracefully (skip watching, no errors)
   - Tests: Unit tests with temp git repo, simulate branch change
   Done when: Git branch changes trigger git_branch_changed events

** [#B] Add git origin and branch to /api/status
   Why: Dashboard needs current git context
   Change:
   - Extend statusResponse in internal/api/rest.go: GitOrigin, GitBranch strings
   - Read git origin from .git/config: parse [remote "origin"] section
   - Read git branch from .git/HEAD (reuse GitWatcher logic)
   - Cache on startup, update on git_branch_changed events
   - Handle errors gracefully: empty strings if not git repo
   - Add working_dir field (already in plan) for full context
   - Tests: API test with/without git repo; go test ./internal/api
   Done when: GET /api/status returns git origin and current branch

** [#B] Update Dashboard to show git branch live
   Why: Users need to see current git context in Dashboard
   Change:
   - Add git origin/branch display to Dashboard.svelte status section
   - Show: "origin/branch-name" in compact format
   - Connect to /ws/events on Dashboard mount
   - Subscribe to git_branch_changed events
   - On event: update status display without full page refresh
   - Style: monospace font, subtle color, near working directory
   - Handle missing git info: show "not a git repo" or hide section
   - Tests: Manual test: git checkout, verify Dashboard updates
   Done when: Dashboard shows live git branch without polling

** [#C] Add configurable watcher limits and cleanup
   Why: Prevent resource exhaustion from too many watchers
   Change:
   - Add GESTALT_MAX_WATCHES env var (default 100)
   - Track active watch count in Watcher
   - Return error if max watches exceeded
   - Implement periodic cleanup: remove watchers with no subscribers
   - Add metrics: active watches, events delivered, errors
   - Log watcher lifecycle: add/remove at debug level
   - Document limits in README under configuration
   Tests: Test watch limit enforcement; verify cleanup works
   Done when: Watcher respects resource limits and cleans up unused watches

** [#C] Add debouncing and event coalescing
   Why: Prevent event flooding from rapid file changes (e.g., editor autosave)
   Change:
   - Add 100ms debounce window per path
   - Collect events during window, deliver once at window end
   - Preserve latest event data (e.g., timestamp, op type)
   - Configurable debounce duration per watcher
   - Special case: git operations often touch multiple files rapidly
   - Tests: Unit test with rapid file modifications; verify single event
   Done when: Rapid changes trigger single event after debounce window

** [#C] Add frontend WebSocket event store
   Why: Centralize WebSocket event handling in frontend
   Change:
   - Create frontend/src/lib/eventStore.js for /ws/events connection
   - Single WebSocket connection shared by all components
   - Export subscribe(eventType, callback) for component usage
   - Handle reconnection with exponential backoff
   - Log connection state changes (connecting/connected/disconnected)
   - Provide connection status for UI feedback
   - Clean up subscriptions on component unmount (prevent leaks)
   Tests: Frontend unit tests for store; manual connection test
   Done when: Frontend has reusable WebSocket event infrastructure

** [#C] Add error handling and recovery
   Why: Filesystem watching can fail (permission, filesystem full, etc)
   Change:
   - Catch fsnotify errors: log at warning level with context
   - Attempt watcher recreation on failure (max 3 retries)
   - Exponential backoff between retry attempts
   - Notify frontend of watch failures via error events
   - Show toast notification: "File watching unavailable" (for PLAN.org/git)
   - Fall back to polling if watching fails persistently
   - Document failure modes in README
   Tests: Simulate watch failures (permissions, invalid paths)
   Done when: Watcher handles errors gracefully with fallback options

** [#C] Add integration tests for end-to-end event flow
   Why: Verify complete flow from filesystem change to frontend update
   Change:
   - Create test: start server, connect WebSocket, modify watched file
   - Verify event delivery within 200ms (including debounce)
   - Test multiple concurrent clients receiving same event
   - Test git branch change detection end-to-end
   - Test WebSocket reconnection and event recovery
   - Test resource cleanup: watchers removed when clients disconnect
   - Use temp directories and temp git repos for isolation
   Tests: go test ./... integration suite passes
   Done when: E2E tests cover critical paths with real filesystem operations

** [#C] Document event system and usage patterns
   Why: Developers need to understand how to add new watchers
   Change:
   - Add "Filesystem Event System" section to README.md
   - Document EventHub API: how to subscribe/publish events
   - Document WebSocket /ws/events protocol and message format
   - Provide example: adding a new watched file or event type
   - Document debouncing behavior and configuration
   - Document resource limits and cleanup policies
   - Add architecture diagram (optional): Watcher → EventHub → WebSocket
   - Document frontend eventStore.js usage pattern
   Tests: None (documentation only)
   Done when: Event system is fully documented with examples

* DONE [#B] Dashboard and Plan UI improvements
  Goal: Streamline dashboard UX by showing working directory, adding agent start/stop controls, embedding logs directly, removing redundant sections, and enabling real-time plan file watching.
  Notes:
  - Dashboard is the primary control surface; reduce clutter, increase information density
  - Agent terminals: show play/stop button instead of always creating new terminals
  - Only one active terminal per agent (enforced by backend, UI reflects state)
  - Visual feedback: running vs stopped state with color changes
  - Working directory prominently displayed (users need to know context)
  - Logs embedded in dashboard (remove separate tab, reduce navigation)
  - Skills list removed (redundant; shown in agent cards already)
  - Live terminals section removed (state now clear from agent cards)
  - Plan tab: fix file watching to update on changes (currently only loads at startup)
  - All changes must maintain clean separation: components remain modular and testable
  - Backend changes minimal: add working directory to status API, ensure agent state tracking
  Date: 2026-01-08

** [#B] Setup Tailwind CSS for Svelte frontend
   Why: Streamline styling and reduce custom CSS; perfect timing with dashboard overhaul
   Change:
   - Install tailwindcss, postcss, autoprefixer as dev dependencies
   - Create tailwind.config.js with Svelte content paths: './src/**/*.{html,js,svelte,ts}'
   - Create postcss.config.js with tailwindcss and autoprefixer plugins
   - Create or update src/app.css with Tailwind directives (@tailwind base/components/utilities)
   - Import app.css in src/main.js or App.svelte
   - Configure Vite to process Tailwind (already works with PostCSS out of box)
   - Test with simple utility class (e.g., bg-blue-500) in Dashboard.svelte
   - Keep existing component styles working during transition (gradual migration)
   - Document Tailwind usage in comments: "New code uses Tailwind, old code migrates as touched"
   Tests: npm run build; verify Tailwind classes render; npm test still passes
   Done when: Tailwind configured, builds successfully, ready for use in new code

** [#B] Add working directory to status API
   Why: Dashboard needs to prominently display where Gestalt is running
   Change:
   - Extend statusResponse struct in internal/api/rest.go to include WorkDir string
   - Populate with os.Getwd() in status handler
   - Handle error if getwd fails (log warning, use "unknown" or empty string)
   - Update API response: "working_dir" field in JSON
   Tests: GET /api/status includes working_dir; go test ./internal/api
   Done when: Status endpoint returns current working directory

** [#B] Update Dashboard status section with working directory
   Why: Users need prominent display of working directory; remove useless metrics
   Change:
   - Remove "Active terminals" and "Skills available" status cards from Dashboard.svelte
   - Remove "Server time" status card (not useful)
   - Add single prominent "Working directory" card showing full path from status.working_dir
   - Style: make working directory card span full width or prominent position
   - Use monospace font for path display
   - Keep eyebrow and h1 (Gestalt title) unchanged
   Tests: npm test -- tests/dashboard.test.js (if exists); manual visual check
   Done when: Dashboard shows working directory prominently, other metrics removed

** [#B] Add agent state tracking to Manager
   Why: Need to track which agents are running vs stopped for play/stop UI
   Change:
   - Manager already tracks agentSessions map (agent name → terminal ID)
   - Add method Manager.GetAgentTerminal(agentName string) (terminalID string, running bool)
   - Returns terminal ID if agent has running session, empty string if stopped
   - This is for UI state; existing single-instance enforcement unchanged
   Tests: Unit tests for Manager.GetAgentTerminal; go test ./internal/terminal
   Done when: Manager can report agent running state by name

** [#B] Extend agents API to include terminal state
   Why: Frontend needs to know which agents are currently running
   Change:
   - Extend agentSummary struct in internal/api/rest.go to include TerminalID string and Running bool
   - In GET /api/agents handler, check Manager.GetAgentTerminal(agent.Name) for each agent
   - Populate terminal_id and running fields in response
   - If agent running, include terminal ID; if stopped, terminal_id is empty and running is false
   Tests: API test verifies running/stopped agents; go test ./internal/api
   Done when: GET /api/agents returns terminal state per agent

** [#B] Transform agent buttons to play/stop controls
   Why: Dashboard should show start/stop controls instead of always creating new terminals
   Change:
   - Replace agent buttons in Dashboard.svelte agent-grid section
   - If agent.running: show stop button (⏹ or "Stop") with agent.name
   - If !agent.running: show play button (▶ or "Start") with agent.name
   - Play button: calls createTerminal(agent.id) (existing behavior)
   - Stop button: calls deleteTerminal(agent.terminal_id) (existing function)
   - Update button styling: .agent-button--running and .agent-button--stopped classes
   - Running state: slightly different background color (e.g., light green/blue tint)
   - Stopped state: default/muted color
   - Keep agent skills display below button (unchanged)
   Tests: npm test -- tests/dashboard.test.js; manual test play/stop
   Done when: Agent cards show play/stop based on state; visual feedback works

** [#B] Remove skills section from Dashboard
   Why: Skills list is redundant; already shown in agent cards
   Change:
   - Remove entire .dashboard__skills section from Dashboard.svelte
   - Remove loadSkills() function and related state (skills, skillsLoading, skillsError)
   - Remove agentNamesForSkill() function (no longer needed)
   - Keep agentSkills loading for agent cards (still need skills per agent)
   - Remove associated styles for .dashboard__skills, .skill-grid, .skill-card
   Tests: npm test; manual check no regression in agent skills display
   Done when: Skills section removed; agent cards still show skills correctly

** [#B] Remove live terminals section from Dashboard
   Why: Agent state is now clear from agent cards; separate list is redundant
   Change:
   - Remove entire .dashboard__list section from Dashboard.svelte
   - Keep terminals prop and state (needed for App.svelte tab management)
   - Remove formatTime function if only used for terminal list
   - Remove associated styles for .dashboard__list, .terminal-list, .terminal-row
   Tests: npm test; verify tabs still work (terminals tracked in App.svelte)
   Done when: Live terminals section removed; terminal tabs still functional

** [#B] Embed logs directly in Dashboard
   Why: Logs should be visible without switching tabs; reduce navigation overhead
   Change:
   - Add compact logs section to Dashboard.svelte below agent section
   - Import log fetching logic from LogsView.svelte (fetchLogs, filtering)
   - Display last 10-20 log entries in compact format (timestamp, level badge, message)
   - Keep filter dropdown (level filter) and auto-refresh toggle
   - Style: compact cards, smaller font, less padding than full LogsView
   - Add "View all logs" link that switches to Logs tab (keep tab for full view)
   - Refresh logs on mount and every 5s (same as LogsView auto-refresh)
   Tests: npm test -- tests/dashboard.test.js; verify logs display and refresh
   Done when: Dashboard shows recent logs; full Logs tab still accessible

** [#C] Remove Logs tab from navigation
   Why: Logs are now in Dashboard; separate tab is redundant
   Change:
   - Remove logs tab from tabs array in App.svelte initialization
   - Remove 'logs' case from activeView computed property
   - Remove LogsView import and section from App.svelte template
   - Keep LogsView.svelte file (might be useful for "view all" link in future)
   - Update TabBar to not show logs tab
   Tests: npm test; manual check tab navigation works
   Done when: Logs tab not visible; logs accessible via dashboard

** [#B] Move all session storage to .gestalt directory
   Why: Keep working directory clean; make session data accessible and organized
   Change:
   - Change default session log directory from "logs/sessions" to ".gestalt/sessions"
   - Change default input history directory from "logs/input-history" to ".gestalt/input-history"
   - Update ManagerOptions defaults in cmd/gestalt/main.go
   - Update env var documentation: GESTALT_SESSION_DIR, GESTALT_INPUT_HISTORY_DIR
   - Create .gestalt directory in current working directory on startup
   - Update persistence.go and input_logger.go to use new paths
   - Add .gestalt to .gitignore if not already present
   - Migrate existing logs/ data on first startup (optional, or document manual migration)
   Tests: go test ./internal/terminal; verify files created in .gestalt/
   Done when: All session data stored in .gestalt/ directory

** [#B] Fix terminal history persistence on reconnect
   Why: Terminal loses history when frontend closes and reopens
   Change:
   - Issue: frontend doesn't fetch full history on reconnect
   - On WebSocket connect in terminalStore.js, fetch GET /api/terminals/:id/output
   - Write buffered history to xterm before starting live WebSocket stream
   - Backend already maintains OutputBuffer (1000 lines) and SessionLogger (disk)
   - Fetch should get max 2000 lines from both buffer and disk (if session file exists)
   - Handle loading state: show "Loading history..." in terminal header
   - Add sessionStorage or memory cache to avoid re-fetching if already loaded
   - Ensure history lines don't duplicate when WebSocket starts streaming
   Tests: Manual test: connect, type output, close browser, reopen → verify history visible
   Done when: Terminal history fully restored on frontend reconnect

** [#B] Fix terminal layout: full width and page-level scrolling
   Why: Terminal is boxed with double scrollbars; should be full-page and directly scrollable
   Change:
   - TerminalView.svelte removes padding wrapper (currently adds 2rem padding)
   - Terminal.svelte should fill viewport: use viewport height (100vh minus header)
   - Change grid-template-rows in .terminal-shell to use vh units
   - Remove min-height: 70vh, use height: calc(100vh - 64px - [input-box-height])
   - Make xterm container grow to fill available space
   - Page scrollbar should scroll xterm viewport directly (no nested scrolling)
   - Test with different content heights and window sizes
   Tests: Manual test: resize window, scroll terminal, verify no double scrollbars
   Done when: Terminal is full-width, full-height, single scrollbar

** [#B] Make command input box fixed at bottom
   Why: Input box should always be visible regardless of terminal scroll position
   Change:
   - CommandInput should be position: sticky or fixed at bottom of viewport
   - Adjust Terminal.svelte layout: input box outside scrollable terminal area
   - Use CSS: position: sticky; bottom: 0; z-index: 10;
   - Add subtle shadow or border-top to separate from terminal content
   - Ensure input box doesn't cover terminal content (adjust terminal bottom padding)
   - Keep input box within .terminal-shell bounds (not floating over page)
   Tests: Manual test: scroll terminal, verify input box stays at bottom
   Done when: Input box always visible at bottom during scroll

** [#B] Add scroll-to-bottom button to command input
   Why: Users need quick way to jump to bottom of long terminal output
   Change:
   - Add button to CommandInput.svelte above/beside textarea
   - Button label: "↓ Scroll to bottom" or just icon ⬇
   - On click: scroll xterm viewport to bottom
   - Access xterm via terminalStore state: state.scrollToBottom() method
   - Add scrollToBottom() method to terminalStore.js: calls term.scrollToBottom()
   - Show button only when not already at bottom (detect scroll position)
   - Style: small, subtle button that doesn't interfere with input
   - Position: inline with "Direct input" toggle, or above textarea
   Tests: Manual test: scroll up, click button, verify jumps to bottom
   Done when: Scroll-to-bottom button works in command input area

** [#B] Implement file watching for PLAN.org updates
   Why: Plan view should update when file changes, not just at startup
   Change:
   - Add file watching to PlanView.svelte using backend polling or native file watch
   - Option 1 (simple): poll /api/plan every 5-10s, compare content hash or timestamp
   - Option 2 (better): add ETag header to /api/plan, use If-None-Match for efficient polling
   - Option 3 (ideal): add WebSocket endpoint for plan updates (more complex)
   - Start with Option 1: poll every 5s, compare content, reload OrgViewer if changed
   - Add loading indicator for refreshes (subtle, non-intrusive)
   - Keep manual refresh button for user control
   Tests: Manual test: edit PLAN.org, verify UI updates; npm test
   Done when: Plan view updates automatically when file changes

** [#C] Add ETag support to plan endpoint (optional enhancement)
   Why: Efficient polling without transferring full file every time
   Change:
   - Compute ETag for /api/plan response (hash of file content or mtime)
   - Return ETag header in response
   - Support If-None-Match request header, return 304 Not Modified if unchanged
   - PlanView sends If-None-Match with stored ETag
   - Only reload content if server returns 200 (content changed)
   - This is optional enhancement; basic polling sufficient initially
   Tests: API test for ETag and 304 responses; go test ./internal/api
   Done when: Plan polling uses ETags for efficiency (optional)

** [#C] Polish agent card styling for running state
   Why: Visual feedback should be clear and pleasant
   Change:
   - Running state: subtle green or blue tint in .agent-button--running
   - Stopped state: neutral/muted colors in .agent-button--stopped
   - Add transition for smooth color change on state change
   - Consider adding pulsing animation or indicator dot for running state
   - Ensure colors work in both light and dark themes (if applicable)
   - Keep buttons accessible: sufficient contrast, clear labels
   Tests: Manual visual testing; accessibility check
   Done when: Running/stopped states have clear, pleasant visual feedback

** [#C] Update documentation for Dashboard changes
   Why: Users need to understand new dashboard layout and controls
   Change:
   - Update README.md to document dashboard features
   - Document working directory display
   - Document agent play/stop controls
   - Document embedded logs section
   - Note that Logs tab is removed (logs in dashboard)
   - Document plan auto-refresh behavior
   Tests: None (documentation only)
   Done when: README reflects new dashboard structure and features

<<<<<<< HEAD
=======
** FIX Touch scroll terminal history (multi-touch + touch-anywhere)
   Why: Touch devices should scroll terminal history from any point in the viewport
   Change:
   - Add touch handlers to scroll xterm viewport on single or multi-touch gestures
   - Keep mouse selection behavior intact
   Tests: go test ./...; npm test
   Done when: Swipe anywhere in terminal scrolls history on touch devices

** FIX Focus command input on terminal tab activation/creation
   Why: Command input should be ready immediately after opening or switching tabs
   Change:
   - Focus command input on tab activation and initial terminal creation
   - Respect direct input mode to focus xterm instead
   Tests: go test ./...; npm test
   Done when: Input focus lands correctly on tab switch and creation

** FIX Agent start/stop button state updates immediately
   Why: Running state should reflect changes without page reload
   Change:
   - Refresh agent list after start/stop actions
   Tests: go test ./...; npm test
   Done when: Agent buttons flip to running/stopped immediately

** FIX Show git origin/branch in dashboard status
   Why: Dashboard should show repo context alongside working directory
   Change:
   - Extend /api/status with git_origin and git_branch fields (read once on boot)
   - Parse .git/config for origin and .git/HEAD for branch
   - Update status card to show working directory, origin, and branch on one line
   Tests: go test ./...; npm test
   Done when: Status shows origin/branch with working directory

>>>>>>> 13091cc (refine prompts and new fixer agent)
* DONE [#B] Agent profile widgets: configurable UI composition
  Goal: Extend agent profiles with a "widgets" array that controls which UI elements appear in an agent's terminal tab, starting with a Plan sidebar widget that displays PLAN.org alongside the terminal.
  Notes:
  - Agent profiles get new optional field: "widgets": ["plan-sidebar", ...] (array of widget names)
  - First widget implementation: "plan-sidebar" - shows OrgViewer component in a sidebar
  - Layout: when "plan-sidebar" widget is present, split terminal tab into 3/5 terminal + 2/5 plan sidebar
  - OrgViewer component already exists and was designed for sidebar use (from completed PLAN.org viewer work)
  - Widgets are opt-in per agent: agents without "widgets" field show full-width terminal (current behavior)
  - Future widgets could include: logs, metrics, file browser, skill library, workflow status
  - Layout system should be flexible: different widgets may have different sizes/positions
  - Use CSS Grid or Flexbox for responsive layout
  - Backend: Agent struct gets Widgets []string field, validation, JSON parsing
  - Frontend: Terminal tab reads agent.widgets and renders layout with appropriate components
  - Sidebar should be responsive: collapsible/expandable, maybe resizable in future
  Date: 2025-12-31

** TODO [#B] Add widgets field to Agent struct and JSON schema
   Why: Backend needs to store and validate widget configuration from agent JSON files
   Change:
   - Add Widgets []string `json:"widgets,omitempty"` field to Agent struct in internal/agent/agent.go
   - Widget names use kebab-case: "plan-sidebar", "logs-panel", etc.
   - Validation: warn (don't fail) if unknown widget name is referenced
   - Add validation helper: ValidateWidget(name string) that checks against known widgets
   - Known widgets initially: ["plan-sidebar"]
   - Update Agent.Validate() to check widget names and log warnings for unknown ones
   - Empty/missing widgets field is valid (means no widgets, current behavior)
   Tests: Unit tests for Agent with widgets field; valid/invalid widget names
   Done when: Agent struct accepts and validates widgets array

** TODO [#B] Update agent loader to support widgets field
   Why: Agent loader must parse and validate widgets from JSON files
   Change:
   - Loader already handles JSON unmarshaling; widgets will be parsed automatically
   - Add logging when widgets are loaded: info level "Agent 'X' has widgets: [...]"
   - Warn if unknown widget referenced: "Unknown widget 'foo' in agent 'bar', ignoring"
   - No special handling needed beyond Agent struct changes (automatic via JSON tags)
   - Update example agent configs to demonstrate widgets usage
   Tests: Loader tests with agents containing widgets field
   Done when: Agent JSON files with widgets load and validate correctly

** TODO [#B] Extend API to expose agent widgets
   Why: Frontend needs to know which widgets to render for each agent
   Change:
   - GET /api/agents already returns agent metadata; ensure widgets field is included
   - GET /api/terminals/:id should include agent.widgets in SessionInfo/terminalSummary
   - Widgets array should be in JSON response for both endpoints
   - Add widgets to terminalSummary struct in internal/api/types.go (if exists) or inline response
   Tests: API tests verify widgets field in responses
   Done when: Frontend can fetch widget configuration via API

** TODO [#B] Create terminal layout container component
   Why: Need flexible layout system for terminal + sidebar widgets
   Change:
   - Create frontend/src/components/TerminalLayout.svelte
   - Props: widgets (array of widget names), terminalId, agent
   - Default layout: full-width terminal (no widgets)
   - If widgets includes "plan-sidebar": use CSS Grid with 3fr / 2fr layout (60% / 40%)
   - Left area: terminal component, Right area: widget container
   - Make layout responsive: handle narrow screens (stack vertically on mobile?)
   - Add CSS classes: .terminal-layout, .terminal-area, .widget-area
   - Widget area should have overflow: auto and independent scrolling
   Tests: Manual test with/without widgets; verify layout proportions
   Done when: Layout component renders terminal with/without sidebar

** TODO [#B] Create widget container and widget factory
   Why: Need system to dynamically render different widget types
   Change:
   - Create frontend/src/components/WidgetContainer.svelte
   - Props: widgetName (string), terminalId, agent
   - Use switch/case or component map to render correct widget component
   - Handle unknown widgets gracefully: show placeholder or warning message
   - For "plan-sidebar": render OrgViewer component
   - Add styling: consistent padding, borders, background matching app theme
   - Widget container should handle loading states for async widgets
   Tests: Manual test with "plan-sidebar" widget; verify OrgViewer renders
   Done when: Widget container correctly renders plan-sidebar widget

** TODO [#B] Integrate OrgViewer as plan-sidebar widget
   Why: Plan sidebar is the first widget implementation
   Change:
   - OrgViewer.svelte already exists in frontend/src/components/
   - Ensure OrgViewer works in sidebar context: compact styling, responsive width
   - OrgViewer should fetch /api/plan on mount (already implemented)
   - Add CSS adjustments for sidebar context: reduce padding, smaller fonts if needed
   - Verify expand/collapse, filtering work in narrow width (~40% of screen)
   - Add subtle visual separator between terminal and sidebar (border or shadow)
   Tests: Manual test OrgViewer in sidebar; verify usability at ~2/5 screen width
   Done when: Plan sidebar displays PLAN.org alongside terminal

** TODO [#B] Wire layout system into Terminal.svelte
   Why: Terminal component needs to use new layout when agent has widgets
   Change:
   - Terminal.svelte currently renders xterm instance directly
   - Wrap xterm in TerminalLayout component
   - Pass agent.widgets array to TerminalLayout
   - TerminalLayout decides whether to show sidebar based on widgets
   - Ensure xterm still gets proper resize events and fit addon works
   - Terminal should occupy full 60% of its container (not affected by sidebar)
   Tests: Manual test: create agent with/without plan-sidebar widget
   Done when: Agent terminals with plan-sidebar show split layout

** TODO [#C] Update example agent configs with widgets
   Why: Demonstrate widget usage and provide working examples
   Change:
   - Update one example agent (e.g., config/agents/copilot.json) to include widgets
   - Add: "widgets": ["plan-sidebar"]
   - Keep other example agents without widgets (show both patterns)
   - Document widget field in README.md under Agent Profiles section
   Tests: Load example agents; verify copilot shows plan-sidebar
   Done when: Example demonstrates plan-sidebar widget usage

** TODO [#C] Add widget resizing capability (optional enhancement)
   Why: Users may want to adjust sidebar width
   Change:
   - Add draggable splitter between terminal and sidebar
   - Use mouse events to adjust CSS Grid proportions on drag
   - Store width preference in localStorage per widget type
   - Default: 60/40 split, allow range 40-80% for terminal
   - This is optional enhancement; can defer if too complex initially
   Tests: Manual test dragging splitter; verify layout adjusts smoothly
   Done when: Users can resize plan-sidebar width (optional)

** TODO [#C] Document widgets system
   Why: Users and contributors need to understand widget configuration
   Change:
   - Add "Agent Widgets" section to README.md
   - Document widgets field in agent profile JSON format
   - Document available widgets: plan-sidebar (with description and screenshot if possible)
   - Document layout behavior: how widgets affect terminal tab composition
   - Document future widget ideas: logs, metrics, file browser, etc.
   - Add example JSON with widgets configuration
   Tests: None (documentation only)
   Done when: Widget system is fully documented in README

* DONE [#B] Semantic versioning with automated releases
  Goal: Implement semantic versioning throughout Gestalt with automated version generation in GitHub Actions based on conventional commits (feat:/fix:), compile version into backend and frontend, and display version in UI near the Gestalt title.
  Notes:
  - Use conventional commits (feat:, fix:) to drive semantic versioning
  - Use npm semver package for version parsing and bumping
  - Node.js script analyzes git log since last tag, detects feat:/fix:/BREAKING CHANGE:
  - Script uses semver.inc() to bump version appropriately
  - Version must be passed at build time to both Go backend and Vite frontend
  - Backend: compile version as const or var, expose via /api/status
  - Frontend: inject version at build time via Vite define, display in Dashboard header
  - UI: reuse .cta class styling (gray, small text) as .version class for version display
  - Version appears near "Gestalt" title in Dashboard header
  - Minimal dependency: only semver package (already Node.js project)
  - Initial version: v1.0.0 (project is mature enough)
  - Git tags are source of truth; no manual version files
  Date: 2025-12-30

** [#B] Create Node.js script for version detection using semver
   Why: Need reliable version bumping based on conventional commits using semver package
   Change:
   - Install semver package as dev dependency in root: npm install --save-dev semver
   - Create scripts/get-next-version.js Node.js script
   - Logic: read git log from last tag to HEAD, parse commit messages
   - Use git describe or git tag to get current version
   - Detect patterns: "feat:" → semver.inc('minor'), "fix:" → semver.inc('patch'), "BREAKING CHANGE:" → semver.inc('major')
   - If no tag exists, output 1.0.0 as initial version
   - Use semver.valid() to validate versions, semver.clean() to normalize
   - Output format: semantic version string without 'v' prefix (e.g., "1.2.3")
   - Handle edge cases: no commits since tag, multiple types in range, invalid existing tags
   - Script should be idempotent and fast
   - Priority order: BREAKING CHANGE > feat > fix (highest precedence wins)
   - Exit with code 0 and output version to stdout for easy capture in workflows
   Tests: Run script manually with various commit histories
   Done when: Script correctly determines next version from git history using semver

** [#B] Create GitHub Actions release workflow
   Why: Automate version detection, tagging, and release creation on main branch
   Change:
   - Create .github/workflows/release.yml (separate from tests.yml)
   - Trigger: on push to main branch only
   - Setup steps: checkout → setup Node.js → npm install semver
   - Run scripts/get-next-version.js to determine next version
   - Compare with current tag (git describe --tags); skip if no change
   - Create git tag with 'v' prefix: v1.2.3
   - Use GitHub API or gh CLI to create release with auto-generated notes
   - Set up GITHUB_TOKEN permissions: contents: write (for tags)
   - Generate release notes from commits since last tag using GitHub's API
   - Tag format: v1.2.3 (with 'v' prefix for git, script outputs without prefix)
   Tests: Push feat: or fix: commit to main, verify tag and release created
   Done when: GitHub Action automatically tags and releases on conventional commits

** [#B] Pass version to Go backend at build time
   Why: Backend needs to know its version for /api/status and logging
   Change:
   - Add internal/version/version.go with var Version string
   - Use Go linker flags in Makefile and GitHub Action: -ldflags "-X gestalt/internal/version.Version=$VERSION"
   - Default Version to "dev" if not set at build time
   - Export version in /api/status response as "version" field
   - Add version to startup log message
   - Update GNUmakefile to accept VERSION variable: make VERSION=1.2.3
   Tests: go test ./...; verify version appears in /api/status
   Done when: Backend binary contains version compiled at build time

** [#B] Pass version to frontend at build time
   Why: Frontend needs to display version in UI
   Change:
   - Use Vite's define option to inject version at build time
   - Update vite.config.js: define: { __APP_VERSION__: JSON.stringify(process.env.VERSION || 'dev') }
   - Create frontend/src/lib/version.js exporting VERSION constant
   - Pass VERSION env var from Makefile and GitHub Action to npm build
   - Vite replaces __APP_VERSION__ at bundle time (tree-shakeable)
   Tests: npm run build; verify version is in bundle
   Done when: Frontend bundle contains version from build-time env var

** [#C] Display version in Dashboard header
   Why: Users should see which version of Gestalt they're running
   Change:
   - Import VERSION from lib/version.js in Dashboard.svelte
   - Add version display in the header brand area
   - Replace the "by Dyne.org" text with version label
   - Reuse existing brand-by styling for the version display
   Tests: npm run build; visually verify version displays correctly
   Done when: Version appears in Dashboard header with .cta-inspired styling

** [#C] Update Makefile to integrate versioning
   Why: Local builds should support version injection
   Change:
   - Add VERSION ?= dev to Makefile (default to "dev" for local builds)
   - Alternatively: VERSION ?= $(shell git describe --tags --always --dirty 2>/dev/null || echo "dev")
   - Update build target to pass VERSION to both Go and npm
   - Go build: add -ldflags "-X gestalt/internal/version.Version=$(VERSION)"
   - npm build: export VERSION=$(VERSION) before running npm run build
   - Document in comments: "make VERSION=1.2.3 to build with specific version"
   - Add phony target "version" that prints current version from git
   Tests: make VERSION=1.0.0; verify both binaries have correct version
   Done when: Makefile supports VERSION variable for local builds

** [#C] Integrate versioning into test workflow
   Why: Test builds should include version info for debugging
   Change:
   - Update .github/workflows/tests.yml to detect version during build
   - Add step: run scripts/get-next-version.sh or git describe for current version
   - Pass VERSION env var to build steps (Go and npm)
   - This workflow does NOT create tags (release.yml handles that)
   - Display version in test summary output for visibility
   - Handle case where no tags exist yet (use "dev" or "1.0.0-dev")
   Tests: Push to PR or branch, verify tests run with version info
   Done when: Test workflow builds contain version from git tags

** [#C] Document versioning workflow
   Why: Contributors need to understand commit message conventions
   Change:
   - Add "Versioning" section to README.md
   - Document conventional commit format: feat:, fix:, BREAKING CHANGE:
   - Explain semantic versioning rules (major.minor.patch)
   - Document how version is injected at build time (Go ldflags, Vite define)
   - Explain automatic tagging: "Push feat: commit to main → v1.1.0 tag created"
   - Show examples: "feat: add terminal history → bumps minor", "fix: resolve connection bug → bumps patch"
   - Mention initial version is v1.0.0
   - Document local build with version: make VERSION=1.2.3
   - Link to conventional commits specification (optional)
   Tests: None (documentation only)
   Done when: README clearly documents versioning workflow and conventions


* DONE [#A] Temporal workflow integration for HITL session lifecycle
  Goal: Integrate Temporal.io workflows to manage durable, semi-interactive agent sessions with human-in-the-loop (HITL) coordination, tracking agent work phases (start: L1/L2 plan tasks) and stops (terminal bells requiring user attention).
  Notes:
  - Core Gestalt functionality: agents record start (which PLAN.org L1/L2 they're working on) and stop (terminal bell signals)
  - Terminal sessions modeled as Temporal workflows with durable state across crashes
  - Signals enable HITL: pause for user input, request another agent's analysis, approval gates
  - Activities: spawn terminal (PTY), execute commands, read output, detect bells
  - Workflow state: session ID, current L1/L2 task, start time, pause/resume events, bell events
  - Terminal bell detection triggers workflow signal → pause → await user action or agent handoff
  - Event history provides full audit trail of agent work sessions
  - Future: wire stops to actions (ask user, delegate to another agent, approval workflows)
  - Temporal SDK: use Go SDK (go.temporal.io/sdk) - matches existing Go backend
  - Temporal server: run local dev server initially, production deployment later
  - Integration: extend Manager/Session to optionally use Temporal workflows
  - Backward compat: existing sessions work without Temporal; opt-in for workflow-managed sessions
  - PLAN.org parsing: read current WIP L1/L2 to record what agent is working on
  - Bell detection: already exists in xterm.js frontend; needs backend signal propagation
  Date: 2025-12-31
  Ref: https://github.com/dyne/gestalt/issues/4

** [#B] Setup Temporal development environment
   Why: Need Temporal server running locally for development and testing
   Change:
   - Add Temporal CLI to development dependencies (temporalio/cli)
   - Document installation: `brew install temporal` (macOS) or download binary
   - Add `make temporal-dev` target to start Temporal dev server
   - Default: temporal server start-dev (includes UI at localhost:8233)
   - Dev server uses built-in SQLite (perfect for local-only Gestalt deployment)
   - Add Temporal server health check to startup logs
   - Document Temporal UI access in README.md
   - Document data persistence: SQLite file persists workflows across restarts
   Tests: Start temporal dev server, verify UI accessible
   Done when: Temporal dev server runs locally and is documented

** [#B] Add Temporal Go SDK dependency
   Why: Need Temporal client and worker SDK in Go backend
   Change:
   - Add dependency: go get go.temporal.io/sdk@latest
   - Add dependency: go get go.temporal.io/api@latest (for API types)
   - Create internal/temporal/ package for Temporal integration
   - Initialize Temporal client in cmd/gestalt/main.go
   - Configure client: namespace (default), host (localhost:7233 for dev)
   - Add GESTALT_TEMPORAL_HOST env var (default: localhost:7233)
   - Add GESTALT_TEMPORAL_NAMESPACE env var (default: "default")
   - Handle connection errors gracefully: warn and continue without Temporal if unavailable
   Tests: go test ./...; verify Temporal client initializes
   Done when: Temporal SDK integrated and client connects to server

** [#B] Create session workflow definition
   Why: Define workflow for terminal session lifecycle management
   Change:
   - Create internal/temporal/workflows/session_workflow.go
   - SessionWorkflow(ctx workflow.Context, req SessionWorkflowRequest) (SessionWorkflowResult, error)
   - Request: SessionID, AgentID, L1Task, L2Task, Shell, StartTime
   - Result: SessionID, EndTime, FinalStatus, EventCount
   - Workflow state: CurrentL1, CurrentL2, Status (running/paused/stopped), BellEvents
   - Signal: UpdateTaskSignal(l1, l2 string) - agent updates which task they're working on
   - Signal: BellSignal(timestamp, context string) - terminal bell detected, pause for HITL
   - Signal: ResumeSignal(action string) - user resumes after bell (continue/abort/handoff)
   - Signal: TerminateSignal(reason string) - graceful shutdown
   - Query: GetStatusQuery() - return current workflow state
   - Implement workflow logic: await signals, record events, manage lifecycle
   Tests: Unit tests for workflow logic with mock activities
   Done when: SessionWorkflow defined with signals and queries

** [#B] Create session activities
   Why: Activities perform actual operations (spawn PTY, detect bells, read output)
   Change:
   - Create internal/temporal/activities/session_activities.go
   - SpawnTerminalActivity(ctx, sessionID, shell string) error - creates terminal session
   - TerminateTerminalActivity(ctx, sessionID string) error - cleanly closes terminal
   - RecordBellActivity(ctx, sessionID, timestamp, context string) error - logs bell event
   - UpdateTaskActivity(ctx, sessionID, l1, l2 string) error - records task switch
   - GetOutputActivity(ctx, sessionID string) (string, error) - retrieves terminal output
   - Activities interact with existing Manager/Session infrastructure
   - Activities are idempotent (safe to retry on failure)
   - Activities log all actions for audit trail
   Tests: Unit tests for each activity; integration test with real Manager
   Done when: Activities connect workflow to terminal operations

** [#B] Extend Session to integrate with Temporal workflow
   Why: Terminal sessions need to optionally participate in Temporal workflows
   Change:
   - Add WorkflowID and RunID fields to Session struct (optional, nil if not using Temporal)
   - Add method Session.StartWorkflow(client, l1, l2 string) error - initiates workflow
   - Add method Session.SendBellSignal(context string) error - sends bell event to workflow
   - Add method Session.UpdateTask(l1, l2 string) error - updates current task in workflow
   - Modify Session.Close() to send TerminateSignal if workflow active
   - Terminal bell detection → call SendBellSignal → workflow pauses
   - Make workflow integration opt-in: only create workflow if GESTALT_TEMPORAL_ENABLED=true
   Tests: Unit tests for workflow integration; manual test with Temporal UI
   Done when: Sessions can optionally be managed by Temporal workflows

** [#B] Parse PLAN.org to extract current WIP tasks
   Why: Agents need to know which L1/L2 they're working on to record in workflow
   Change:
   - Extend internal/plan/ package (or create if doesn't exist) with parser
   - Parse PLAN.org to find WIP entries (TODO/WIP keywords)
   - Find current WIP L1 heading and its WIP L2 child
   - Return (l1Title, l2Title string) for current work
   - Handle multiple WIP entries: warn user, return first or fail
   - Handle no WIP entries: return empty strings
   - Cache parsed plan; reload on file change (fsnotify) or API call
   - Add GET /api/plan/current endpoint returning current WIP L1/L2
   Tests: Unit tests with sample PLAN.org content; various WIP scenarios
   Done when: Can extract current WIP L1/L2 from PLAN.org

** [#B] Wire terminal bell detection to workflow signals
   Why: Terminal bells must trigger workflow pause for HITL
   Change:
   - Frontend already handles xterm.js onBell event
   - Add POST /api/terminals/:id/bell endpoint to receive bell notifications
   - Endpoint extracts recent terminal output as context (last 50 lines)
   - Call session.SendBellSignal(context) to notify workflow
   - Workflow receives BellSignal → pauses → waits for ResumeSignal
   - Log bell events at warning level (visible in logs tab)
   - Optional: show toast notification on bell (configurable)
   Tests: Manual test: trigger bell in terminal, verify workflow pauses
   Done when: Terminal bells propagate to Temporal workflows

** [#C] Create Temporal worker process
   Why: Workers execute workflow and activity code
   Change:
   - Create internal/temporal/worker.go with StartWorker(client, manager) error
   - Worker registers SessionWorkflow and all activities
   - Worker uses Manager to access terminal sessions for activities
   - Worker runs in separate goroutine, lifecycle tied to main process
   - Add graceful shutdown: stop worker before closing manager
   - Worker logs activity execution for debugging
   - Configure worker options: max concurrent activities, timeouts
   Tests: Start worker, verify workflows execute successfully
   Done when: Worker processes workflows and activities

** [#B] Create Flow tab for workflow visualization
   Why: Users need dedicated UI to monitor all active workflows and HITL pauses
   Change:
   - Add "Flow" tab to TabBar (after Dashboard, Plan, Logs tabs)
   - Create frontend/src/views/FlowView.svelte as main component
   - Display list of all active workflow sessions (not just current terminal)
   - For each workflow: session ID, agent name, current L1/L2 task, status badge
   - Status badges: running (green), paused (yellow), stopped (gray)
   - Click workflow to expand details: start time, event timeline, current output context
   - Paused workflows highlighted prominently with action buttons
   - Action buttons: Resume, Abort, View Terminal (switches to terminal tab)
   - Auto-refresh every 5s to show live workflow state
   - Empty state: "No active workflows" when no sessions using Temporal
   - Compact design: matches Plan and Logs tab styling
   Tests: Manual test: create workflow sessions, verify Flow tab displays them
   Done when: Flow tab shows all workflow sessions with status and actions

** [#C] Add workflow detail components
   Why: Flow tab needs detailed views for individual workflows
   Change:
   - Create frontend/src/components/WorkflowCard.svelte for list items
   - Create frontend/src/components/WorkflowDetail.svelte for expanded view
   - WorkflowCard: compact single-line display with expand button
   - WorkflowDetail: full timeline, bell events, task history, output snippets
   - Display bell context (last 50 lines of output that triggered pause)
   - Show pause duration and waiting time
   - Add copy button for workflow ID (for debugging with Temporal UI)
   - Link to Temporal UI: "View in Temporal" button (opens localhost:8233)
   Tests: Manual test: expand workflow details, verify all info displayed
   Done when: Flow tab has rich workflow detail views

** [#C] Implement resume actions for paused workflows
   Why: Users need to respond to bell-triggered pauses
   Change:
   - Add POST /api/terminals/:id/workflow/resume endpoint
   - Accept action parameter: "continue" (resume as-is), "abort" (terminate), "handoff" (future)
   - Send ResumeSignal to workflow with chosen action
   - Workflow resumes based on action: continue → unpause, abort → terminate workflow
   - Log resume actions for audit trail
   - Frontend: show resume buttons when workflow is paused
   - Future: "handoff" triggers another agent to take over (defer to later)
   Tests: Manual test: pause via bell, resume via UI, verify workflow continues
   Done when: Users can resume paused workflows

** [#C] Add workflow event history API
   Why: Users and admins need full audit trail of agent sessions
   Change:
   - Add GET /api/terminals/:id/workflow/history endpoint
   - Query Temporal for workflow execution history
   - Return events: task updates, bell events, pause/resume, signals
   - Format as JSON array with timestamps and event types
   - Optional: export as CSV for external analysis
   - Add WorkflowHistory.svelte component to display timeline
   Tests: Manual test: run workflow, view history, verify all events recorded
   Done when: Full workflow history is accessible via API and UI

** [#C] Configure workflow retry and timeout policies
   Why: Workflows need robust error handling and bounded execution
   Change:
   - Add workflow options: execution timeout (24 hours default)
   - Add activity retry policies: exponential backoff, max attempts
   - Add workflow retry policy: retry on transient failures
   - Add heartbeat timeout for long-running activities
   - Configure activity timeouts based on operation (spawn: 30s, read: 5s)
   - Document timeout policies in README
   Tests: Test timeout scenarios; verify retries work correctly
   Done when: Workflows have production-ready error handling

** [#C] Add workflow metrics and monitoring
   Why: Operators need visibility into workflow health
   Change:
   - Add Prometheus metrics for workflows: started, completed, failed, paused
   - Add metrics for activities: execution time, retry count, failure rate
   - Add GET /api/metrics endpoint exposing Prometheus format
   - Log workflow start/stop events at info level
   - Optional: integrate with Temporal's built-in observability
   - Document metrics in README
   Tests: Start workflows, verify metrics appear in /api/metrics
   Done when: Workflow metrics are exposed and documented

** [#C] Document Temporal integration
   Why: Users and contributors need to understand workflow system
   Change:
   - Add "Temporal Workflows" section to README.md
   - Document HITL workflow concept and benefits
   - Document how agent sessions map to workflows
   - Document L1/L2 task tracking and bell-triggered pauses
   - Document resume actions and future handoff capabilities
   - Document local deployment: temporal server start-dev with SQLite
   - Add architecture diagram showing workflow interaction with sessions
   - Link to Temporal docs for advanced usage
   Tests: None (documentation only)
   Done when: Temporal integration is fully documented

** [#C] Add workflow-managed session creation option
   Why: Users should choose whether to use Temporal workflows
   Change:
   - Add "workflow" boolean to POST /api/terminals request
   - If workflow=true, create session with Temporal workflow
   - If workflow=false, create standard session (current behavior)
   - Update agent profiles: add "use_workflow" boolean field
   - UI: checkbox on dashboard "Enable workflow tracking" (per agent or global)
   - Default: workflow disabled (opt-in) to avoid breaking existing usage
   Tests: Create both workflow and non-workflow sessions, verify both work
   Done when: Users can choose workflow mode per session

** [#B] Implement future handoff capability (deferred)
   Why: Bell stops should eventually trigger agent-to-agent handoffs
   Change:
   - Design handoff protocol: paused agent → new agent receives context + task
   - Add HandoffSignal(targetAgentID, context, reason string) to workflow
   - Implement agent selection logic: which agent to handoff to?
   - Create new workflow for target agent, link to original workflow
   - Transfer terminal control or create new terminal for handoff agent
   - This is future work; defer until core HITL is stable
   Tests: Design document and prototype; implementation TBD
   Done when: Handoff design documented (implementation deferred)

** [#B] Auto-manage Temporal dev server in .gestalt
   Why: Local dev should not require manual Temporal start/stop and should keep data under .gestalt/temporal
   Change:
   - Add config/env to enable Temporal dev server auto-management
   - On startup, spawn Temporal dev server with SQLite in .gestalt/temporal
   - Store Temporal logs, cache, and data under .gestalt/temporal
   - On shutdown, terminate the Temporal dev server cleanly
   - Keep existing manual workflow for users who prefer it
   Tests: Manual run; verify temporal files created under .gestalt/temporal and server stops on exit
   Done when: gestalt starts/stops Temporal dev server and persists data under .gestalt/temporal

** [#B] Default workflow tracking on
   Why: All sessions should be workflow-managed unless explicitly disabled
   Change:
   - Default workflow tracking to enabled when not specified
   - Keep API `workflow=false` and agent `use_workflow=false` as overrides
   - Keep GUI toggle; default to enabled when unspecified
   Tests: Start agent/terminal without options and confirm workflow appears; test explicit disable
   Done when: Unspecified sessions start workflows, with explicit disables honored

* TODO [#B] Enhanced input UX with multiline input box and command history
  Goal: Replace direct PTY keyboard input with a dedicated multiline input box at the bottom of agent pages, featuring browsable command history, future-proof for assisted input features, and independent clipboard handling.
  Notes:
  - Current state: all keyboard input is intercepted by terminalStore.js, only Ctrl+C and Ctrl+V handled externally
  - New approach: dedicated input box outside PTY, commands sent to PTY only on submission (Enter)
  - Input box: 3 lines default height, multiline capable, bottom of agent page (below terminal)
  - History navigation: Ctrl+Up/Down to browse previous commands (like readline but in-app)
  - History storage: in-memory circular buffer + file persistence (reuse OutputBuffer/SessionLogger patterns)
  - File format: logs/input-history/{agentName}-{timestamp}.jsonl (JSON lines, one command per line)
  - History grouping: by agent name when available; fallback to terminal ID for non-agent terminals
  - Future features enabled: search history, AI-assisted input, command review/editing, templates
  - PTY isolation: disable direct PTY keyboard input; input box is the only entry path
  - Backward compat: not required for this L1; prioritize readability and clean UX
  - Use Svelte best practices for multiline input: textarea with proper resize, autosize, or contenteditable
  - History buffer: 1000 commands default (configurable), persist to disk async
  - Navigation: Ctrl+Up (previous), Ctrl+Down (next), Enter (submit), Shift+Enter (newline in multiline)
  - Empty commands not recorded in history (skip whitespace-only)
  Date: 2025-12-31

** DONE [#B] Create input history buffer backend structure
   Why: Need reusable in-memory circular buffer for command history similar to OutputBuffer
   Change:
   - Create internal/terminal/input_buffer.go with InputBuffer struct
   - Similar to OutputBuffer: maxCommands int, entries []InputEntry, mutex for thread-safety
   - InputEntry fields: Command string, Timestamp time.Time
   - Methods: Append(command string), GetAll() []InputEntry, GetRecent(n int) []InputEntry
   - Skip empty/whitespace-only commands in Append
   - Trim whitespace from commands before storing
   - Default capacity: 1000 commands (DefaultInputBufferSize constant)
   - Thread-safe for concurrent access from WebSocket and persistence goroutines
   - Circular buffer behavior: oldest commands dropped when limit reached
   Tests: Unit tests for InputBuffer: append, circular behavior, concurrent access
   Done when: InputBuffer struct exists with tests matching OutputBuffer quality

** DONE [#B] Create input history persistence logger
   Why: Persist command history to disk for durability across restarts
   Change:
   - Create internal/terminal/input_logger.go with InputLogger struct (similar to SessionLogger)
   - File path: logs/input-history/{agentName}-{timestamp}.jsonl
   - One JSON object per line: {"command":"...","timestamp":"..."}
   - Async write via channel (reuse SessionLogger pattern: write channel, flush goroutine)
   - Flush policy: every 1s or after N commands (consistent with SessionLogger)
   - Create logs/input-history/ directory if missing
   - Handle errors gracefully: log warning, continue without persistence if file ops fail
   - Close/flush on session termination
   Tests: Unit tests for InputLogger; verify file creation and content
   Done when: Input history persists to disk asynchronously

** DONE [#B] Integrate input buffer into Session
   Why: Each terminal session needs its own input history
   Change:
   - Add InputBuffer and InputLogger fields to Session struct in internal/terminal/session.go
   - Initialize InputBuffer and InputLogger in newSession() (alongside OutputBuffer/SessionLogger)
   - InputLogger uses same logs/input-history/ directory (configurable via env var)
   - Use agent name for history file prefix when available, fallback to terminal ID otherwise
   - Expose input history via Session methods: RecordInput(command string), GetInputHistory() []InputEntry
   - RecordInput: appends to buffer and writes to logger
   - Handle nil InputLogger gracefully if persistence disabled
   - Add env var: GESTALT_INPUT_HISTORY_PERSIST (default true), GESTALT_INPUT_HISTORY_DIR (default logs/input-history)
   Tests: Session tests verify input recording and retrieval
   Done when: Sessions track and persist input history

** DONE [#B] Add REST API endpoint for input history
   Why: Frontend needs to fetch command history for navigation
   Change:
   - Add GET /api/terminals/:id/input-history endpoint in internal/api/routes.go
   - Query parameters: limit (default 100), since (timestamp/index for pagination)
   - Return JSON array of commands: [{command: string, timestamp: ISO8601}, ...]
   - Read from session.InputBuffer.GetRecent(limit)
   - Timestamps: track command submission time (InputBuffer InputEntry)
   - Handle session not found errors
   - Auth: same as other terminal endpoints (token-based)
   Tests: API tests for input-history endpoint
   Done when: Frontend can fetch command history via REST

** DONE [#B] Create multiline input component
   Why: Need UI component for command input at bottom of terminal page
   Change:
   - Create frontend/src/components/CommandInput.svelte
   - Use <textarea> with rows={3} for 3-line default height
   - Props: terminalId, onSubmit callback, disabled state
   - Styling: match terminal theme (dark background, light text, monospace font)
   - Auto-resize: consider textarea autosize behavior (expand on content, max height)
   - Placeholder: "Type command... (Enter to submit, Shift+Enter for newline)"
   - Submit behavior: Enter key (without Shift) submits, calls onSubmit(value), clears textarea
   - Shift+Enter: inserts newline (standard multiline textarea behavior)
   - Focus behavior: auto-focus on mount, restore focus after submission
   - Styling: border, padding, consistent with terminal shell styling
   Tests: Manual test: type commands, submit, verify clearing and focus
   Done when: CommandInput component renders and submits input

** DONE [#B] Add history navigation to CommandInput
   Why: Users need Ctrl+Up/Down to browse command history
   Change:
   - Maintain history array in component state (fetched from API)
   - Track current history index (starts at -1, meaning no history navigation)
   - Fetch history on mount: call GET /api/terminals/:id/input-history
   - Store fetched history in local state for navigation
   - Keydown handler: detect Ctrl+ArrowUp and Ctrl+ArrowDown
   - Ctrl+Up: navigate backwards (index++), load command into textarea
   - Ctrl+Down: navigate forwards (index--), restore empty or latest command
   - Edge behavior: at oldest command, Ctrl+Up does nothing; at newest, Ctrl+Down restores empty
   - Reset index to -1 after submission (fresh command)
   - Handle empty history gracefully (no navigation)
   Tests: Manual test: submit commands, use Ctrl+Up/Down to navigate
   Done when: History navigation works with Ctrl+Up/Down

** DONE [#B] Wire CommandInput into Terminal.svelte layout
   Why: Input box needs to appear at bottom of terminal page
   Change:
   - Modify Terminal.svelte to add CommandInput below terminal body
   - Layout: CSS Grid with rows: header (auto) / terminal body (1fr) / input (auto)
   - Input area: fixed height based on CommandInput (3 lines default)
   - Pass terminalId prop to CommandInput
   - onSubmit handler: send command to PTY via existing sendData/WebSocket
   - Ensure terminal and input are visually distinct: border/separator between them
   - Responsive: input box should work on mobile (adjust height/font size)
   Tests: Manual test: render terminal with input box, submit commands
   Done when: Input box appears at bottom and sends commands to PTY

** DONE [#B] Send submitted commands to PTY with newline
   Why: Commands from input box need to execute in the shell
   Change:
   - onSubmit handler in Terminal.svelte receives command string
   - Append '\n' to command before sending to PTY (shell needs newline to execute)
   - Use existing terminalStore sendData mechanism: state.sendData(command + '\n')
   - Handle multiline commands: preserve internal newlines, append final newline
   - Record command in session history: POST to /api/terminals/:id/input-history
   - Update local history state in CommandInput after submission
   Tests: Manual test: submit commands, verify execution in PTY, check history
   Done when: Commands from input box execute in shell

** DONE [#B] Add POST endpoint to record input history
   Why: Frontend needs to record commands in backend history
   Change:
   - Add POST /api/terminals/:id/input-history endpoint
   - Request body: {command: string}
   - Call session.RecordInput(command) to store in buffer and persist
   - Return success or error response
   - Validation: reject empty commands (trimmed whitespace check)
   - Auth: same token-based auth as other endpoints
   Tests: API tests for POST input-history endpoint
   Done when: Frontend can record commands via REST

** DONE [#B] Disable direct PTY keyboard input
   Why: Ensure all input flows through CommandInput for a clean, consistent UX
   Change:
   - Remove or gate terminalStore.js key handlers that send keystrokes to PTY
   - Keep copy selection behavior and output rendering intact
   - Ensure Ctrl+C no longer sends to PTY from the terminal canvas
   - Document the new interaction model in README or UI hint text if needed
   Tests: Manual test: typing in terminal canvas does nothing; CommandInput works
   Done when: PTY only receives input from the CommandInput component
   - This is future work; current implementation keeps PTY input for compatibility
   - Add option to disable term.onData handler in terminalStore.js
   - Make input box the sole input method (no direct keyboard to PTY)
   - Requires testing with various shells and use cases
   - Consider escape hatch: Ctrl+Shift+I to toggle direct input mode
   - Document input isolation mode in README when implemented
   Tests: Manual test with input-only mode; verify no direct PTY input
   Done when: PTY input can be optionally disabled (deferred)

** TODO [#C] Add input history search functionality (future)
   Why: Users may want to search through command history
   Change:
   - Add search input box above CommandInput (or modal dialog)
   - Filter history by substring match
   - Show filtered results with highlighting
   - Select result to populate CommandInput
   - This is future enhancement; basic navigation is sufficient initially
   Tests: Manual test search and selection
   Done when: History search is functional (deferred)

** TODO [#C] Add AI-assisted input features (future)
   Why: Enable future features like command suggestions, templates, corrections
   Change:
   - Integration point: CommandInput can call AI APIs for suggestions
   - Examples: command completion, syntax checking, template expansion
   - This is future work enabled by input box architecture
   - Document architecture for extensions in README
   Tests: None (future work)
   Done when: Architecture documented for AI-assisted input (deferred)

** TODO [#C] Add input history cleanup policy
   Why: Prevent unbounded disk usage from command history files
   Change:
   - Reuse session log cleanup logic from persistence.go
   - Cleanup policy: keep last N files per terminal, or files from last 7 days
   - Run cleanup goroutine in Manager (similar to session log cleanup)
   - Make retention configurable: GESTALT_INPUT_HISTORY_RETENTION_DAYS (default 7)
   - Log cleanup actions at info level
   Tests: Create old files, run cleanup, verify deletion
   Done when: Old input history files are cleaned up automatically

** TODO [#C] Document input history system
   Why: Users and contributors need to understand input box and history
   Change:
   - Add "Command Input and History" section to README.md
   - Document input box usage: Enter to submit, Shift+Enter for multiline, Ctrl+Up/Down for history
   - Document history persistence: file format, location, retention policy
   - Document configuration: env vars for history dir, persistence, retention
   - Document REST API endpoints: GET/POST /api/terminals/:id/input-history
   - Document future features: search, AI-assisted input, PTY isolation
   Tests: None (documentation only)
   Done when: Input history system is fully documented

* DONE [#B] Embed all resources into gestalt binary
  Goal: Make gestalt binary fully self-contained by embedding frontend dist/, config/agents/, config/prompts/, and config/skills/ so it can run from anywhere without external files.
  Notes:
  - Use Go 1.16+ embed.FS for embedding files at compile time
  - Embed frontend/dist/ (built frontend assets)
  - Embed config/agents/*.json, config/prompts/*.txt, config/skills/*/ (default configs)
  - External override directory: ./gestalt/ (relative to binary location)
  - Runtime override: if ./gestalt/config/ exists, use it instead of embedded
  - Search order: ./gestalt/config/agents → embedded config/agents (same for prompts, skills)
  - Log which source is used: "using embedded config" or "using external config at ./gestalt/"
  - Update loaders to accept io.FS interface for embedded or real filesystem
  - Keep PLAN.org external (runtime-only, not embedded)
  - --extract-config flag writes all embedded resources to ./gestalt/ (config + frontend dist)
  - Extraction creates: ./gestalt/config/agents/, ./gestalt/config/prompts/, ./gestalt/config/skills/, ./gestalt/dist/
  Date: 2026-01-07

** Update agent loader to support embed.FS
   Why: Agent loader needs to read from embedded filesystem or real filesystem
   Change:
   - Add io.FS parameter to agent.Loader.Load()
   - Use fs.ReadDir and fs.ReadFile instead of os.ReadDir/os.ReadFile
   - Keep backward compatibility: if FS is nil, use os.DirFS as default
   - Update internal/agent/loader.go Load signature and implementation
   - Pass prompts directory as separate FS or combined with agents
   Tests: Unit tests with embed.FS mock; verify existing tests still pass
   Done when: Agent loader works with both embedded and real filesystems

** Update skill loader to support embed.FS
   Why: Skill loader needs to read from embedded filesystem
   Change:
   - Add io.FS parameter to skill.Loader.Load()
   - Use fs.ReadDir, fs.ReadFile, fs.Sub for nested directories
   - Support skills with scripts/, references/, assets/ from embedded FS
   - Keep backward compatibility: if FS is nil, use os.DirFS
   - Update internal/skill/loader.go
   Tests: Unit tests with embed.FS; verify nested directory handling
   Done when: Skill loader works with embedded filesystem

** Create embedded resources in cmd/gestalt/embed.go
   Why: Single place to define all embedded resources
   Change:
   - Create cmd/gestalt/embed.go with //go:embed directives
   - Embed frontend/dist/* as frontendFS (embed.FS)
   - Embed config/agents as agentsFS
   - Embed config/prompts as promptsFS
   - Embed config/skills as skillsFS
   - Export embedded FS variables or getter functions
   - Document each embedded directory in comments
   Tests: Build and verify embedded files are in binary (check binary size)
   Done when: All resources are embedded at compile time

** Update main.go to use embedded or external resources
   Why: Support runtime override of embedded defaults from ./gestalt/ directory
   Change:
   - Check if ./gestalt/config/agents/ exists; if yes, use os.DirFS("./gestalt/config")
   - If not, use embedded configFS from embed.go
   - Log decision: "using embedded config" or "using external config at ./gestalt/config"
   - Pass appropriate FS to agent and skill loaders
   - Check ./gestalt/dist/ for frontend; if exists, use it; else use embedded frontendFS
   - Update findStaticDir to return "./gestalt/dist" if it exists
   - Serve embedded frontend via http.FS if no ./gestalt/dist/
   Tests: Run binary with/without ./gestalt/ directory; verify correct source used
   Done when: Binary prefers ./gestalt/ overrides but falls back to embedded

** Update API static handler to serve embedded frontend
   Why: Serve embedded frontend when no external dist/ directory
   Change:
   - Modify RegisterRoutes to accept embed.FS for frontend
   - If staticDir is empty, check if embedded frontendFS is available
   - Use http.FileServer(http.FS(frontendFS)) for embedded serving
   - Ensure SPA routing works with embedded FS (index.html fallback)
   - Keep existing SPAHandler logic compatible
   Tests: Test static file serving with embedded FS
   Done when: Embedded frontend serves correctly via HTTP

** Add --extract-config CLI flag
   Why: Users may want to customize embedded defaults
   Change:
   - Add --extract-config flag to main.go
   - Extract all embedded resources to ./gestalt/ directory
   - Create: ./gestalt/config/agents/, ./gestalt/config/prompts/, ./gestalt/config/skills/
   - Create: ./gestalt/dist/ (frontend assets)
   - Write all embedded files preserving directory structure
   - Skip if files already exist (or add --force flag to overwrite)
   - Print extraction summary: "Extracted N agents, M prompts, P skills, frontend assets to ./gestalt/"
   - Exit after extraction (don't start server)
   Tests: Run gestalt --extract-config; verify ./gestalt/ structure created
   Done when: Users can extract all embedded resources to ./gestalt/ for customization

** Update Makefile build to ensure frontend is built
   Why: Embedded frontend requires dist/ to exist at build time
   Change:
   - Update make gestalt target to depend on frontend build
   - Add target: make build-frontend (cd frontend && npm run build)
   - Ensure make gestalt runs build-frontend first
   - Document build order in Makefile comments
   - Consider: make gestalt-dev (no embed) vs make gestalt (with embed)
   Tests: make clean && make gestalt; verify binary works standalone
   Done when: make gestalt produces fully self-contained binary

** Document embedded binary usage
   Why: Users need to understand embedded vs external config behavior
   Change:
   - Add "Embedded Resources" section to README.md
   - Document: binary contains default config and frontend
   - Document: ./gestalt/ directory overrides embedded defaults
   - Document: search order: ./gestalt/config → embedded config
   - Document: --extract-config flag to extract all resources to ./gestalt/
   - Document: how to build from source with embedding
   - Show example: copy gestalt binary anywhere and run
   - Show example: gestalt --extract-config, then customize ./gestalt/config/
   Tests: None (documentation only)
   Done when: README explains embedded resources and ./gestalt/ override

** Test standalone binary deployment
   Why: Verify binary truly works outside source tree
   Change:
   - Build binary: make gestalt
   - Copy to /tmp/gestalt-test/ (clean directory)
   - Run from there: ./gestalt (should use embedded resources)
   - Verify: frontend loads, agents/skills available, terminals work
   - Test: ./gestalt --extract-config (creates ./gestalt/ directory)
   - Modify ./gestalt/config/agents/example.json
   - Restart: ./gestalt (should use ./gestalt/config/)
   - Verify: modified config is active
   Tests: Integration test of standalone deployment and override
   Done when: Binary runs with embedded defaults and ./gestalt/ overrides work

* DONE [#B] gestalt-send CLI tool and agent instance management
  Goal: Create a CLI tool for piping stdin to agent terminals (e.g., `cat file | gestalt-send agent-name`), ensure agent profiles have unique names, enforce single-instance agents (only one terminal per agent), and use agent names for tab labels instead of "Terminal 1/2/3".
  Notes:
  - CLI tool: gestalt-send command that reads stdin and sends to agent's PTY via REST API
  - Usage: `cat file | gestalt-send architect` or `echo "command" | gestalt-send copilot`
  - Target agent by name (not terminal ID) for ease of use
  - Agent name uniqueness: enforce at load time in agent.Loader, reject duplicate names
  - Single-instance agents: Manager tracks agent→terminal mapping, prevent duplicate agent starts
  - Tab labeling: use agent.Name instead of generic "Terminal N"
  - API: add POST /api/agents/:name/input endpoint to send data to agent's terminal
  - If agent not running: return 404 or optionally auto-start (configurable)
  - Authentication: gestalt-send uses GESTALT_TOKEN env var (same as server)
  - Server URL: gestalt-send uses GESTALT_URL env var (default http://localhost:8080)
  - CLI flags: --url, --token, --start (auto-start agent if not running)
  - Error handling: clear messages if agent not found, not running, or network errors
  - Build: add cmd/gestalt-send/main.go, build with `make gestalt-send`
  - Install: copy binary to PATH or document usage from repo
  Date: 2025-12-31

** [#B] Enforce unique agent names in agent loader
   Why: Agent names must be unique to support instance management and CLI tool
   Change:
   - Modify internal/agent/loader.go Load() function
   - Track seen agent names during load, detect duplicates
   - If duplicate name found: return error with both file paths
   - Error message: "Duplicate agent name 'copilot' in files: agents/a.json, agents/b.json"
   - Validation happens after all files are parsed but before returning map
   - Use case-sensitive name comparison (names must match exactly)
   - Add unit test for duplicate detection with temp agent files
   Tests: Loader test with duplicate agent names; verify error returned
   Done when: Agent loader rejects duplicate names with clear error

** [#B] Add agent instance tracking to Manager
   Why: Enforce single-instance agents (only one terminal per agent)
   Change:
   - Add field to Manager: agentSessions map[string]string (agentName → terminalID)
   - Update Manager.Create() to check if agent already has a running terminal
   - If agentSessions[agentName] exists: return error ErrAgentAlreadyRunning
   - On session creation: record agentSessions[agentName] = session.ID
   - On session deletion: remove agentSessions[agentName]
   - Add method Manager.GetSessionByAgent(agentName string) (*Session, bool)
   - Handle case where agent profile is nil (non-agent terminals, allow multiple)
   - Thread-safe: protect agentSessions with Manager.mu mutex
   Tests: Manager tests for duplicate agent prevention, cleanup on delete
   Done when: Manager prevents duplicate agent instances

** [#B] Update createTerminal API to handle duplicate agents
   Why: REST API needs to return appropriate error for duplicate agents
   Change:
   - Modify internal/api/rest.go createTerminal handler
   - Catch terminal.ErrAgentAlreadyRunning error from Manager.Create()
   - Return 409 Conflict with message: "Agent 'name' is already running in terminal ID"
   - Include existing terminal ID in error response for frontend
   - Update error type: add Field string to apiError for terminal_id
   - Frontend can use this to switch to existing terminal tab instead of failing silently
   Tests: API integration test for duplicate agent creation
   Done when: API returns 409 for duplicate agents with terminal ID

** [#B] Update frontend to use agent name for tab labels
   Why: Tab labels should show agent name, not "Terminal N"
   Change:
   - Modify frontend/src/App.svelte openTerminalTab() or tab creation logic
   - Currently: `label: terminal.title || Terminal ${terminal.id}`
   - Change to prioritize agent name: if terminal has agent, use agent.name
   - Backend already sets Title from agent.Name in Manager.Create()
   - Verify terminal.title comes from API response correctly
   - Keep fallback for non-agent terminals: "Terminal {id}"
   Tests: Frontend unit test for tab label selection (agent title vs fallback), run `npm test -- tests/app.test.js`
   Done when: Agent terminal tabs display agent name

** [#B] Handle duplicate agent in frontend gracefully
   Why: When duplicate agent detected, switch to existing tab instead of error toast
   Change:
   - Modify Dashboard.svelte createTerminal() handler
   - Catch 409 response from POST /api/terminals
   - Parse terminal_id from error response
   - Find existing tab with that terminal ID and switch to it
   - Show info toast: "Agent 'name' is already running" (not error)
   - Optional: add visual feedback (tab highlight/flash)
   Tests: Frontend unit test for 409 handling (switch to existing tab + info toast), run `npm test -- tests/app.test.js`
   Done when: Duplicate agent creation switches to existing tab

** [#B] Add REST API endpoint for sending input to agent by name
   Why: CLI tool needs to send data to agent without knowing terminal ID
   Change:
   - Add POST /api/agents/:name/input endpoint in internal/api/routes.go
   - Look up agent terminal using Manager.GetSessionByAgent(name)
   - If not found: return 404 "Agent 'name' is not running"
   - Read request body as raw bytes (stdin data)
   - Write to session.input channel (same as WebSocket input)
   - Content-Type: application/octet-stream or text/plain
   - Return 200 OK with bytes written count
   - Auth: require token (same as other endpoints)
   Tests: API integration test for agent input endpoint
   Done when: API endpoint accepts input for agent by name

** [#B] Create gestalt-send CLI binary structure
   Why: Need separate CLI tool for piping data to agents
   Change:
   - Create cmd/gestalt-send/main.go
   - CLI flags: --url (default $GESTALT_URL or http://localhost:8080)
   - CLI flags: --token (default $GESTALT_TOKEN)
   - CLI flags: --start (auto-start agent if not running, future feature)
   - Positional arg: agent name (required)
   - Usage: gestalt-send [flags] <agent-name>
   - Read stdin until EOF using io.Copy or bufio.Reader
   - Basic structure: flag parsing, stdin read, HTTP POST
   - Exit codes: 0 (success), 1 (usage error), 2 (agent not found), 3 (network error)
   Tests: Go unit test for CLI arg parsing/usage errors in cmd/gestalt-send; run `go test ./cmd/gestalt-send`
   Done when: CLI binary structure exists with flag handling

** [#B] Implement stdin-to-HTTP POST in gestalt-send
   Why: Core functionality: pipe stdin to agent terminal via API
   Change:
   - Read stdin: io.ReadAll(os.Stdin) or streaming with bufio
   - Build URL: {baseURL}/api/agents/{agentName}/input
   - Create HTTP POST request with Authorization: Bearer {token}
   - Set Content-Type: application/octet-stream
   - Body: stdin bytes
   - Send request using http.DefaultClient with timeout (30s)
   - Handle responses: 200 (success), 404 (agent not running), 401 (auth), 500 (server error)
   - Print errors to stderr with helpful messages
   Tests: Go unit test with httptest server validating POST payload and exit codes, run `go test ./cmd/gestalt-send`
   Done when: stdin data is sent to agent terminal successfully

** [#B] Resolve agent name or id in gestalt-send
   Why: Allow CLI input to match either agent ID or agent name.
   Change:
   - Query /api/agents and resolve input to agent ID + agent name.
   - If input matches agent ID, use corresponding agent name for /api/agents/:name/input.
   - If input matches agent name, use corresponding agent ID for /api/terminals (auto-start).
   - If input matches both with different agents, return a clear error.
   - Cache agent list for 60s (reuse completion cache dir or in-memory).
   Tests: Go unit test for name/id resolution and ambiguous cases; run `go test ./cmd/gestalt-send`
   Done when: CLI accepts either id or name without ambiguity.

** [#C] Add auto-start option to gestalt-send (optional)
   Why: Convenience feature to start agent if not already running
   Change:
   - Add --start flag to gestalt-send CLI
   - If POST /api/agents/:name/input returns 404 and --start is set:
   - Call POST /api/terminals with agent name to create terminal
   - Retry POST /api/agents/:name/input after short delay (1s)
   - Handle race condition if another process starts agent simultaneously
   - This is optional enhancement; basic version requires agent running
   Tests: Manual test with --start flag
   Done when: Auto-start flag creates agent terminal if missing (optional)

** [#C] Add verbose and debug output to gestalt-send
   Why: Help users diagnose connection and authentication issues
   Change:
   - Add --verbose flag: print HTTP request/response details to stderr
   - Add --debug flag: print full request body preview (first 100 bytes)
   - Show: URL, token (masked), response status, bytes sent
   - Do not print sensitive data (full token) unless --debug explicitly set
   - Use structured output: "Sending N bytes to agent 'X' at URL..."
   Tests: Manual test with --verbose and --debug flags
   Done when: CLI provides helpful diagnostic output

** [#C] Build and install gestalt-send in Makefile
   Why: Users need easy way to build and install CLI tool
   Change:
   - Add gestalt-send target to GNUmakefile
   - Build: go build -o gestalt-send cmd/gestalt-send/main.go
   - Add to default build target (alongside gestalt server)
   - Add install target: copy gestalt-send to /usr/local/bin or ~/.local/bin
   - Document in README: make gestalt-send, sudo make install
   - Consider: version stamping with ldflags (same as server)
   Tests: make gestalt-send; verify binary works
   Done when: gestalt-send builds via Makefile

** [#C] Add shell completion for gestalt-send (optional)
   Why: Improve CLI UX with agent name tab-completion
   Change:
   - Generate bash/zsh completion scripts
   - Completion: fetch agent names from GET /api/agents
   - Cache agent names for 60s to avoid repeated API calls
   - Install completion: gestalt-send completion bash > /etc/bash_completion.d/gestalt-send
   - This is optional enhancement for better UX
   Tests: Manual test tab-completion in bash/zsh
   Done when: Shell completion works for agent names (optional)

** [#C] Document gestalt-send usage and examples
   Why: Users need to understand CLI tool usage patterns
   Change:
   - Add "gestalt-send CLI Tool" section to README.md
   - Document installation: make gestalt-send, copy to PATH
   - Document environment variables: GESTALT_URL, GESTALT_TOKEN
   - Document usage: cat file | gestalt-send agent-name
   - Add examples: piping file contents, command output, multi-line input
   - Example use cases: send logs to agent, feed data for analysis, scripting
   - Document error codes and troubleshooting
   - Document --start flag (if implemented)
   Tests: None (documentation only)
   Done when: gestalt-send is fully documented with examples

** [#C] Add integration test for end-to-end CLI workflow
   Why: Verify complete workflow from CLI to agent terminal
   Change:
   - Create test: start server, create agent terminal, run gestalt-send
   - Verify data appears in terminal output buffer
   - Test error cases: agent not found, wrong token, network errors
   - Use temp config directory with test agent profiles
   - Clean up terminals after test
   Tests: Integration test in cmd/gestalt-send/
   Done when: End-to-end CLI test passes reliably


* DONE [#B] Agent Skills integration
  Goal: Integrate the Agent Skills standard (agentskills.io) into Gestalt to provide agents with discoverable, on-demand capabilities through structured skill packages stored in config/skills/
  Notes:
  - Agent Skills are folders containing SKILL.md (YAML frontmatter + Markdown instructions)
  - Progressive disclosure: load metadata at startup, full instructions on activation
  - Skills can include optional directories: scripts/, references/, assets/
  - Each skill has: name, description (for discovery), license, compatibility, metadata
  - Agents in config/agents/*.json can reference skills via "skills": ["skill-name", ...]
  - Skill metadata injected into agent system prompt for discovery
  - When agent activates a skill, full SKILL.md is provided to the LLM
  - Scripts in skills/ can be executed by the agent
  - Reference files loaded on-demand to save context
  - Validation: skill names must match directory names, required frontmatter fields
  - Security: consider sandboxing script execution, logging, confirmation prompts
  - Integration approach: filesystem-based (agents use shell commands to access skills)
  - Skills are portable, versionable, and shareable across different agent tools
  Date: 2025-12-31

**  [#B] Create skill data structure and parser
   Why: Need to parse SKILL.md frontmatter and validate skill format
   Change:
   - Create internal/skill/ package with Skill struct
   - Fields: Name, Description, License, Compatibility, Metadata (map), AllowedTools ([]string)
   - Fields: Path (skill directory), Content (markdown body after frontmatter)
   - Add YAML frontmatter parser (use gopkg.in/yaml.v3 for minimal dependency)
   - Parse both frontmatter and body content from SKILL.md
   - Validate: name format (lowercase, hyphens, 1-64 chars, no leading/trailing hyphen)
   - Validate: description (1-1024 chars, non-empty)
   - Validate: name matches parent directory name
   - Add optional validation for scripts/, references/, assets/ directories
   - Document skill struct in internal/skill/doc.go
   Tests: Unit tests for parsing valid/invalid SKILL.md files, validation edge cases
   Done when: Skill struct exists with YAML parsing and validation

**  [#B] Implement skill loader from config/skills/
   Why: Load skill packages from filesystem at startup
   Change:
   - Create skill.Loader with Load(dir string) (map[string]*Skill, error)
   - Scan config/skills/*/ directories for SKILL.md files
   - Parse each SKILL.md into Skill struct (frontmatter + body)
   - Use directory name as skill ID, validate against frontmatter name
   - Return map[skillID]*Skill for easy lookup
   - Handle errors: missing SKILL.md, invalid YAML, validation failures
   - If config/skills/ doesn't exist, return empty map (not an error)
   - Log warnings for invalid skills but don't fail entire load
   - Check for optional directories (scripts/, references/, assets/)
   Tests: Unit tests with temp directories; valid/invalid skill structures
   Done when: Loader successfully reads skill packages from directory

**  [#B] Wire skill loader into Manager initialization
   Why: Manager needs access to skills for agent initialization
   Change:
   - Add Skills field to ManagerOptions: map[string]*skill.Skill
   - Load skills in cmd/gestalt/main.go before creating Manager
   - Pass skills to Manager via ManagerOptions
   - Store skills in Manager struct for lookup during terminal creation
   - Add method Manager.GetSkill(name string) (*Skill, bool)
   - Add method Manager.ListSkills() []SkillMetadata (for API)
   Tests: Integration test verifying Manager has skills after init
   Done when: Manager has access to loaded skill packages

**  [#B] Extend agent profiles to reference skills
   Why: Agents need to declare which skills they have access to
   Change:
   - Add Skills field to Agent struct: []string `json:"skills"`
   - Skills field is optional array of skill names
   - Validate skill references during agent load: warn if skill doesn't exist
   - Store resolved skill references in agent for prompt generation
   - Update example agent configs to demonstrate skills usage
   - Example: "skills": ["git-workflows", "code-review", "data-analysis"]
   Tests: Agent loader tests with valid/invalid skill references
   Done when: Agent profiles can declare skill dependencies

**  [#C] Generate skill metadata for agent prompts
   Why: Agents need skill discovery information in system prompt
   Change:
   - Create skill.GeneratePromptXML(skills []*Skill) string function
   - Generate XML format: <available_skills><skill><name>...</name><description>...</description><location>...</location></skill></available_skills>
   - Include absolute path to SKILL.md in <location> for filesystem access
   - Keep metadata concise (~50-100 tokens per skill)
   - Only include skills referenced by the agent (from agent.Skills array)
   - Document XML format for prompt injection
   Tests: Unit tests for XML generation with various skill sets
   Done when: Function generates proper XML for agent system prompts

**  [#B] Inject skill metadata into agent prompts
   Why: Agents must know which skills are available at startup
   Change:
   - Modify prompt injection logic in terminal/session.go
   - After shell starts, before custom prompts, inject skill metadata
   - Generate XML from agent's skill list: GeneratePromptXML(agent.Skills)
   - Write skill metadata as initial prompt content
   - Add delay (100ms) before custom prompts
   - Log skill injection at info level
   - Handle case where agent has no skills (skip injection)
   Tests: Manual test: create agent with skills, verify XML in terminal
   Done when: Skill metadata appears in agent terminal on startup

**  [#C] Add GET /api/skills endpoint
   Why: Frontend and external tools need to query available skills
   Change:
   - Add GET /api/skills REST endpoint
   - Return array of skill metadata: name, description, path, license
   - Optionally filter by agent: GET /api/skills?agent=copilot
   - Include skill directory structure info (has scripts, references, assets)
   - Add unit tests for endpoint
   Tests: GET /api/skills returns skill list with metadata
   Done when: API endpoint exposes available skills

**  [#C] Add GET /api/skills/:name endpoint
   Why: Agents/users may need to read full skill content
   Change:
   - Add GET /api/skills/:name endpoint
   - Return full skill details: metadata + markdown body + directory structure
   - Include list of files in scripts/, references/, assets/
   - Optionally: GET /api/skills/:name/files/:path to read specific files
   - Handle file not found errors gracefully
   Tests: GET /api/skills/:name returns complete skill information
   Done when: API endpoint exposes full skill content

**  [#C] Create example skills in config/skills/
   Why: Provide working examples for users
   Change:
   - Create config/skills/ directory
   - Add example skill: config/skills/git-workflows/SKILL.md
   - Add example skill: config/skills/code-review/SKILL.md
   - Add example skill: config/skills/terminal-navigation/SKILL.md
   - Each example includes: proper frontmatter, clear instructions, references
   - Optional: include example scripts in scripts/ directory
   - Document skill format in README.md
   Tests: Load examples; verify they parse correctly
   Done when: Example skills exist and demonstrate the format

**  [#C] Update frontend to display skills
   Why: Users should see which skills are available
   Change:
   - Add "Skills" section to Dashboard.svelte
   - Fetch skills via GET /api/skills on mount
   - Display skill cards: name, description, associated agents
   - Optional: clicking skill shows full SKILL.md content in modal
   - Show skill count in dashboard status
   - Update UI to show which skills an agent has when creating terminal
   Tests: Manual test skills display in UI
   Done when: Dashboard shows available skills

**  [#C] Document Agent Skills integration
   Why: Users and contributors need to understand skills system
   Change:
   - Add "Agent Skills" section to README.md
   - Document skill directory structure and SKILL.md format
   - Document how to create new skills
   - Document how to assign skills to agents
   - Link to agentskills.io specification
   - Document skill discovery and activation process
   - Add examples of skill usage patterns
   Tests: None (documentation only)
   Done when: Agent Skills system is fully documented

**  [#C] Add skill validation CLI command (optional)
   Why: Help users create valid skills
   Change:
   - Add CLI command: gestalt validate-skill <path>
   - Use internal/skill package to validate skill structure
   - Check frontmatter format, name rules, required fields
   - Check for optional directories and common mistakes
   - Print validation results and suggestions
   - Exit with code 0 (valid) or 1 (invalid)
   - Alternative: document using skills-ref CLI from agentskills.io
   Tests: Manual test with valid/invalid skill directories
   Done when: Users can validate skills before deployment (optional)

**  [#C] Consider script execution security (future)
   Why: Executing skill scripts has security implications
   Change:
   - Document security considerations in README
   - Consider: sandboxing, allowlisting, user confirmation prompts
   - Consider: logging all script executions for auditing
   - Consider: skill signature verification for trusted sources
   - This is future work; initial implementation trusts all skills in config/
   - Add warning in docs about only using trusted skills
   Tests: None (documentation and future planning)
   Done when: Security considerations documented (implementation deferred)

**  [#B] Fix skill prompt injection order and content
   Why: Skill metadata is being injected into terminal output before agent prompts; skill instructions should appear after prompts as a marked Skills section.
   Change:
   - Trace the prompt/skill injection path to confirm where terminal output is written.
   - Adjust ordering so agent prompt(s) run first, then insert a clear "Skills" section containing the full SKILL.md content.
   - Ensure metadata XML stays in the LLM system prompt only (not written to the terminal).
   Tests: Manual check: startup shows agent prompt first, then skills section with SKILL.md content.
   Done when: Terminal startup output order matches expected prompt -> skills section, and XML metadata is not printed to the terminal.

**  [#B] Update available_skills metadata format and stop terminal printing
   Why: Skills should be provided as metadata-only context (name + description), not printed to the terminal.
   Change:
   - Replace the current skill metadata format with the requested <available_skills> block lines (name + description).
   - Ensure the metadata is injected only into the skill tool description/system prompt, never written to the terminal.
   - Keep the UI subtitle for skills in the terminal header.
   - Update tests to cover the new metadata format and ensure no terminal writes.
   Tests: Unit test for metadata formatting; manual check that terminal output no longer prints skills.
   Done when: Skill metadata uses the new format and terminal output stays clean.

* DONE [#B] Terminal history persistence across disconnects
  Goal: Preserve terminal output history when users disconnect and reconnect, allowing them to see what happened while they were away.
  Notes:
  - Current problem: OutputBuffer (1000 lines) exists in memory but xterm.js instance is fresh on reconnect
  - When WebSocket connects, it only receives new output (fire-and-forget broadcast)
  - Users lose scrollback history if they close browser or reload page
  - Existing GET /api/terminals/:id/output endpoint returns buffer lines but frontend doesn't use it
  - Solutions considered:
    1. Simple: Fetch buffer via REST on connect, write to xterm before attaching WebSocket
    2. Enhanced: Persist to disk (logs/sessions/{id}.txt), survive server restarts
    3. Hybrid: In-memory buffer + optional disk persistence (configurable)
  - Decision: Start with solution 1 (REST fetch on connect), then add optional disk persistence
  - Disk format: logs/sessions/{terminalId}-{timestamp}.txt with append-only writes
  - Cleanup policy: keep last N sessions per terminal, or files from last 7 days
  - Performance: async file writes, buffered I/O, don't block terminal operations
  Date: 2025-12-30

** Wire existing /output endpoint into frontend on connect
   Why: Backend already buffers 1000 lines; frontend just needs to fetch and display them
   Change:
   - In terminalStore.js, fetch GET /api/terminals/{id}/output before connecting WebSocket
   - Write buffered lines to xterm using term.write() or term.writeln()
   - Handle edge cases: empty buffer, API errors, slow responses
   - Add loading state: "Loading history..." status message
   - Preserve terminal state: don't clear xterm on reconnect
   - Consider: ANSI escape sequences in buffer may need processing
   Tests: Manual test: connect, type output, disconnect, reconnect → verify history appears
   Done when: Reconnecting shows buffered output from OutputBuffer

** Add optional disk persistence for terminal output
   Why: Survive server restarts and provide longer history than in-memory buffer
   Change:
   - Create internal/terminal/persistence.go with SessionLogger
   - SessionLogger: async writer that appends to logs/sessions/{terminalId}-{timestamp}.txt
   - Hook into Session.broadcastLoop: write chunks to both Broadcaster and SessionLogger
   - Use buffered writer (bufio.Writer) with periodic flush (every 1s or 4KB)
   - Handle file creation errors gracefully: log warning, continue without persistence
   - Add Close() method to flush and close file on session termination
   Tests: Unit test SessionLogger; integration test verifies file contents
   Done when: Terminal output is written to disk asynchronously

** Load persisted history on session reconnect
   Why: Restore history beyond in-memory buffer limit after server restart
   Change:
   - On WebSocket connect, check if session file exists
   - If exists: read last N lines (e.g., 2000) from file
   - Send historical lines to subscriber before live output
   - Handle large files: use tail-like reading (seek to end, read backwards)
   - Combine with in-memory buffer: prefer buffer if available, fall back to file
   - Add GET /api/terminals/:id/history?lines=N endpoint for REST access
   Tests: Restart server, reconnect → verify persisted history loads
   Done when: Reconnect shows persisted history from disk

** Add session file cleanup policy
   Why: Prevent unbounded disk usage from accumulating session logs
   Change:
   - Create cleanup goroutine in Manager: runs hourly
   - Policy: keep last 5 sessions per terminal ID, or files modified in last 7 days
   - Delete oldest files that don't match retention policy
   - Make retention configurable: GESTALT_SESSION_RETENTION_DAYS (default 7)
   - Log cleanup actions at info level
   - Handle concurrent file access: ignore "file not found" errors during cleanup
   Tests: Create old files, run cleanup, verify correct files deleted
   Done when: Old session logs are automatically cleaned up

** Add configuration options for persistence
   Why: Users may want to disable persistence or tune buffer sizes
   Change:
   - Add env vars: GESTALT_SESSION_PERSIST (true/false), GESTALT_SESSION_DIR (default logs/sessions)
   - Add GESTALT_SESSION_BUFFER_LINES (default 1000) for in-memory buffer size
   - Document in README.md under configuration section
   - Make persistence opt-in or opt-out (decide based on disk usage concerns)
   - Add /api/status field showing persistence status
   Tests: Test with persistence disabled; verify no files created
   Done when: Persistence is configurable via env vars

** Optimize file I/O for high-throughput terminals
   Why: Avoid blocking or degrading terminal performance with disk writes
   Change:
   - Use channel-based async writes: SessionLogger has write channel (buffered)
   - Goroutine drains channel and writes to disk
   - If channel fills, drop oldest chunks (lossy under extreme load)
   - Add metrics: dropped chunks counter, flush latency
   - Consider: rotate files after size threshold (e.g., 10MB)
   Tests: Stress test with high output rate; verify no blocking
   Done when: Disk persistence doesn't impact terminal responsiveness

** Update frontend to indicate history loading state
   Why: Users should know when history is being loaded vs live output
   Change:
   - Add status indicator: "Loading history..." during fetch
   - Show visual separator between history and live output (optional)
   - Add timestamp annotations if loading persisted history
   - Handle slow history loads: timeout after 5s, show warning
   - Consider: virtualized scrolling for very long history
   Tests: Manual test with large history buffer
   Done when: Users see clear feedback during history load

* DONE [#B] Org-mode PLAN.org viewer component
  Goal: Add a pleasant, compact Svelte outliner component to visualize PLAN.org with foldable sections, syntax highlighting for TODO/WIP/DONE keywords, priorities, and eventual sidebar integration.
  Notes:
  - Target users: casual users who don't use Emacs org-mode
  - Style inspiration: Emacs org-mode rendering but more polished and user-friendly
  - Must support: folding/expanding headings, keyword highlighting (TODO/WIP/DONE), priority badges ([#A], [#B], [#C])
  - Must be compact: designed for eventual sidebar placement alongside terminals
  - Parser: lightweight custom parser (no external org-mode lib dependencies)
  - Features: collapse/expand all, collapse by level, keyword filtering, search (optional)
  - Interaction: click to expand/collapse, visual hierarchy with indentation
  - Backend: serve PLAN.org via GET /api/plan endpoint (read-only for now)
  - Frontend: new OrgViewer.svelte component, add "Plan" tab to dashboard
  - Future: editing support, sync with file changes, real-time updates
  Date: 2025-12-29

** [#B] Create backend endpoint to serve PLAN.org
   Why: Frontend needs access to PLAN.org contents via API
   Change:
   - Add GET /api/plan endpoint in api/routes.go
   - Read PLAN.org file from project root
   - Return raw text content with text/plain or application/json (wrap in {"content": "..."})
   - Handle file not found gracefully (return empty or error)
   - No auth required initially (read-only public data)
   - Consider: ETag/Last-Modified headers for caching
   Tests: GET /api/plan returns PLAN.org contents
   Done when: API endpoint serves PLAN.org file contents

** [#B] Create org-mode parser for outline structure
   Why: Need to parse org-mode syntax into structured data for rendering
   Change:
   - Create frontend/src/lib/orgParser.js
   - Parse org headings: detect * ** *** heading levels
   - Extract TODO keywords: TODO, WIP, DONE (configurable array)
   - Extract priority: [#A], [#B], [#C] patterns
   - Extract heading text (after keywords/priority)
   - Build tree structure: {level, keyword, priority, text, children, collapsed}
   - Parse body text: lines between headings belong to parent heading
   - Handle edge cases: empty lines, malformed headings, missing keywords
   - Return array of top-level nodes with nested children
   Tests: Unit tests with sample org-mode text; verify tree structure
   Done when: Parser converts org text to structured tree

** [#B] Create OrgViewer Svelte component
   Why: Main UI component for displaying parsed org-mode outline
   Change:
   - Create frontend/src/components/OrgViewer.svelte
   - Accept props: orgText (string) or orgTree (parsed structure)
   - If orgText provided, parse on mount using orgParser
   - Render tree recursively: OrgNode components for each heading
   - Styling: compact vertical spacing, clear hierarchy with indentation
   - Responsive: works in full tab or sidebar (flexible width)
   - Handle empty/loading state gracefully
   Tests: Manual rendering test with sample org-mode content
   Done when: Component renders parsed org-mode structure

** [#B] Create OrgNode component for heading rendering
   Why: Recursive component for each outline node with expand/collapse
   Change:
   - Create frontend/src/components/OrgNode.svelte
   - Props: node (heading data), level (indent depth), onToggle callback
   - Render: expand/collapse icon + keyword badge + priority badge + heading text
   - Expand icon: ▶ (collapsed) or ▼ (expanded), click to toggle
   - Keyword styling: TODO (blue), WIP (yellow/orange), DONE (green/gray), none (default)
   - Priority styling: [#A] (red), [#B] (orange), [#C] (gray/muted)
   - Body text: render in muted color below heading when expanded
   - Children: recursively render child nodes when expanded
   - Indentation: left padding based on level (e.g., level * 1.5rem)
   Tests: Manual test with nested headings, toggle behavior
   Done when: Individual nodes render with proper styling and expand/collapse

** [#C] Add expand/collapse controls
   Why: Users need convenient ways to navigate large outlines
   Change:
   - Add toolbar buttons: "Expand All", "Collapse All"
   - Add level-based collapse: "Collapse to L1", "Collapse to L2"
   - Implement recursive state updates in OrgViewer
   - Persist expand/collapse state in component state (not localStorage yet)
   - Keyboard shortcuts: Space to toggle focused node (optional)
   Tests: Manual test expand/collapse functionality
   Done when: Toolbar controls work correctly

** [#C] Add keyword filtering
   Why: Users may want to focus on TODO/WIP items only
   Change:
   - Add filter dropdown: "All", "TODO only", "WIP only", "DONE only", "TODO+WIP"
   - Filter at render time: hide nodes that don't match filter
   - Show/hide body text based on filter setting
   - Preserve expand/collapse state during filtering
   Tests: Manual test filtering with various keyword combinations
   Done when: Filter dropdown correctly shows/hides nodes

** [#C] Add search functionality (optional)
   Why: Large plans benefit from text search
   Change:
   - Add search input box in toolbar
   - Highlight matching text in headings and body
   - Auto-expand nodes containing matches
   - Clear highlights on search clear
   - Debounce search input (300ms)
   Tests: Manual test search with various queries
   Done when: Search highlights and expands matching nodes

** [#B] Integrate OrgViewer into dashboard
   Why: Users need access to plan viewer in the UI
   Change:
   - Add "Plan" tab to TabBar (after Dashboard, before terminal tabs)
   - Create PlanView.svelte wrapper component
   - Fetch /api/plan on mount, pass to OrgViewer
   - Handle loading and error states
   - Add refresh button to reload plan
   - Style consistent with rest of app
   Tests: Manual test Plan tab in UI
   Done when: Plan tab shows PLAN.org outline

** [#C] Polish styling and responsiveness
   Why: Ensure component is pleasant and usable as specified
   Change:
   - Refine color scheme: match Gestalt design language
   - Ensure compact spacing: maximize information density
   - Test in narrow sidebar width (e.g., 300px)
   - Smooth animations for expand/collapse (CSS transitions)
   - Hover effects on headings
   - Focus states for accessibility
   - Dark mode support (if app has dark mode)
   Tests: Manual visual testing at various widths
   Done when: Component looks polished and works in sidebar

** TODO [#C] Add CSS for compact sidebar layout (future)
   Why: Component should eventually work as sidebar alongside terminals
   Change:
   - Design sidebar layout: resizable splitter between plan and terminals
   - Add sidebar toggle button
   - Persist sidebar width and visibility in localStorage
   - Ensure terminals resize correctly when sidebar shown/hidden
   - This step is future work, not blocking initial implementation
   Tests: Manual test sidebar integration
   Done when: Plan viewer works as collapsible sidebar (defer to later)

* DONE [#A] Comprehensive testing strategy and regression protection
  Goal: Establish robust test coverage for all Gestalt features to prevent regressions and ensure reliability.
  Notes:
  - Current state: 11 test files, ~1939 lines of tests, all tests passing
  - Coverage: agent (excellent), api (good), logging (good), terminal (good), orchestrator (none), cmd (none)
  - Backend: 25 source files, 11 test files (44% file coverage, likely lower line coverage)
  - Frontend: No test infrastructure currently configured
  - Testing philosophy: pragmatic, focus on critical paths and integration points
  - Tools: Go standard testing + table-driven tests, consider testify/assert for readability
  - Frontend tools: Vitest + Svelte Testing Library (matches Vite/Svelte stack)
  - Integration: E2E tests for WebSocket flows, API interactions, terminal lifecycle
  - Strategy: unit tests for logic, integration tests for I/O and state, E2E for user flows
  Date: 2025-12-29

** [#B] Audit and document current test coverage
   Why: Understand what's tested, what's missing, establish baseline metrics
   Change:
   - Run `go test -cover ./...` and document coverage percentages per package
   - Identify untested packages: orchestrator (no tests), cmd/gestalt (no tests)
   - List critical untested code paths: prompt injection, session lifecycle, WebSocket reconnection
   - Document existing test patterns: fakePty, table-driven tests, integration test helpers
   - Create TESTING.md documenting testing approach, conventions, and how to run tests
   - Set coverage targets: aim for 70% overall, 80%+ for critical packages (agent, terminal, api)
   Tests: Document current coverage; no new tests in this step
   Done when: TESTING.md exists with coverage audit and testing guidelines

** [#B] Add missing unit tests for terminal package
   Why: Terminal session/manager is core functionality with some untested paths
   Change:
   - Test session lifecycle: creation, input/output, close, cleanup
   - Test prompt injection: single prompt, multiple prompts, missing files, timing
   - Test output buffer: circular behavior, line extraction, race conditions
   - Test broadcaster: multi-subscriber fanout, slow subscriber handling, close behavior
   - Test shell selection logic: SHELL env var, fallbacks, Windows vs Unix
   - Add table-driven tests for edge cases (empty input, large buffers, concurrent access)
   - Test onair_string detection and prompt injection gating
   Tests: Increase terminal package coverage to 80%+
   Done when: Critical terminal paths have test coverage; go test ./... passes

** [#B] Add unit tests for orchestrator package
   Why: Currently has no tests; future inter-terminal communication depends on it
   Change:
   - Test any existing orchestrator logic (currently minimal/stub)
   - If orchestrator is empty stub, add placeholder test file with package structure
   - Document intended orchestrator responsibilities in doc.go
   - Add tests as orchestrator features are implemented
   Tests: Basic orchestrator test file exists
   Done when: orchestrator package has test foundation ready for future features

** [#C] Add integration tests for cmd/gestalt
   Why: Main entry point has no tests; configuration loading and wiring needs validation
   Change:
   - Test config loading: env vars (PORT, SHELL, TOKEN), defaults
   - Test agent loading integration: valid/invalid agent files, missing prompts
   - Test static file serving: frontend dist directory detection
   - Consider: spin up test server, verify endpoints respond (heavy, may defer)
   - Document why some paths are hard to test (server startup, signal handling)
   Tests: Basic cmd/gestalt test coverage for config and initialization
   Done when: Config loading and agent wiring have test coverage

** [#B] Add WebSocket integration tests
   Why: WebSocket flows are critical but complex; need end-to-end validation
   Change:
   - Test terminal WebSocket: connect, send input, receive output, resize, disconnect
   - Test logs WebSocket: connect, receive log stream, filter by level, disconnect
   - Test auth: token validation, unauthorized access, missing token
   - Test reconnection: connection drop, exponential backoff, auth failure
   - Test concurrent connections: multiple clients to same terminal
   - Use gorilla/websocket test client or real WebSocket connections
   - Mock PTY for deterministic terminal output in tests
   Tests: WebSocket integration tests pass reliably
   Done when: Critical WebSocket paths tested; can detect regressions

** [#B] Setup frontend testing infrastructure
   Why: Frontend has zero tests; UI regressions go unnoticed
   Change:
   - Install Vitest: `npm install -D vitest @testing-library/svelte jsdom`
   - Configure vitest.config.js for Svelte component testing
   - Add test script to package.json: `"test": "vitest run"`
   - Create example test: terminalStore.test.js or api.test.js
   - Document frontend testing approach in TESTING.md
   - Consider: Playwright for E2E UI tests (defer if too heavy initially)
   Tests: npm test runs and passes
   Done when: Frontend test infrastructure is functional

** [#B] Add frontend unit tests for core modules
   Why: Store logic and API client are testable without full component rendering
   Change:
   - Test api.js: apiFetch error handling, buildWebSocketUrl, token handling
   - Test terminalStore.js: state management, WebSocket lifecycle, reconnection logic
   - Test notificationStore.js: add/dismiss/auto-dismiss, toast lifecycle
   - Mock fetch API and WebSocket for deterministic tests
   - Use vi.mock() for module mocking in Vitest
   Tests: Core frontend logic has unit test coverage
   Done when: API client and stores have 70%+ test coverage

** [#C] Add frontend component tests
   Why: UI components need testing but are lower priority than logic
   Change:
   - Test Dashboard.svelte: agent buttons, terminal creation, error display
   - Test TabBar.svelte: tab switching, close button, active state
   - Test Toast.svelte: display, auto-dismiss, dismiss button
   - Test LogsView.svelte: log filtering, refresh, display
   - Use @testing-library/svelte for component testing (render, user events)
   - Focus on behavior, not implementation details
   Tests: Key UI components have test coverage
   Done when: Dashboard and TabBar have basic component tests

** [#B] Add E2E integration test suite
   Why: Validate complete user flows across backend and frontend
   Change:
   - Setup E2E test harness: start server, create test client, cleanup
   - Test flow: start server → create terminal via API → connect WebSocket → send input → verify output
   - Test flow: create agent terminal → verify prompt injection → verify onair_string gating
   - Test flow: trigger log event → verify toast appears → verify log in logs tab
   - Test auth flow: missing token → 401 → provide token → success
   - Consider: Playwright for browser-based E2E (can defer if too heavy)
   - Document E2E test execution in TESTING.md
   Tests: E2E test suite passes reliably
   Done when: Critical user flows have E2E test coverage

** [#C] Add test coverage reporting and CI integration
   Why: Track coverage over time, prevent coverage regressions
   Change:
   - Setup Go coverage reporting: `go test -coverprofile=coverage.out ./...`
   - Setup frontend coverage: configure Vitest coverage (c8 or istanbul)
   - Add coverage thresholds: fail if coverage drops below targets
   - Consider: upload coverage to codecov.io or similar (optional)
   - Document coverage commands in TESTING.md
   - Add CI workflow if using GitHub Actions (run tests on PR/push)
   Tests: Coverage reports generate successfully
   Done when: Coverage tracking is automated and documented

** [#C] Add property-based and fuzz testing (optional)
   Why: Find edge cases that manual test cases miss
   Change:
   - Identify good candidates: agent JSON parsing, prompt name validation, log filtering
   - Use Go testing.F for fuzz testing (built into Go 1.18+)
   - Consider: rapid for property-based testing (external dep, may skip)
   - Add fuzz tests for JSON unmarshaling with malformed input
   - Add fuzz tests for path parsing with unusual characters
   - Document fuzz testing in TESTING.md
   Tests: Fuzz tests run and find no crashes
   Done when: Critical parsing logic has fuzz test coverage (optional)

** [#C] Document testing best practices and conventions
   Why: Maintain test quality as codebase grows
   Change:
   - Extend TESTING.md with best practices: table-driven tests, test naming, mocking
   - Document when to unit test vs integration test vs E2E test
   - Document test fixture patterns: fakePty, test servers, temp directories
   - Add examples of good tests from existing codebase
   - Document how to debug failing tests
   - Document test performance: keep unit tests fast (<10ms), integration tests moderate (<100ms)
   Tests: None (documentation only)
   Done when: TESTING.md has comprehensive testing guidelines

* DONE [#B] Fix agent shell args + toast-to-log parity
  Goal: Allow agent shell strings to include arguments, and ensure every toast is also logged.
  Notes:
  - Current agent shell field appears to be a single string passed to exec without args.
  - Desired: support space-separated args (and optionally quoted args) in the shell string.
  - Ensure frontend toasts also emit structured log entries so they appear in Logs view and /api/logs.
  - Keep behavior minimal and explicit; avoid new dependencies unless required.
** [#B] Support shell string arguments in agent config
   Why: Agents like copilot require a shell/command plus flags in config.
   Change:
   - Parse agent.Shell into command + args (define parsing rules, e.g., shlex-like or simple split)
   - Update session/terminal spawn to accept argv rather than only a single path
   - Update validation and tests for parsing edge cases
   Tests: Unit tests for parsing; go test ./...
   Done when: Agent shell config accepts args and agent launches correctly
** [#B] Log all toast notifications to backend logs
   Why: User-facing toasts must be discoverable in the Logs tab and /api/logs.
   Change:
   - Identify toast creation flow in frontend
   - Ensure each toast emission also creates a log entry (client-side via /api/logs or server-side via logger hooks)
   - Keep log level aligned with toast level
   Tests: Frontend behavior + backend log visibility; go test ./...
   Done when: Every toast is mirrored in backend logs

* DONE [#B] Multi-prompt injection on agent startup
  Goal: Extend agent configuration to support multiple prompts injected sequentially on terminal start.
  Notes:
  - Current: agent has "prompt_file" (string) that references a single file
  - Desired: agent has "prompt" field that can be string OR array of strings
  - Each string is a prompt name (not full path); resolve to config/prompts/{name}.txt
  - Example: "prompt": ["coder", "architect"] → inject coder.txt then architect.txt
  - Backward compatibility for "prompt_file" requires explicit decision
  - Prompts injected sequentially with small delay between each (e.g., 100ms)
  - Empty/missing prompt field means no injection (current default behavior)
  Date: 2025-12-29

** [#B] Confirm prompt_file compatibility decision
   Why: Avoid breaking existing configs without explicit approval
   Change: Decide whether to keep supporting "prompt_file" or remove it
   Tests: None (decision only)
   Done when: Compatibility approach is confirmed

** [#B] Update Agent struct to support prompt array
   Why: Need to accept both single string and array of strings for prompts
   Change:
   - Add new field: Prompts []string `json:"prompt"` to Agent struct
   - Remove PromptFile string `json:"prompt_file"` field entirely
   - Update Validate() to handle new format
   - Update JSON unmarshaling to accept both "prompt": "single" and "prompt": ["multi"]
   - Implement custom UnmarshalJSON if needed for flexible string/array parsing
   Tests: Unit tests for JSON parsing with string, array, empty, nil; validation logic
   Done when: Agent struct accepts prompt field as string or string array

** [#B] Update agent loader to resolve prompt names to paths
   Why: Prompts are stored as names but need to be validated/resolved to file paths
   Change:
   - Add PromptsDir parameter to Loader.Load() (default: "config/prompts")
   - After loading each agent JSON, validate that all prompt names exist as .txt files
   - Keep names in Agent struct; resolve paths during injection (more flexible)
   - Use structured logger to log warning if prompt file doesn't exist
   - Don't fail agent load on missing prompt (graceful degradation)
   - Update loader tests to check prompt file existence validation
   Tests: Unit tests with missing prompt files; verify warnings logged
   Done when: Loader validates prompt names against config/prompts/*.txt

** [#B] Implement sequential prompt injection in session startup
   Why: Multiple prompts need to be injected in order with proper timing
   Change:
   - Locate current prompt injection code (likely in terminal/session.go or manager.go)
   - Replace single prompt file read with loop over agent.Prompts
   - For each prompt name: resolve to config/prompts/{name}.txt, read contents, inject
   - Add configurable delay between prompts (default 100ms) to allow shell processing
   - Use structured logger for warnings if file missing/unreadable, continue with next prompt
   - Consider: inject after shell is ready (existing delay before first prompt)
   - Ensure newlines are properly handled (add \n at end if missing)
   Tests: Manual test with agent using multiple prompts; verify execution order
   Done when: Agent terminals execute all prompts in sequence on startup

** [#C] Update example agent configs to use new format
   Why: Demonstrate new prompt field format and provide working examples
   Change:
   - Update config/agents/*.json to use "prompt" field instead of "prompt_file"
   - Create example with single prompt: "prompt": "coder"
   - Create example with multiple prompts: "prompt": ["coder", "architect"]
   - Keep one example without prompts to show optional nature
   Tests: Load examples; verify they parse and execute correctly
   Done when: Example configs demonstrate new prompt field usage

** [#C] Update documentation for prompt configuration
   Why: Users need to understand new prompt field format and behavior
   Change:
   - Update README.md Agent Profiles section with prompt field documentation
   - Document both formats: "prompt": "single" and "prompt": ["multi"]
   - Document prompt resolution: names → config/prompts/{name}.txt
   - Document injection timing and sequential behavior
   Tests: None (documentation only)
   Done when: README clearly explains prompt field usage

** [#C] Delay initial prompt injection by 1s
   Why: Give shells time to initialize before prompt injection
   Change: Increase the initial prompt delay to 1s before the first prompt
   Tests: Go tests covering prompt injection timing
   Done when: First prompt waits ~1s before injection

** [#C] Inject trailing enter after prompts
   Why: Ensure shell executes prompts cleanly after all injections
   Change: Write a final newline after all prompts are injected
   Tests: Go tests for prompt injection order with trailing enter
   Done when: Prompt injection sends a trailing enter after the last prompt

** [#C] Ensure prompt injection sends terminal enter key
   Why: Some shells/CLI tools may require carriage return to submit input
   Change: Normalize prompt line endings and final enter to use terminal enter semantics
   Tests: Go tests verifying injected input uses the correct enter sequence
   Done when: Injected prompts are accepted by the LLM CLI

** [#C] Increase initial prompt delay to 3s
   Why: Some agents need more startup time before accepting prompt injection
   Change: Increase initial prompt delay from 1s to 3s
   Tests: Go tests covering prompt injection timing
   Done when: First prompt waits ~3s before injection

** [#B] Align injected enter with actual terminal input
   Why: Prompt text appears but is not submitted without manual Enter
   Change: Match injected enter sequence to what the web terminal sends (CR vs CRLF) and adjust prompt normalization
   Tests: Go tests to verify injected bytes match expected enter sequence
   Done when: Prompts submit without manual Enter across agents

** [#C] Delay final enter after prompt injection
   Why: Prompt text appears but enter may be arriving before the CLI is ready
   Change: Add a ~500ms delay before sending the final enter after all prompts
   Tests: Go tests covering prompt injection timing
   Done when: Prompts submit without manual Enter

** [#B] Pace prompt injection to mimic keystrokes
   Why: Prompt text appears but is not submitted; fast bulk writes may be treated differently
   Change: Write prompt content in small chunks with brief delays, then send a delayed enter
   Tests: Go tests for prompt injection ordering and final enter timing
   Done when: Prompts submit without manual Enter across agents

** [#B] Use raw prompt content with typed enter sequence
   Why: Copilot CLI may not accept normalized line endings
   Change: Stop normalizing prompt content; send raw bytes then a simulated enter sequence
   Tests: Go tests verifying raw prompt payload and enter write
   Done when: Copilot accepts injected prompts without manual Enter

** [#A] Gate prompt injection on onair_string output
   Why: Ensure prompts are only injected after the CLI is ready
   Change: Add per-agent onair_string configuration; wait for terminal output to contain it before injecting
   Tests: Go tests simulating output detection and deferred injection
   Done when: Prompt injection waits for onair_string before sending prompts

* DONE [#A] System logging and notification infrastructure
  Goal: Add comprehensive logging system with UI visibility through both toast notifications and dedicated logs tab.
  Notes:
  - Backend warnings (missing prompt files, agent load errors, etc.) must be visible in UI
  - Two-layer approach: ephemeral toasts for immediate feedback + persistent logs tab
  - Backend maintains circular log buffer accessible via REST API
  - Frontend uses Svelte store for notifications with auto-dismiss
  - Toast notifications: auto-dismiss after 3-5s (configurable), support info/warning/error levels
  - Logs tab: persistent view showing all system logs with filtering by level/time
  - WebSocket optional for real-time log streaming (can start with polling)
  - Log levels: DEBUG, INFO, WARNING, ERROR (standard severity)
  Date: 2025-12-29

** [#B] Create backend log buffer and structured logging
   Why: Need centralized log collection that both stdout and API can access
   Change:
   - Create internal/logging package with LogBuffer (circular buffer, thread-safe)
   - LogEntry struct: Timestamp, Level (debug/info/warning/error), Message, Context (map)
   - Default buffer size: 1000 entries (configurable)
   - Create Logger wrapper that writes to both stdout and LogBuffer
   - Replace log.Printf calls with structured logger throughout codebase
   - Logger methods: Debug(), Info(), Warn(), Error()
   - Include contextual fields (e.g., agent_id, terminal_id where relevant)
   Tests: Unit tests for LogBuffer thread-safety, circular behavior, entry limits
   Done when: All backend logging goes through structured logger with buffer

** [#B] Add REST endpoint for log retrieval
   Why: Frontend needs to fetch logs for display in logs tab
   Change:
   - Add GET /api/logs endpoint with query parameters: since (timestamp), level (filter), limit
   - Return JSON array of log entries with timestamp, level, message, context
   - Support pagination: last N entries or entries since timestamp
   - Default: return last 100 entries
   - Add filtering by log level (e.g., ?level=warning returns warning+error only)
   - Consider: HEAD request for log count or latest timestamp (polling optimization)
   Tests: REST endpoint tests with various query parameters
   Done when: Frontend can fetch filtered log history via REST

** [#C] Add WebSocket endpoint for real-time log streaming (optional)
   Why: Real-time log updates provide better UX than polling
   Change:
   - Add GET /ws/logs WebSocket endpoint for log streaming
   - Send log entries as JSON messages when they occur
   - Support client-side level filtering (client sends filter on connect)
   - Reuse existing WebSocket auth pattern (token in query param)
   - Handle subscriber cleanup on disconnect
   - Optional: implement later if REST polling is sufficient initially
   Tests: WebSocket connection test, message delivery test
   Done when: Logs stream to connected WebSocket clients in real-time

** [#B] Create frontend notification store
   Why: Centralized notification state management for toast display
   Change:
   - Create src/lib/notificationStore.js with Svelte writable store
   - Notification object: id, level, message, timestamp, autoClose, duration
   - Methods: addNotification(level, message, opts), dismiss(id), clear()
   - Auto-dismiss logic: setTimeout for toasts, optional permanent notifications
   - Default duration: 5000ms for info, 7000ms for warning, manual for error
   - Unique ID generation (timestamp + counter)
   - Export subscribe() for reactive updates
   Tests: Store tests for add/dismiss/auto-dismiss behavior
   Done when: Notification store manages toast lifecycle

** [#B] Create toast notification component
   Why: Visual display of ephemeral notifications
   Change:
   - Create src/components/Toast.svelte for individual toast
   - Create src/components/ToastContainer.svelte for positioning/stacking
   - Position: top-right or bottom-right corner (configurable)
   - Stack vertically with smooth enter/exit animations (slide + fade)
   - Visual styling: color-coded by level (info=blue, warning=yellow, error=red)
   - Include dismiss button (X) and auto-close progress indicator
   - Support click-to-dismiss
   - Accessibility: ARIA live region for screen readers
   Tests: Manual visual testing; verify animations and auto-dismiss
   Done when: Toasts display and auto-dismiss correctly

** [#B] Create logs tab view
   Why: Persistent access to system logs with filtering and search
   Change:
   - Create src/views/LogsView.svelte as dedicated tab
   - Add "Logs" tab to TabBar (between Dashboard and terminal tabs)
   - Display log entries in scrollable list/table: timestamp, level badge, message
   - Add level filter dropdown (All, Info, Warning, Error)
   - Add auto-refresh toggle (poll every 5s) and manual refresh button
   - Show entry count and latest update time
   - Expand log entry on click to show full context/details
   - Reverse chronological order (newest first)
   - Consider: virtualized scrolling for large log lists
   Tests: Manual testing with various log volumes and filters
   Done when: Logs tab displays backend logs with filtering

** [#B] Wire notifications into existing code paths
   Why: Emit notifications for key user-facing events
   Change:
   - Backend: emit warning logs for missing prompt files, agent load failures
   - Backend: emit info logs for terminal create/destroy, agent startup
   - Frontend: subscribe to notifications in App.svelte
   - Frontend: show toast on terminal connection errors, auth failures
   - Frontend: show toast on API errors (replace inline error text where appropriate)
   - Frontend: poll /api/logs on logs tab mount, display in LogsView
   - Optional: WebSocket log streaming if implemented
   Tests: Trigger various scenarios; verify toasts and logs appear
   Done when: Users see notifications for all important system events

** [#C] Add notification preferences (optional enhancement)
   Why: Users may want to customize notification behavior
   Change:
   - Add settings panel (modal or dedicated view) for notification prefs
   - Toggles: enable/disable toasts, auto-dismiss duration, log level filter
   - Store preferences in localStorage
   - Apply prefs to notification store configuration
   - Default: all notifications enabled
   Tests: Manual testing of preference persistence and application
   Done when: Users can customize notification behavior (optional)

** [#C] Update documentation for logging system
   Why: Developers and users need to understand logging capabilities
   Change:
   - Add "Logging and Notifications" section to README.md
   - Document log levels and when each is used
   - Document /api/logs endpoint and query parameters
   - Document toast notification behavior and auto-dismiss
   - Add screenshot or description of logs tab
   - Document how to add logs in backend code (logger usage)
   Tests: None (documentation only)
   Done when: Logging system is documented in README

* DONE [#B] Agent profiles system
  Goal: Allow customizable terminal configurations for AI agents stored as JSON files in config/agents/.
  Notes:
  - Each agent profile defines: shell/program, initial prompt file, terminal name, LLM type, LLM model
  - Agent profiles live in config/agents/ as JSON files (one per agent)
  - LLM types: copilot, codex, promptline (hardcoded for now)
  - LLM model: "default" for now (future: configurable)
  - Agent selection: via REST API (POST /api/terminals with "agent" parameter)
  - Default behavior: if no agent specified, use current shell-based creation
  - Initial prompt: if specified, write to terminal stdin after spawn
  - UI: one button per agent file, labeled with agent's name attribute
  Date: 2025-12-29

** [#B] Create agent data structure and JSON schema
   Why: Define the agent profile format before loading/using agents
   Change:
   - Create internal/agent/ package with Agent struct
   - Fields: Name (string), Shell (string), PromptFile (string), LLMType (string), LLMModel (string)
   - Add JSON tags for serialization: name, shell, prompt_file, llm_type, llm_model
   - Document schema with example JSON in agent/doc.go
   - Add validation: LLMType must be one of [copilot, codex, promptline]
   - Add validation: required fields (Name, Shell), optional (PromptFile)
   Tests: Unit test JSON marshaling/unmarshaling; validate edge cases
   Done when: Agent struct exists with JSON support and validation

** [#B] Implement agent loader from config/agents/
   Why: Load agent profiles from filesystem at startup
   Change:
   - Create agent.Loader with Load(dir string) (map[string]Agent, error)
   - Scan config/agents/*.json files
   - Parse each JSON file into Agent struct
   - Use filename (without .json) as agent ID
   - Return map[agentID]Agent for easy lookup
   - Handle errors: invalid JSON, validation failures, missing directory
   - If directory doesn't exist, return empty map (not an error)
   Tests: Unit tests with temp directories; valid/invalid JSON files
   Done when: Loader successfully reads agent profiles from directory

** [#B] Wire agent loader into Manager initialization
   Why: Manager needs access to agent profiles for terminal creation
   Change:
   - Add Agents field to ManagerOptions: map[string]agent.Agent
   - Load agents in cmd/gestalt/main.go before creating Manager
   - Pass agents to Manager via ManagerOptions
   - Store agents in Manager struct for lookup during Create
   - Add method Manager.GetAgent(id string) (Agent, bool)
   Tests: Integration test verifying Manager has agents after init
   Done when: Manager has access to loaded agent profiles

** [#B] Extend terminal creation API to accept agent
   Why: Frontend needs to specify which agent to use
   Change:
   - Extend createTerminalRequest to include Agent (optional string)
   - Modify Manager.Create signature: Create(agentID, role, title string) (*Session, error)
   - If agentID empty: use default behavior (current shell, no prompt, title/role as-is)
   - If agentID specified: lookup agent, use agent.Shell, override title with agent.Name
   - Pass agent to Session creation (extend newSession parameters)
   - Store agent reference in Session struct for later use
   Tests: REST API test with/without agent; verify correct shell launched
   Done when: POST /api/terminals accepts "agent" field

** [#C] Implement initial prompt injection
   Why: Agent profiles can specify a prompt file to execute on terminal start
   Change:
   - If agent.PromptFile is not empty, read file contents
   - After PTY starts, write prompt contents to session.input channel
   - Add newline at end if not present
   - Handle errors: file not found, read errors (log warning, continue)
   - Consider delay (50-100ms) after shell spawn before writing prompt
   Tests: Manual test with agent containing prompt file; verify execution
   Done when: Terminal executes prompt commands on startup

** [#C] Store LLM metadata in Session
   Why: Future features (orchestration, AI coordination) need to know terminal's LLM type/model
   Change:
   - Add LLMType and LLMModel fields to Session struct
   - Populate from agent profile during creation
   - Expose in SessionInfo for API responses
   - Extend terminalSummary JSON response to include llm_type and llm_model
   Tests: GET /api/terminals includes LLM metadata
   Done when: Session stores and exposes LLM configuration

** [#C] Add example agent profiles to config/agents/
   Why: Provide working examples for users
   Change:
   - Create config/agents/ directory
   - Add example agent profiles: copilot.json, codex.json, promptline.json
   - Each example uses /bin/bash (or appropriate shell)
   - Document agent profile format in main README.md
   Tests: Load examples; verify they parse correctly
   Done when: Example agent profiles exist and are documented

** [#C] Add GET /api/agents endpoint
   Why: Frontend needs to fetch available agent profiles
   Change:
   - Add GET /api/agents REST endpoint
   - Return array of agent metadata: id, name, llm_type, llm_model
   - Use Manager.Agents map to build response
   - Add unit tests for endpoint
   Tests: GET /api/agents returns agent list
   Done when: API endpoint exposes available agents

** [#C] Update frontend with agent buttons
   Why: Users need UI to spawn terminals with specific agents
   Change:
   - Fetch agents via GET /api/agents in Dashboard.svelte on mount
   - Render one button per agent using agent.name as button label
   - On button click: POST /api/terminals with {"agent": agentID}
   - Open new terminal tab after creation
   - Update terminal tab label to show agent.Name if used
   Tests: Manual test agent buttons in UI; verify correct terminal created
   Done when: Dashboard shows agent buttons; clicking spawns agent terminal

** [#B] Fix terminal tab close freeze and ensure deletion
   Why: Closing a tab freezes the UI and leaves a disconnected session
   Change:
   - Reproduce the close flow in App.svelte/TabBar.svelte
   - Ensure tab close triggers DELETE and removes the tab from UI
   - Fix any stale TerminalView/terminalStore references on close
   - Validate WebSocket shutdown cleanup on close
   Tests: npm run build; go test ./...
   Done when: Closing a tab removes it and the server session cleanly

* DONE [#B] Code quality: maintainability, clarity, and minimalism review
  Goal: Improve code maintainability, modularity, clarity, and minimize dependencies where practical.
  Notes:
  - Focus on making code easier to understand, modify, and extend without breaking things
  - Remove unnecessary complexity and improve separation of concerns
  - Better error handling and resource cleanup patterns
  - Evaluate if dependencies can be reduced (prefer stdlib when sufficient)
  - Document key architectural decisions inline
  - All changes must preserve existing functionality (zero regressions)
  Date: 2025-12-29

** [#C] Backend: improve error handling and resource cleanup
   Why: Several functions ignore errors; goroutine cleanup paths unclear; better patterns improve robustness
   Change:
   - session.Write currently drops errors silently; add error return or log
   - Review session close: ensure all 3 goroutines terminate cleanly on Close()
   - Add context-based cancellation for clean shutdown
   - Audit all defer statements for proper error handling
   - Add error wrapping with context where helpful
   Tests: go test ./...; verify no test regressions
   Done when: Error paths properly handled; goroutine lifecycle is clear and leak-free

** [#C] Backend: evaluate gorilla/websocket dependency
   Why: Minimalism goal; check if golang.org/x/net/websocket or stdlib alternatives sufficient
   Change:
   - Research: does gorilla provide critical features we need? (check origin, control frames, etc)
   - If x/net/websocket is sufficient, migrate to reduce dependencies
   - If gorilla is best choice, document why (e.g., better API, production-ready, control frame handling)
   - Decision: keep or replace, but document the reasoning
   Tests: go test ./...; manual WebSocket connection test if migrating
   Done when: Dependency decision documented; migration complete if chosen

** [#C] Backend: improve modularity in manager and session
   Why: Manager and Session mix multiple concerns; better separation aids testing and future changes
   Change:
   - Extract broadcast/subscriber logic into separate Broadcaster type
   - Consider separating Manager's ID generation, session registry, and lifecycle management
   - Make Session goroutine coordination more explicit (use explicit done channels, context)
   - Add state machine to Session (e.g., connecting → ready → closing → closed)
   - Reduce coupling: Session shouldn't need to know about subscribers; Broadcaster should
   Tests: go test ./...; maintain or improve test coverage
   Done when: Each type has single clear responsibility; easier to modify independently

** [#C] Backend: clarify Windows PTY support and build tags
   Why: Windows returns stub error; status unclear to users/contributors
   Change:
   - Add detailed doc comment in pty_windows.go explaining ConPTY implementation status
   - Document options: implement ConPTY, use github.com/UserExistsError/conpty, or stay stub
   - Add build tag documentation explaining Unix vs Windows behavior
   - If keeping stub, improve error message to guide Windows users
   Tests: Build on Windows; verify error message is helpful
   Done when: Windows support status is crystal clear; path forward documented

** [#C] Backend: refactor API handlers for clarity
   Why: REST handlers mix parsing, validation, auth, business logic; hard to test and modify
   Change:
   - Extract middleware: authMiddleware, loggingMiddleware, jsonErrorMiddleware
   - Create path parsing helpers with unit tests (parseTerminalPath is buried in handler)
   - Centralize validation (e.g., validateTerminalID, validateCreateRequest)
   - Standardize JSON error responses (consistent structure)
   - Consider thin handler layer that delegates to service methods
   Tests: Add unit tests for parsing and validation; go test ./...
   Done when: Handlers are <20 lines; logic is tested; auth/validation centralized

** [#C] Frontend: fix terminal lifecycle to preserve state on tab switch
   Why: Terminal.svelte recreates xterm on every mount; destroys on unmount; loses state
   Change:
   - Move terminal instance ownership to parent or store (don't create in component)
   - Terminal.svelte becomes presentation-only: receives term instance, renders it
   - Preserve WebSocket connections across tab switches or implement reconnection
   - Use CSS display:none for hidden terminals instead of destroying components
   Tests: npm run build; manual tab switching; verify terminal state preserved
   Done when: Switching tabs keeps terminal scrollback and state intact

** [#C] Frontend: remove unused dependencies
   Why: Minimalism; addon-attach is installed but not imported anywhere
   Change:
   - Remove @xterm/addon-attach from package.json (unused)
   - Evaluate @xterm/addon-fit: it's ~10 lines of math; could inline if desired
   - If keeping addon-fit, document why (convenience, maintenance, tested)
   - Check for other unused dependencies
   Tests: npm run build; manual resize test
   Done when: Only necessary deps remain; decision documented if keeping addon-fit

** [#C] Frontend: improve WebSocket error handling
   Why: Connection failures show generic "disconnected"; no retry logic; poor UX
   Change:
   - Add exponential backoff reconnection for WebSocket failures
   - Show user-friendly messages: "Connecting...", "Connection lost, retrying...", "Connected"
   - Handle auth failures (401) differently from network errors
   - Add manual reconnect button after repeated failures
   - Log errors to console for debugging
   Tests: npm run build; manual test with network interruption
   Done when: Users get clear feedback; auto-reconnect works for transient failures

** [#C] Documentation: add architectural inline comments
   Why: Code lacks context on design decisions; onboarding is harder than needed
   Change:
   - Add package doc comments to internal/terminal, internal/api, internal/orchestrator
   - Document goroutine coordination pattern in session.go (who owns what, shutdown order)
   - Explain WebSocket control message protocol in terminal_handler.go
   - Document thread-safety guarantees in Manager (what locks protect what)
   - Add comment explaining why we use fan-out pattern for subscribers
   Tests: None (documentation only)
   Done when: Key patterns and decisions are documented; code is self-explanatory

** [#C] Testing: improve coverage and testability
   Why: Some code paths untested; mocking is hard; no integration tests
   Change:
   - Add tests for parseTerminalPath, validateToken, path parsing edge cases
   - Make Manager testable: inject clock interface for testing timeouts/timestamps
   - Add table-driven tests for shell selection logic
   - Create integration test: spawn terminal, connect WebSocket, send/receive data
   - Document testing approach in README or TESTING.md
   Tests: go test ./...; verify coverage increases
   Done when: Critical paths tested; testing strategy documented

* DONE [#A] Initial project structure with multi-terminal dashboard
  Goal: Set up Gestalt IDE foundation with Go backend, Svelte frontend, and WebSocket-based terminal management system that supports inter-terminal communication.

  Notes:
  - Terminals are not just user-interactive but can read/write to each other
  - AI agents (like Copilot) should be able to monitor and inject commands into terminals
  - Dashboard shows splash page with status + terminal tabs
  - Architecture must be modular from the start to support terminal orchestration
  - Use github.com/creack/pty for PTY management
  - Use gorilla/websocket for WebSocket handling
  - Keep dependencies minimal
  - Decisions confirmed: repo layout = cmd/gestalt + internal, terminal IDs = short incremental, auth = origin checks + token
  - Decisions confirmed: Windows PTY = ConPTY only (no fallback), auth token = Bearer header for REST and WS, Windows shell = system default unless overridden
  - Decisions pending/implicit: shell selection policy on Unix (use $SHELL vs fallback), WebSocket control framing (text JSON for control + binary for data), bell handling (client-side on xterm onBell)
  - Frontend choice: use Vite + Svelte (not SvelteKit) for a lighter integration with Go server

** Set up Go backend structure and dependencies
   Why: Need the server foundation before implementing terminal logic
   Change:
   - Initialize go.mod with module name
   - Decide repo layout (e.g., cmd/gestalt/main.go + internal/{api,terminal,orchestrator})
   - Create main.go with basic HTTP server and config (port, shell command, auth token)
   - Add OS-aware shell default (use $SHELL on Unix; configurable fallback on Windows)
   - Add gorilla/websocket and creack/pty dependencies
   - Create modular package structure:
     - terminal/ - PTY and terminal session management
     - api/ - HTTP/WebSocket handlers
     - orchestrator/ - Inter-terminal communication logic (stub for now)
   Tests: Server starts and responds on port 8080
   Done when: Go project compiles, dependencies resolved, basic server runs

** Implement terminal session manager with inter-terminal awareness
   Why: Core abstraction for managing multiple terminal instances and their communication
   Change:
   - Create terminal/session.go with Terminal session struct
   - Each terminal has: ID, PTY, input/output channels, metadata (including role/purpose)
   - Create terminal/manager.go to track all active sessions
   - Manager provides: Create, Get, List, Delete operations
   - Add hooks for inter-terminal communication (Reader/Writer interfaces or fan-out)
   - Support terminal output broadcast to multiple listeners
   - Define lifecycle rules (close cleanup, optional idle timeout)
   - Decide output buffer size/format for later API (lines vs bytes)
   - Implement incremental ID generator (atomic counter) with string rendering
   Tests: Can create multiple terminal sessions, list them, retrieve by ID
   Done when: Manager can spawn/track terminals with communication hooks

** Implement WebSocket terminal bridge
   Why: Connect browser frontend to backend PTY sessions
   Change:
   - Create api/terminal_handler.go for WebSocket upgrade
   - Implement bidirectional bridge: WebSocket ↔ PTY (binary data frames)
   - Define control message framing for resize (text JSON messages, e.g. {"type":"resize","cols":...,"rows":...})
   - Handle terminal resize events (apply to PTY; SIGWINCH optional)
   - Support multiplexing: one WebSocket can subscribe to terminal output (fan-out)
   - Add basic origin checks (and optional token auth if required)
   - Add endpoints: /ws/terminal/:id for connecting to specific terminal
   Tests: Can connect via WebSocket, send input, receive output
   Done when: WebSocket bidirectionally bridges to PTY with resize support

** Create REST API for terminal management
   Why: Dashboard needs to query status and create/delete terminals
   Change:
   - Create api/routes.go with REST endpoints
   - GET /api/terminals - list all terminals with metadata
   - POST /api/terminals - create new terminal session
   - DELETE /api/terminals/:id - terminate terminal
   - GET /api/status - system status (terminal count, etc)
   - Define response schema (id, title, role, created_at, status)
   - Require token for REST endpoints (Authorization header or query param)
   Tests: Can create/list/delete terminals via REST API
   Done when: All CRUD operations work via HTTP

** Initialize Svelte frontend structure
   Why: Need frontend framework before building UI components
   Change:
   - Use Vite + Svelte (not SvelteKit) for minimal integration with Go server
   - Run `npm create vite@latest frontend -- --template svelte`
   - Install xterm.js and addons: xterm, xterm-addon-fit, xterm-addon-attach
   - Configure Vite to proxy API calls to Go backend (port 8080)
   - Create basic app structure with routing (splash, terminal views)
   Tests: Frontend dev server runs, builds successfully
   Done when: Svelte app runs with xterm.js dependencies installed

** Build splash page dashboard component
   Why: Entry point showing system status and terminal management
   Change:
   - Create Dashboard.svelte component
   - Fetch /api/status and /api/terminals on mount
   - Display: terminal count, system info, list of active terminals
   - Add "New Terminal" button (calls POST /api/terminals)
   - Style with minimal CSS (clean, functional)
   Tests: Dashboard loads, shows correct terminal count, button creates terminal
   Done when: Splash page displays status and can create terminals

** Build terminal tab component with xterm.js
   Why: Display interactive terminals in browser
   Change:
   - Create Terminal.svelte component
   - Initialize xterm.js instance with fit addon
   - Connect to WebSocket /ws/terminal/:id (send resize control JSON on fit)
   - Handle terminal resize on window resize
   - Hook xterm onBell for bell interception/notifications
   - Implement terminal cleanup on component destroy
   Tests: Terminal renders, accepts input, displays output correctly
   Done when: Fully interactive terminal works in browser

** Implement tab switching UI
   Why: Users need to switch between multiple terminals
   Change:
   - Create TabBar.svelte component
   - Maintain array of open terminal tabs (IDs + labels)
   - Switch active terminal on tab click
   - Add close button per tab (calls DELETE /api/terminals/:id)
   - Keep splash page as special "tab 0"
   Tests: Can switch between splash and terminal tabs, close tabs
   Done when: Tab navigation works smoothly

** Wire up complete application flow
   Why: Connect all pieces into working application
   Change:
   - Create App.svelte as main component orchestrator
   - Manage global state: active terminals, current tab
   - Route between splash and terminal views
   - Handle terminal creation → open new tab → connect WebSocket
   - Serve frontend build from Go backend in production
   Tests: Full flow works: splash → create terminal → interact → switch tabs → close
   Done when: Complete application runs end-to-end

** Add basic inter-terminal read capability (foundation)

** Preserve terminal screen buffer across tab switches
   Why: Switching away and back currently wipes the terminal display while the session is still running.
   Change: Rework terminal view lifecycle so xterm DOM/state is preserved or restored on tab reselect (avoid dispose on hide or buffer snapshot/restore).
   Tests: Manual verify tab switching retains visible terminal content; existing go tests still pass.
   Done when: Returning to a terminal shows the same screen contents without requiring a reflow or replay.
   Why: Lay groundwork for terminal orchestration features
   Change:
   - Add GET /api/terminals/:id/output endpoint (recent output buffer)
   - Each terminal maintains circular buffer of recent output (~1000 lines)
   - Document API for reading terminal state (for future AI agent integration)
   - Add metadata field for terminal "role" or "purpose" (future use)
   Tests: Can retrieve recent output from terminal via API
   Done when: API endpoint returns buffered terminal output
