* DONE [#A] Event-based filesystem monitoring with WebSocket notifications
  Goal: Replace polling with an event-driven filesystem monitoring component that uses fsnotify to watch files and notify the frontend via WebSocket when changes occur.
  Notes:
  - Core component: internal/watcher package with reusable Watch service
  - Use github.com/fsnotify/fsnotify (de-facto standard, cross-platform, stable, actively maintained)
  - Architecture: Watch service → event hub → WebSocket broadcaster
  - WebSocket endpoint: /ws/events for real-time notifications to frontend
  - Event types: file_changed, git_branch_changed (extensible for future events)
  - First use case: PLAN.org live updates (replace 5s polling in PlanView)
  - Second use case: git branch monitoring (live updates in Dashboard)
  - Internal API: watcher.Watch(path, callback) returns handle for cleanup
  - Frontend: single WebSocket connection handles all filesystem events
  - Thread-safe: concurrent watchers, multiple subscribers, graceful shutdown
  - Error handling: log warnings on watch failures, auto-restart watcher on error
  - Resource limits: max watched files (configurable), cleanup on unsubscribe
  - Git branch detection: watch .git/HEAD + .git/refs/heads/* for branch changes
  - Event payload: {"type": "file_changed", "path": "PLAN.org", "timestamp": "..."}
  - Minimize dependencies: fsnotify only (stdlib for everything else)
  - Testing: mock fsnotify for unit tests, integration tests with real files
  Date: 2026-01-08

** [#B] Evaluate and add fsnotify dependency
   Why: Need cross-platform filesystem watching; fsnotify is the standard Go library for this
   Change:
   - Research: fsnotify vs alternatives (stdlib has none, inotify is Linux-only, kqueue is BSD-only)
   - fsnotify abstracts platform differences (inotify/kqueue/ReadDirectoryChangesW)
   - Mature library: v1.7.0, 9k+ stars, used by Docker/Kubernetes/etc
   - Add dependency: go get github.com/fsnotify/fsnotify@latest
   - Document in README: why fsnotify chosen (cross-platform, stable, standard)
   - Check license: BSD 3-Clause (compatible with AGPL)
   Tests: go mod tidy; verify module resolves
   Done when: fsnotify added as dependency with justification documented

** [#B] Create internal/watcher package structure
   Why: Need reusable abstraction for filesystem watching
   Change:
   - Create internal/watcher/ package with doc.go documenting purpose
   - Define Watch interface: Watch(path string, callback func(Event)) (Handle, error)
   - Define Event struct: Path, Op (create/write/remove/rename/chmod), Timestamp
   - Define Handle interface: Close() error for cleanup
   - Create Watcher struct wrapping fsnotify.Watcher
   - Thread-safe design: mutex protecting watched paths and callbacks
   - Support multiple callbacks per path (fan-out pattern)
   - Document design: event delivery guarantees, error handling, cleanup
   Tests: Package structure compiles; interfaces defined
   Done when: Watcher package structure exists with documented interfaces

** [#B] Implement core Watcher with fsnotify integration
   Why: Bridge fsnotify events to Gestalt's callback architecture
   Change:
   - Implement New() (*Watcher, error) that creates fsnotify.Watcher
   - Implement Watch(path, callback) that calls fsnotify.Add(path)
   - Start event loop goroutine reading from fsnotify.Events channel
   - On fsnotify event: look up registered callbacks, invoke each
   - Handle fsnotify.Errors channel: log warnings, attempt recovery
   - Implement Close() that stops fsnotify watcher and event loop
   - Add WatchDir option for recursive directory watching (future)
   - Debounce rapid events: 100ms window to collapse duplicate events
   - Tests: Unit tests with mock filesystem (os.CreateTemp, write, remove)
   Done when: Watcher receives fsnotify events and dispatches to callbacks

** [#B] Add event hub for centralized event management
   Why: Decouple watchers from WebSocket broadcasting
   Change:
   - Create internal/watcher/hub.go with EventHub struct
   - EventHub maintains: map of watched paths, registered listeners
   - Method: Subscribe(eventType string, listener func(Event)) → subscription ID
   - Method: Unsubscribe(id string) for cleanup
   - Method: Publish(Event) to notify all subscribers for event type
   - Event types: file_changed, git_branch_changed, (extensible)
   - EventHub wraps Watcher and translates low-level fs events to domain events
   - Add context support for graceful shutdown
   - Tests: Unit tests for subscribe/publish/unsubscribe
   Done when: EventHub can manage subscriptions and fan-out events

** [#B] Implement WebSocket /ws/events endpoint
   Why: Frontend needs real-time event notifications
   Change:
   - Add /ws/events WebSocket endpoint in internal/api/routes.go
   - On connect: subscribe client to EventHub
   - On event: send JSON message to WebSocket client
   - Message format: {"type": "file_changed", "path": "PLAN.org", "timestamp": "2026-01-08T12:00:00Z"}
   - Support client-side filtering: client sends {"subscribe": ["file_changed", "git_branch_changed"]}
   - Handle client disconnect: unsubscribe from EventHub
   - Reuse existing WebSocket auth pattern (token in query param)
   - Add rate limiting: max 100 events/minute per client (prevent abuse)
   - Tests: WebSocket connection test, event delivery test
   Done when: /ws/events streams filesystem events to connected clients

** [#B] Implement PLAN.org file watching
   Why: First use case - live updates for Plan tab
   Change:
   - In cmd/gestalt/main.go: watch PLAN.org file on startup
   - Register callback with EventHub to publish file_changed events
   - Handle PLAN.org creation/deletion gracefully (re-watch if recreated)
   - Add GET /api/plan ETag header (hash of file content) for efficient polling fallback
   - Log watch activation: "Watching PLAN.org for changes"
   - Tests: Integration test: modify PLAN.org, verify event fired
   Done when: PLAN.org changes trigger file_changed events

** [#B] Update PlanView to use WebSocket events
   Why: Replace polling with event-based updates
   Change:
   - Remove 5s polling interval in frontend/src/views/PlanView.svelte
   - Connect to /ws/events on component mount
   - Subscribe to file_changed events for PLAN.org
   - On event: fetch updated content via GET /api/plan
   - Show subtle notification: "Plan updated" (auto-dismiss)
   - Handle WebSocket disconnection: reconnect with exponential backoff
   - Fallback: if WebSocket unavailable, revert to 10s polling (degraded mode)
   - Tests: Manual test: edit PLAN.org, verify UI updates immediately
   Done when: Plan tab updates instantly when PLAN.org changes

** [#B] Implement git branch monitoring
   Why: Second use case - live git branch updates in Dashboard
   Change:
   - Create internal/watcher/git.go with GitWatcher
   - Watch .git/HEAD file for branch changes
   - Parse .git/HEAD: "ref: refs/heads/main" → extract branch name
   - Handle detached HEAD state (HEAD contains commit SHA)
   - Watch .git/refs/heads/* for new branches (optional, future)
   - On change: publish git_branch_changed event with branch name
   - Add to EventHub on startup if .git directory exists
   - Handle non-git repos gracefully (skip watching, no errors)
   - Tests: Unit tests with temp git repo, simulate branch change
   Done when: Git branch changes trigger git_branch_changed events

** [#B] Add git origin and branch to /api/status
   Why: Dashboard needs current git context
   Change:
   - Extend statusResponse in internal/api/rest.go: GitOrigin, GitBranch strings
   - Read git origin from .git/config: parse [remote "origin"] section
   - Read git branch from .git/HEAD (reuse GitWatcher logic)
   - Cache on startup, update on git_branch_changed events
   - Handle errors gracefully: empty strings if not git repo
   - Add working_dir field (already in plan) for full context
   - Tests: API test with/without git repo; go test ./internal/api
   Done when: GET /api/status returns git origin and current branch

** [#B] Update Dashboard to show git branch live
   Why: Users need to see current git context in Dashboard
   Change:
   - Add git origin/branch display to Dashboard.svelte status section
   - Show: "origin/branch-name" in compact format
   - Connect to /ws/events on Dashboard mount
   - Subscribe to git_branch_changed events
   - On event: update status display without full page refresh
   - Style: monospace font, subtle color, near working directory
   - Handle missing git info: show "not a git repo" or hide section
   - Tests: Manual test: git checkout, verify Dashboard updates
   Done when: Dashboard shows live git branch without polling

** [#C] Add configurable watcher limits and cleanup
   Why: Prevent resource exhaustion from too many watchers
   Change:
   - Add GESTALT_MAX_WATCHES env var (default 100)
   - Track active watch count in Watcher
   - Return error if max watches exceeded
   - Implement periodic cleanup: remove watchers with no subscribers
   - Add metrics: active watches, events delivered, errors
   - Log watcher lifecycle: add/remove at debug level
   - Document limits in README under configuration
   Tests: Test watch limit enforcement; verify cleanup works
   Done when: Watcher respects resource limits and cleans up unused watches

** [#C] Add debouncing and event coalescing
   Why: Prevent event flooding from rapid file changes (e.g., editor autosave)
   Change:
   - Add 100ms debounce window per path
   - Collect events during window, deliver once at window end
   - Preserve latest event data (e.g., timestamp, op type)
   - Configurable debounce duration per watcher
   - Special case: git operations often touch multiple files rapidly
   - Tests: Unit test with rapid file modifications; verify single event
   Done when: Rapid changes trigger single event after debounce window

** [#C] Add frontend WebSocket event store
   Why: Centralize WebSocket event handling in frontend
   Change:
   - Create frontend/src/lib/eventStore.js for /ws/events connection
   - Single WebSocket connection shared by all components
   - Export subscribe(eventType, callback) for component usage
   - Handle reconnection with exponential backoff
   - Log connection state changes (connecting/connected/disconnected)
   - Provide connection status for UI feedback
   - Clean up subscriptions on component unmount (prevent leaks)
   Tests: Frontend unit tests for store; manual connection test
   Done when: Frontend has reusable WebSocket event infrastructure

** [#C] Add error handling and recovery
   Why: Filesystem watching can fail (permission, filesystem full, etc)
   Change:
   - Catch fsnotify errors: log at warning level with context
   - Attempt watcher recreation on failure (max 3 retries)
   - Exponential backoff between retry attempts
   - Notify frontend of watch failures via error events
   - Show toast notification: "File watching unavailable" (for PLAN.org/git)
   - Fall back to polling if watching fails persistently
   - Document failure modes in README
   Tests: Simulate watch failures (permissions, invalid paths)
   Done when: Watcher handles errors gracefully with fallback options

** [#C] Add integration tests for end-to-end event flow
   Why: Verify complete flow from filesystem change to frontend update
   Change:
   - Create test: start server, connect WebSocket, modify watched file
   - Verify event delivery within 200ms (including debounce)
   - Test multiple concurrent clients receiving same event
   - Test git branch change detection end-to-end
   - Test WebSocket reconnection and event recovery
   - Test resource cleanup: watchers removed when clients disconnect
   - Use temp directories and temp git repos for isolation
   Tests: go test ./... integration suite passes
   Done when: E2E tests cover critical paths with real filesystem operations

** [#C] Document event system and usage patterns
   Why: Developers need to understand how to add new watchers
   Change:
   - Add "Filesystem Event System" section to README.md
   - Document EventHub API: how to subscribe/publish events
   - Document WebSocket /ws/events protocol and message format
   - Provide example: adding a new watched file or event type
   - Document debouncing behavior and configuration
   - Document resource limits and cleanup policies
   - Add architecture diagram (optional): Watcher → EventHub → WebSocket
   - Document frontend eventStore.js usage pattern
   Tests: None (documentation only)
   Done when: Event system is fully documented with examples

* DONE [#B] Dashboard and Plan UI improvements
  Goal: Streamline dashboard UX by showing working directory, adding agent start/stop controls, embedding logs directly, removing redundant sections, and enabling real-time plan file watching.
  Notes:
  - Dashboard is the primary control surface; reduce clutter, increase information density
  - Agent terminals: show play/stop button instead of always creating new terminals
  - Only one active terminal per agent (enforced by backend, UI reflects state)
  - Visual feedback: running vs stopped state with color changes
  - Working directory prominently displayed (users need to know context)
  - Logs embedded in dashboard (remove separate tab, reduce navigation)
  - Skills list removed (redundant; shown in agent cards already)
  - Live terminals section removed (state now clear from agent cards)
  - Plan tab: fix file watching to update on changes (currently only loads at startup)
  - All changes must maintain clean separation: components remain modular and testable
  - Backend changes minimal: add working directory to status API, ensure agent state tracking
  Date: 2026-01-08

** [#B] Setup Tailwind CSS for Svelte frontend
   Why: Streamline styling and reduce custom CSS; perfect timing with dashboard overhaul
   Change:
   - Install tailwindcss, postcss, autoprefixer as dev dependencies
   - Create tailwind.config.js with Svelte content paths: './src/**/*.{html,js,svelte,ts}'
   - Create postcss.config.js with tailwindcss and autoprefixer plugins
   - Create or update src/app.css with Tailwind directives (@tailwind base/components/utilities)
   - Import app.css in src/main.js or App.svelte
   - Configure Vite to process Tailwind (already works with PostCSS out of box)
   - Test with simple utility class (e.g., bg-blue-500) in Dashboard.svelte
   - Keep existing component styles working during transition (gradual migration)
   - Document Tailwind usage in comments: "New code uses Tailwind, old code migrates as touched"
   Tests: npm run build; verify Tailwind classes render; npm test still passes
   Done when: Tailwind configured, builds successfully, ready for use in new code

** [#B] Add working directory to status API
   Why: Dashboard needs to prominently display where Gestalt is running
   Change:
   - Extend statusResponse struct in internal/api/rest.go to include WorkDir string
   - Populate with os.Getwd() in status handler
   - Handle error if getwd fails (log warning, use "unknown" or empty string)
   - Update API response: "working_dir" field in JSON
   Tests: GET /api/status includes working_dir; go test ./internal/api
   Done when: Status endpoint returns current working directory

** [#B] Update Dashboard status section with working directory
   Why: Users need prominent display of working directory; remove useless metrics
   Change:
   - Remove "Active terminals" and "Skills available" status cards from Dashboard.svelte
   - Remove "Server time" status card (not useful)
   - Add single prominent "Working directory" card showing full path from status.working_dir
   - Style: make working directory card span full width or prominent position
   - Use monospace font for path display
   - Keep eyebrow and h1 (Gestalt title) unchanged
   Tests: npm test -- tests/dashboard.test.js (if exists); manual visual check
   Done when: Dashboard shows working directory prominently, other metrics removed

** [#B] Add agent state tracking to Manager
   Why: Need to track which agents are running vs stopped for play/stop UI
   Change:
   - Manager already tracks agentSessions map (agent name → terminal ID)
   - Add method Manager.GetAgentTerminal(agentName string) (terminalID string, running bool)
   - Returns terminal ID if agent has running session, empty string if stopped
   - This is for UI state; existing single-instance enforcement unchanged
   Tests: Unit tests for Manager.GetAgentTerminal; go test ./internal/terminal
   Done when: Manager can report agent running state by name

** [#B] Extend agents API to include terminal state
   Why: Frontend needs to know which agents are currently running
   Change:
   - Extend agentSummary struct in internal/api/rest.go to include TerminalID string and Running bool
   - In GET /api/agents handler, check Manager.GetAgentTerminal(agent.Name) for each agent
   - Populate terminal_id and running fields in response
   - If agent running, include terminal ID; if stopped, terminal_id is empty and running is false
   Tests: API test verifies running/stopped agents; go test ./internal/api
   Done when: GET /api/agents returns terminal state per agent

** [#B] Transform agent buttons to play/stop controls
   Why: Dashboard should show start/stop controls instead of always creating new terminals
   Change:
   - Replace agent buttons in Dashboard.svelte agent-grid section
   - If agent.running: show stop button (⏹ or "Stop") with agent.name
   - If !agent.running: show play button (▶ or "Start") with agent.name
   - Play button: calls createTerminal(agent.id) (existing behavior)
   - Stop button: calls deleteTerminal(agent.terminal_id) (existing function)
   - Update button styling: .agent-button--running and .agent-button--stopped classes
   - Running state: slightly different background color (e.g., light green/blue tint)
   - Stopped state: default/muted color
   - Keep agent skills display below button (unchanged)
   Tests: npm test -- tests/dashboard.test.js; manual test play/stop
   Done when: Agent cards show play/stop based on state; visual feedback works

** [#B] Remove skills section from Dashboard
   Why: Skills list is redundant; already shown in agent cards
   Change:
   - Remove entire .dashboard__skills section from Dashboard.svelte
   - Remove loadSkills() function and related state (skills, skillsLoading, skillsError)
   - Remove agentNamesForSkill() function (no longer needed)
   - Keep agentSkills loading for agent cards (still need skills per agent)
   - Remove associated styles for .dashboard__skills, .skill-grid, .skill-card
   Tests: npm test; manual check no regression in agent skills display
   Done when: Skills section removed; agent cards still show skills correctly

** [#B] Remove live terminals section from Dashboard
   Why: Agent state is now clear from agent cards; separate list is redundant
   Change:
   - Remove entire .dashboard__list section from Dashboard.svelte
   - Keep terminals prop and state (needed for App.svelte tab management)
   - Remove formatTime function if only used for terminal list
   - Remove associated styles for .dashboard__list, .terminal-list, .terminal-row
   Tests: npm test; verify tabs still work (terminals tracked in App.svelte)
   Done when: Live terminals section removed; terminal tabs still functional

** [#B] Embed logs directly in Dashboard
   Why: Logs should be visible without switching tabs; reduce navigation overhead
   Change:
   - Add compact logs section to Dashboard.svelte below agent section
   - Import log fetching logic from LogsView.svelte (fetchLogs, filtering)
   - Display last 10-20 log entries in compact format (timestamp, level badge, message)
   - Keep filter dropdown (level filter) and auto-refresh toggle
   - Style: compact cards, smaller font, less padding than full LogsView
   - Add "View all logs" link that switches to Logs tab (keep tab for full view)
   - Refresh logs on mount and every 5s (same as LogsView auto-refresh)
   Tests: npm test -- tests/dashboard.test.js; verify logs display and refresh
   Done when: Dashboard shows recent logs; full Logs tab still accessible

** [#C] Remove Logs tab from navigation
   Why: Logs are now in Dashboard; separate tab is redundant
   Change:
   - Remove logs tab from tabs array in App.svelte initialization
   - Remove 'logs' case from activeView computed property
   - Remove LogsView import and section from App.svelte template
   - Keep LogsView.svelte file (might be useful for "view all" link in future)
   - Update TabBar to not show logs tab
   Tests: npm test; manual check tab navigation works
   Done when: Logs tab not visible; logs accessible via dashboard

** [#B] Move all session storage to .gestalt directory
   Why: Keep working directory clean; make session data accessible and organized
   Change:
   - Change default session log directory from "logs/sessions" to ".gestalt/sessions"
   - Change default input history directory from "logs/input-history" to ".gestalt/input-history"
   - Update ManagerOptions defaults in cmd/gestalt/main.go
   - Update env var documentation: GESTALT_SESSION_DIR, GESTALT_INPUT_HISTORY_DIR
   - Create .gestalt directory in current working directory on startup
   - Update persistence.go and input_logger.go to use new paths
   - Add .gestalt to .gitignore if not already present
   - Migrate existing logs/ data on first startup (optional, or document manual migration)
   Tests: go test ./internal/terminal; verify files created in .gestalt/
   Done when: All session data stored in .gestalt/ directory

** [#B] Fix terminal history persistence on reconnect
   Why: Terminal loses history when frontend closes and reopens
   Change:
   - Issue: frontend doesn't fetch full history on reconnect
   - On WebSocket connect in terminalStore.js, fetch GET /api/terminals/:id/output
   - Write buffered history to xterm before starting live WebSocket stream
   - Backend already maintains OutputBuffer (1000 lines) and SessionLogger (disk)
   - Fetch should get max 2000 lines from both buffer and disk (if session file exists)
   - Handle loading state: show "Loading history..." in terminal header
   - Add sessionStorage or memory cache to avoid re-fetching if already loaded
   - Ensure history lines don't duplicate when WebSocket starts streaming
   Tests: Manual test: connect, type output, close browser, reopen → verify history visible
   Done when: Terminal history fully restored on frontend reconnect

** [#B] Fix terminal layout: full width and page-level scrolling
   Why: Terminal is boxed with double scrollbars; should be full-page and directly scrollable
   Change:
   - TerminalView.svelte removes padding wrapper (currently adds 2rem padding)
   - Terminal.svelte should fill viewport: use viewport height (100vh minus header)
   - Change grid-template-rows in .terminal-shell to use vh units
   - Remove min-height: 70vh, use height: calc(100vh - 64px - [input-box-height])
   - Make xterm container grow to fill available space
   - Page scrollbar should scroll xterm viewport directly (no nested scrolling)
   - Test with different content heights and window sizes
   Tests: Manual test: resize window, scroll terminal, verify no double scrollbars
   Done when: Terminal is full-width, full-height, single scrollbar

** [#B] Make command input box fixed at bottom
   Why: Input box should always be visible regardless of terminal scroll position
   Change:
   - CommandInput should be position: sticky or fixed at bottom of viewport
   - Adjust Terminal.svelte layout: input box outside scrollable terminal area
   - Use CSS: position: sticky; bottom: 0; z-index: 10;
   - Add subtle shadow or border-top to separate from terminal content
   - Ensure input box doesn't cover terminal content (adjust terminal bottom padding)
   - Keep input box within .terminal-shell bounds (not floating over page)
   Tests: Manual test: scroll terminal, verify input box stays at bottom
   Done when: Input box always visible at bottom during scroll

** [#B] Add scroll-to-bottom button to command input
   Why: Users need quick way to jump to bottom of long terminal output
   Change:
   - Add button to CommandInput.svelte above/beside textarea
   - Button label: "↓ Scroll to bottom" or just icon ⬇
   - On click: scroll xterm viewport to bottom
   - Access xterm via terminalStore state: state.scrollToBottom() method
   - Add scrollToBottom() method to terminalStore.js: calls term.scrollToBottom()
   - Show button only when not already at bottom (detect scroll position)
   - Style: small, subtle button that doesn't interfere with input
   - Position: inline with "Direct input" toggle, or above textarea
   Tests: Manual test: scroll up, click button, verify jumps to bottom
   Done when: Scroll-to-bottom button works in command input area

** [#B] Implement file watching for PLAN.org updates
   Why: Plan view should update when file changes, not just at startup
   Change:
   - Add file watching to PlanView.svelte using backend polling or native file watch
   - Option 1 (simple): poll /api/plan every 5-10s, compare content hash or timestamp
   - Option 2 (better): add ETag header to /api/plan, use If-None-Match for efficient polling
   - Option 3 (ideal): add WebSocket endpoint for plan updates (more complex)
   - Start with Option 1: poll every 5s, compare content, reload OrgViewer if changed
   - Add loading indicator for refreshes (subtle, non-intrusive)
   - Keep manual refresh button for user control
   Tests: Manual test: edit PLAN.org, verify UI updates; npm test
   Done when: Plan view updates automatically when file changes

** [#C] Add ETag support to plan endpoint (optional enhancement)
   Why: Efficient polling without transferring full file every time
   Change:
   - Compute ETag for /api/plan response (hash of file content or mtime)
   - Return ETag header in response
   - Support If-None-Match request header, return 304 Not Modified if unchanged
   - PlanView sends If-None-Match with stored ETag
   - Only reload content if server returns 200 (content changed)
   - This is optional enhancement; basic polling sufficient initially
   Tests: API test for ETag and 304 responses; go test ./internal/api
   Done when: Plan polling uses ETags for efficiency (optional)

** [#C] Polish agent card styling for running state
   Why: Visual feedback should be clear and pleasant
   Change:
   - Running state: subtle green or blue tint in .agent-button--running
   - Stopped state: neutral/muted colors in .agent-button--stopped
   - Add transition for smooth color change on state change
   - Consider adding pulsing animation or indicator dot for running state
   - Ensure colors work in both light and dark themes (if applicable)
   - Keep buttons accessible: sufficient contrast, clear labels
   Tests: Manual visual testing; accessibility check
   Done when: Running/stopped states have clear, pleasant visual feedback

** [#C] Update documentation for Dashboard changes
   Why: Users need to understand new dashboard layout and controls
   Change:
   - Update README.md to document dashboard features
   - Document working directory display
   - Document agent play/stop controls
   - Document embedded logs section
   - Note that Logs tab is removed (logs in dashboard)
   - Document plan auto-refresh behavior
   Tests: None (documentation only)
   Done when: README reflects new dashboard structure and features

<<<<<<< HEAD
=======
** FIX Touch scroll terminal history (multi-touch + touch-anywhere)
   Why: Touch devices should scroll terminal history from any point in the viewport
   Change:
   - Add touch handlers to scroll xterm viewport on single or multi-touch gestures
   - Keep mouse selection behavior intact
   Tests: go test ./...; npm test
   Done when: Swipe anywhere in terminal scrolls history on touch devices

** FIX Focus command input on terminal tab activation/creation
   Why: Command input should be ready immediately after opening or switching tabs
   Change:
   - Focus command input on tab activation and initial terminal creation
   - Respect direct input mode to focus xterm instead
   Tests: go test ./...; npm test
   Done when: Input focus lands correctly on tab switch and creation

** FIX Agent start/stop button state updates immediately
   Why: Running state should reflect changes without page reload
   Change:
   - Refresh agent list after start/stop actions
   Tests: go test ./...; npm test
   Done when: Agent buttons flip to running/stopped immediately

** FIX Show git origin/branch in dashboard status
   Why: Dashboard should show repo context alongside working directory
   Change:
   - Extend /api/status with git_origin and git_branch fields (read once on boot)
   - Parse .git/config for origin and .git/HEAD for branch
   - Update status card to show working directory, origin, and branch on one line
   Tests: go test ./...; npm test
   Done when: Status shows origin/branch with working directory

>>>>>>> 13091cc (refine prompts and new fixer agent)
* TODO [#B] Agent profile widgets: configurable UI composition
  Goal: Extend agent profiles with a "widgets" array that controls which UI elements appear in an agent's terminal tab, starting with a Plan sidebar widget that displays PLAN.org alongside the terminal.
  Notes:
  - Agent profiles get new optional field: "widgets": ["plan-sidebar", ...] (array of widget names)
  - First widget implementation: "plan-sidebar" - shows OrgViewer component in a sidebar
  - Layout: when "plan-sidebar" widget is present, split terminal tab into 3/5 terminal + 2/5 plan sidebar
  - OrgViewer component already exists and was designed for sidebar use (from completed PLAN.org viewer work)
  - Widgets are opt-in per agent: agents without "widgets" field show full-width terminal (current behavior)
  - Future widgets could include: logs, metrics, file browser, skill library, workflow status
  - Layout system should be flexible: different widgets may have different sizes/positions
  - Use CSS Grid or Flexbox for responsive layout
  - Backend: Agent struct gets Widgets []string field, validation, JSON parsing
  - Frontend: Terminal tab reads agent.widgets and renders layout with appropriate components
  - Sidebar should be responsive: collapsible/expandable, maybe resizable in future
  Date: 2025-12-31

** TODO [#B] Add widgets field to Agent struct and JSON schema
   Why: Backend needs to store and validate widget configuration from agent JSON files
   Change:
   - Add Widgets []string `json:"widgets,omitempty"` field to Agent struct in internal/agent/agent.go
   - Widget names use kebab-case: "plan-sidebar", "logs-panel", etc.
   - Validation: warn (don't fail) if unknown widget name is referenced
   - Add validation helper: ValidateWidget(name string) that checks against known widgets
   - Known widgets initially: ["plan-sidebar"]
   - Update Agent.Validate() to check widget names and log warnings for unknown ones
   - Empty/missing widgets field is valid (means no widgets, current behavior)
   Tests: Unit tests for Agent with widgets field; valid/invalid widget names
   Done when: Agent struct accepts and validates widgets array

** TODO [#B] Update agent loader to support widgets field
   Why: Agent loader must parse and validate widgets from JSON files
   Change:
   - Loader already handles JSON unmarshaling; widgets will be parsed automatically
   - Add logging when widgets are loaded: info level "Agent 'X' has widgets: [...]"
   - Warn if unknown widget referenced: "Unknown widget 'foo' in agent 'bar', ignoring"
   - No special handling needed beyond Agent struct changes (automatic via JSON tags)
   - Update example agent configs to demonstrate widgets usage
   Tests: Loader tests with agents containing widgets field
   Done when: Agent JSON files with widgets load and validate correctly

** TODO [#B] Extend API to expose agent widgets
   Why: Frontend needs to know which widgets to render for each agent
   Change:
   - GET /api/agents already returns agent metadata; ensure widgets field is included
   - GET /api/terminals/:id should include agent.widgets in SessionInfo/terminalSummary
   - Widgets array should be in JSON response for both endpoints
   - Add widgets to terminalSummary struct in internal/api/types.go (if exists) or inline response
   Tests: API tests verify widgets field in responses
   Done when: Frontend can fetch widget configuration via API

** TODO [#B] Create terminal layout container component
   Why: Need flexible layout system for terminal + sidebar widgets
   Change:
   - Create frontend/src/components/TerminalLayout.svelte
   - Props: widgets (array of widget names), terminalId, agent
   - Default layout: full-width terminal (no widgets)
   - If widgets includes "plan-sidebar": use CSS Grid with 3fr / 2fr layout (60% / 40%)
   - Left area: terminal component, Right area: widget container
   - Make layout responsive: handle narrow screens (stack vertically on mobile?)
   - Add CSS classes: .terminal-layout, .terminal-area, .widget-area
   - Widget area should have overflow: auto and independent scrolling
   Tests: Manual test with/without widgets; verify layout proportions
   Done when: Layout component renders terminal with/without sidebar

** TODO [#B] Create widget container and widget factory
   Why: Need system to dynamically render different widget types
   Change:
   - Create frontend/src/components/WidgetContainer.svelte
   - Props: widgetName (string), terminalId, agent
   - Use switch/case or component map to render correct widget component
   - Handle unknown widgets gracefully: show placeholder or warning message
   - For "plan-sidebar": render OrgViewer component
   - Add styling: consistent padding, borders, background matching app theme
   - Widget container should handle loading states for async widgets
   Tests: Manual test with "plan-sidebar" widget; verify OrgViewer renders
   Done when: Widget container correctly renders plan-sidebar widget

** TODO [#B] Integrate OrgViewer as plan-sidebar widget
   Why: Plan sidebar is the first widget implementation
   Change:
   - OrgViewer.svelte already exists in frontend/src/components/
   - Ensure OrgViewer works in sidebar context: compact styling, responsive width
   - OrgViewer should fetch /api/plan on mount (already implemented)
   - Add CSS adjustments for sidebar context: reduce padding, smaller fonts if needed
   - Verify expand/collapse, filtering work in narrow width (~40% of screen)
   - Add subtle visual separator between terminal and sidebar (border or shadow)
   Tests: Manual test OrgViewer in sidebar; verify usability at ~2/5 screen width
   Done when: Plan sidebar displays PLAN.org alongside terminal

** TODO [#B] Wire layout system into Terminal.svelte
   Why: Terminal component needs to use new layout when agent has widgets
   Change:
   - Terminal.svelte currently renders xterm instance directly
   - Wrap xterm in TerminalLayout component
   - Pass agent.widgets array to TerminalLayout
   - TerminalLayout decides whether to show sidebar based on widgets
   - Ensure xterm still gets proper resize events and fit addon works
   - Terminal should occupy full 60% of its container (not affected by sidebar)
   Tests: Manual test: create agent with/without plan-sidebar widget
   Done when: Agent terminals with plan-sidebar show split layout

** TODO [#C] Update example agent configs with widgets
   Why: Demonstrate widget usage and provide working examples
   Change:
   - Update one example agent (e.g., config/agents/copilot.json) to include widgets
   - Add: "widgets": ["plan-sidebar"]
   - Keep other example agents without widgets (show both patterns)
   - Document widget field in README.md under Agent Profiles section
   Tests: Load example agents; verify copilot shows plan-sidebar
   Done when: Example demonstrates plan-sidebar widget usage

** TODO [#C] Add widget resizing capability (optional enhancement)
   Why: Users may want to adjust sidebar width
   Change:
   - Add draggable splitter between terminal and sidebar
   - Use mouse events to adjust CSS Grid proportions on drag
   - Store width preference in localStorage per widget type
   - Default: 60/40 split, allow range 40-80% for terminal
   - This is optional enhancement; can defer if too complex initially
   Tests: Manual test dragging splitter; verify layout adjusts smoothly
   Done when: Users can resize plan-sidebar width (optional)

** TODO [#C] Document widgets system
   Why: Users and contributors need to understand widget configuration
   Change:
   - Add "Agent Widgets" section to README.md
   - Document widgets field in agent profile JSON format
   - Document available widgets: plan-sidebar (with description and screenshot if possible)
   - Document layout behavior: how widgets affect terminal tab composition
   - Document future widget ideas: logs, metrics, file browser, etc.
   - Add example JSON with widgets configuration
   Tests: None (documentation only)
   Done when: Widget system is fully documented in README

* WIP [#B] Semantic versioning with automated releases
  Goal: Implement semantic versioning throughout Gestalt with automated version generation in GitHub Actions based on conventional commits (feat:/fix:), compile version into backend and frontend, and display version in UI near the Gestalt title.
  Notes:
  - Use conventional commits (feat:, fix:) to drive semantic versioning
  - Use npm semver package for version parsing and bumping
  - Node.js script analyzes git log since last tag, detects feat:/fix:/BREAKING CHANGE:
  - Script uses semver.inc() to bump version appropriately
  - Version must be passed at build time to both Go backend and Vite frontend
  - Backend: compile version as const or var, expose via /api/status
  - Frontend: inject version at build time via Vite define, display in Dashboard header
  - UI: reuse .cta class styling (gray, small text) as .version class for version display
  - Version appears near "Gestalt" title in Dashboard header
  - Minimal dependency: only semver package (already Node.js project)
  - Initial version: v1.0.0 (project is mature enough)
  - Git tags are source of truth; no manual version files
  Date: 2025-12-30

** DONE [#B] Create Node.js script for version detection using semver
   Why: Need reliable version bumping based on conventional commits using semver package
   Change:
   - Install semver package as dev dependency in root: npm install --save-dev semver
   - Create scripts/get-next-version.js Node.js script
   - Logic: read git log from last tag to HEAD, parse commit messages
   - Use git describe or git tag to get current version
   - Detect patterns: "feat:" → semver.inc('minor'), "fix:" → semver.inc('patch'), "BREAKING CHANGE:" → semver.inc('major')
   - If no tag exists, output 1.0.0 as initial version
   - Use semver.valid() to validate versions, semver.clean() to normalize
   - Output format: semantic version string without 'v' prefix (e.g., "1.2.3")
   - Handle edge cases: no commits since tag, multiple types in range, invalid existing tags
   - Script should be idempotent and fast
   - Priority order: BREAKING CHANGE > feat > fix (highest precedence wins)
   - Exit with code 0 and output version to stdout for easy capture in workflows
   Tests: Run script manually with various commit histories
   Done when: Script correctly determines next version from git history using semver

** DONE [#B] Create GitHub Actions release workflow
   Why: Automate version detection, tagging, and release creation on main branch
   Change:
   - Create .github/workflows/release.yml (separate from tests.yml)
   - Trigger: on push to main branch only
   - Setup steps: checkout → setup Node.js → npm install semver
   - Run scripts/get-next-version.js to determine next version
   - Compare with current tag (git describe --tags); skip if no change
   - Create git tag with 'v' prefix: v1.2.3
   - Use GitHub API or gh CLI to create release with auto-generated notes
   - Set up GITHUB_TOKEN permissions: contents: write (for tags)
   - Generate release notes from commits since last tag using GitHub's API
   - Tag format: v1.2.3 (with 'v' prefix for git, script outputs without prefix)
   Tests: Push feat: or fix: commit to main, verify tag and release created
   Done when: GitHub Action automatically tags and releases on conventional commits

** DONE [#B] Pass version to Go backend at build time
   Why: Backend needs to know its version for /api/status and logging
   Change:
   - Add internal/version/version.go with var Version string
   - Use Go linker flags in Makefile and GitHub Action: -ldflags "-X gestalt/internal/version.Version=$VERSION"
   - Default Version to "dev" if not set at build time
   - Export version in /api/status response as "version" field
   - Add version to startup log message
   - Update GNUmakefile to accept VERSION variable: make VERSION=1.2.3
   Tests: go test ./...; verify version appears in /api/status
   Done when: Backend binary contains version compiled at build time

** DONE [#B] Pass version to frontend at build time
   Why: Frontend needs to display version in UI
   Change:
   - Use Vite's define option to inject version at build time
   - Update vite.config.js: define: { __APP_VERSION__: JSON.stringify(process.env.VERSION || 'dev') }
   - Create frontend/src/lib/version.js exporting VERSION constant
   - Pass VERSION env var from Makefile and GitHub Action to npm build
   - Vite replaces __APP_VERSION__ at bundle time (tree-shakeable)
   Tests: npm run build; verify version is in bundle
   Done when: Frontend bundle contains version from build-time env var

** DONE [#C] Display version in Dashboard header
   Why: Users should see which version of Gestalt they're running
   Change:
   - Import VERSION from lib/version.js in Dashboard.svelte
   - Add version display near "Gestalt" h1 in the header div
   - Reuse existing .cta class styling as .version class (small, gray text)
   - Markup: <span class="version">v{VERSION}</span>
   - Placement: after the h1, same container, visually subtle
   - Keep existing .cta styles, duplicate as .version for semantic clarity
   - Version should be understated, not competing with main title
   Tests: npm run build; visually verify version displays correctly
   Done when: Version appears in Dashboard header with .cta-inspired styling

** DONE [#C] Update Makefile to integrate versioning
   Why: Local builds should support version injection
   Change:
   - Add VERSION ?= dev to Makefile (default to "dev" for local builds)
   - Alternatively: VERSION ?= $(shell git describe --tags --always --dirty 2>/dev/null || echo "dev")
   - Update build target to pass VERSION to both Go and npm
   - Go build: add -ldflags "-X gestalt/internal/version.Version=$(VERSION)"
   - npm build: export VERSION=$(VERSION) before running npm run build
   - Document in comments: "make VERSION=1.2.3 to build with specific version"
   - Add phony target "version" that prints current version from git
   Tests: make VERSION=1.0.0; verify both binaries have correct version
   Done when: Makefile supports VERSION variable for local builds

** DONE [#C] Integrate versioning into test workflow
   Why: Test builds should include version info for debugging
   Change:
   - Update .github/workflows/tests.yml to detect version during build
   - Add step: run scripts/get-next-version.sh or git describe for current version
   - Pass VERSION env var to build steps (Go and npm)
   - This workflow does NOT create tags (release.yml handles that)
   - Display version in test summary output for visibility
   - Handle case where no tags exist yet (use "dev" or "1.0.0-dev")
   Tests: Push to PR or branch, verify tests run with version info
   Done when: Test workflow builds contain version from git tags

** TODO [#C] Document versioning workflow
   Why: Contributors need to understand commit message conventions
   Change:
   - Add "Versioning" section to README.md
   - Document conventional commit format: feat:, fix:, BREAKING CHANGE:
   - Explain semantic versioning rules (major.minor.patch)
   - Document how version is injected at build time (Go ldflags, Vite define)
   - Explain automatic tagging: "Push feat: commit to main → v1.1.0 tag created"
   - Show examples: "feat: add terminal history → bumps minor", "fix: resolve connection bug → bumps patch"
   - Mention initial version is v1.0.0
   - Document local build with version: make VERSION=1.2.3
   - Link to conventional commits specification (optional)
   Tests: None (documentation only)
   Done when: README clearly documents versioning workflow and conventions


* TODO [#A] Temporal workflow integration for HITL session lifecycle
  Goal: Integrate Temporal.io workflows to manage durable, semi-interactive agent sessions with human-in-the-loop (HITL) coordination, tracking agent work phases (start: L1/L2 plan tasks) and stops (terminal bells requiring user attention).
  Notes:
  - Core Gestalt functionality: agents record start (which PLAN.org L1/L2 they're working on) and stop (terminal bell signals)
  - Terminal sessions modeled as Temporal workflows with durable state across crashes
  - Signals enable HITL: pause for user input, request another agent's analysis, approval gates
  - Activities: spawn terminal (PTY), execute commands, read output, detect bells
  - Workflow state: session ID, current L1/L2 task, start time, pause/resume events, bell events
  - Terminal bell detection triggers workflow signal → pause → await user action or agent handoff
  - Event history provides full audit trail of agent work sessions
  - Future: wire stops to actions (ask user, delegate to another agent, approval workflows)
  - Temporal SDK: use Go SDK (go.temporal.io/sdk) - matches existing Go backend
  - Temporal server: run local dev server initially, production deployment later
  - Integration: extend Manager/Session to optionally use Temporal workflows
  - Backward compat: existing sessions work without Temporal; opt-in for workflow-managed sessions
  - PLAN.org parsing: read current WIP L1/L2 to record what agent is working on
  - Bell detection: already exists in xterm.js frontend; needs backend signal propagation
  Date: 2025-12-31
  Ref: https://github.com/dyne/gestalt/issues/4

** TODO [#B] Setup Temporal development environment
   Why: Need Temporal server running locally for development and testing
   Change:
   - Add Temporal CLI to development dependencies (temporalio/cli)
   - Document installation: `brew install temporal` (macOS) or download binary
   - Add `make temporal-dev` target to start Temporal dev server
   - Default: temporal server start-dev (includes UI at localhost:8233)
   - Dev server uses built-in SQLite (perfect for local-only Gestalt deployment)
   - Add Temporal server health check to startup logs
   - Document Temporal UI access in README.md
   - Document data persistence: SQLite file persists workflows across restarts
   Tests: Start temporal dev server, verify UI accessible
   Done when: Temporal dev server runs locally and is documented

** TODO [#B] Add Temporal Go SDK dependency
   Why: Need Temporal client and worker SDK in Go backend
   Change:
   - Add dependency: go get go.temporal.io/sdk@latest
   - Add dependency: go get go.temporal.io/api@latest (for API types)
   - Create internal/temporal/ package for Temporal integration
   - Initialize Temporal client in cmd/gestalt/main.go
   - Configure client: namespace (default), host (localhost:7233 for dev)
   - Add GESTALT_TEMPORAL_HOST env var (default: localhost:7233)
   - Add GESTALT_TEMPORAL_NAMESPACE env var (default: "default")
   - Handle connection errors gracefully: warn and continue without Temporal if unavailable
   Tests: go test ./...; verify Temporal client initializes
   Done when: Temporal SDK integrated and client connects to server

** TODO [#B] Create session workflow definition
   Why: Define workflow for terminal session lifecycle management
   Change:
   - Create internal/temporal/workflows/session_workflow.go
   - SessionWorkflow(ctx workflow.Context, req SessionWorkflowRequest) (SessionWorkflowResult, error)
   - Request: SessionID, AgentID, L1Task, L2Task, Shell, StartTime
   - Result: SessionID, EndTime, FinalStatus, EventCount
   - Workflow state: CurrentL1, CurrentL2, Status (running/paused/stopped), BellEvents
   - Signal: UpdateTaskSignal(l1, l2 string) - agent updates which task they're working on
   - Signal: BellSignal(timestamp, context string) - terminal bell detected, pause for HITL
   - Signal: ResumeSignal(action string) - user resumes after bell (continue/abort/handoff)
   - Signal: TerminateSignal(reason string) - graceful shutdown
   - Query: GetStatusQuery() - return current workflow state
   - Implement workflow logic: await signals, record events, manage lifecycle
   Tests: Unit tests for workflow logic with mock activities
   Done when: SessionWorkflow defined with signals and queries

** TODO [#B] Create session activities
   Why: Activities perform actual operations (spawn PTY, detect bells, read output)
   Change:
   - Create internal/temporal/activities/session_activities.go
   - SpawnTerminalActivity(ctx, sessionID, shell string) error - creates terminal session
   - TerminateTerminalActivity(ctx, sessionID string) error - cleanly closes terminal
   - RecordBellActivity(ctx, sessionID, timestamp, context string) error - logs bell event
   - UpdateTaskActivity(ctx, sessionID, l1, l2 string) error - records task switch
   - GetOutputActivity(ctx, sessionID string) (string, error) - retrieves terminal output
   - Activities interact with existing Manager/Session infrastructure
   - Activities are idempotent (safe to retry on failure)
   - Activities log all actions for audit trail
   Tests: Unit tests for each activity; integration test with real Manager
   Done when: Activities connect workflow to terminal operations

** TODO [#B] Extend Session to integrate with Temporal workflow
   Why: Terminal sessions need to optionally participate in Temporal workflows
   Change:
   - Add WorkflowID and RunID fields to Session struct (optional, nil if not using Temporal)
   - Add method Session.StartWorkflow(client, l1, l2 string) error - initiates workflow
   - Add method Session.SendBellSignal(context string) error - sends bell event to workflow
   - Add method Session.UpdateTask(l1, l2 string) error - updates current task in workflow
   - Modify Session.Close() to send TerminateSignal if workflow active
   - Terminal bell detection → call SendBellSignal → workflow pauses
   - Make workflow integration opt-in: only create workflow if GESTALT_TEMPORAL_ENABLED=true
   Tests: Unit tests for workflow integration; manual test with Temporal UI
   Done when: Sessions can optionally be managed by Temporal workflows

** TODO [#B] Parse PLAN.org to extract current WIP tasks
   Why: Agents need to know which L1/L2 they're working on to record in workflow
   Change:
   - Extend internal/plan/ package (or create if doesn't exist) with parser
   - Parse PLAN.org to find WIP entries (TODO/WIP keywords)
   - Find current WIP L1 heading and its WIP L2 child
   - Return (l1Title, l2Title string) for current work
   - Handle multiple WIP entries: warn user, return first or fail
   - Handle no WIP entries: return empty strings
   - Cache parsed plan; reload on file change (fsnotify) or API call
   - Add GET /api/plan/current endpoint returning current WIP L1/L2
   Tests: Unit tests with sample PLAN.org content; various WIP scenarios
   Done when: Can extract current WIP L1/L2 from PLAN.org

** TODO [#B] Wire terminal bell detection to workflow signals
   Why: Terminal bells must trigger workflow pause for HITL
   Change:
   - Frontend already handles xterm.js onBell event
   - Add POST /api/terminals/:id/bell endpoint to receive bell notifications
   - Endpoint extracts recent terminal output as context (last 50 lines)
   - Call session.SendBellSignal(context) to notify workflow
   - Workflow receives BellSignal → pauses → waits for ResumeSignal
   - Log bell events at warning level (visible in logs tab)
   - Optional: show toast notification on bell (configurable)
   Tests: Manual test: trigger bell in terminal, verify workflow pauses
   Done when: Terminal bells propagate to Temporal workflows

** TODO [#C] Create Temporal worker process
   Why: Workers execute workflow and activity code
   Change:
   - Create internal/temporal/worker.go with StartWorker(client, manager) error
   - Worker registers SessionWorkflow and all activities
   - Worker uses Manager to access terminal sessions for activities
   - Worker runs in separate goroutine, lifecycle tied to main process
   - Add graceful shutdown: stop worker before closing manager
   - Worker logs activity execution for debugging
   - Configure worker options: max concurrent activities, timeouts
   Tests: Start worker, verify workflows execute successfully
   Done when: Worker processes workflows and activities

** TODO [#B] Create Flow tab for workflow visualization
   Why: Users need dedicated UI to monitor all active workflows and HITL pauses
   Change:
   - Add "Flow" tab to TabBar (after Dashboard, Plan, Logs tabs)
   - Create frontend/src/views/FlowView.svelte as main component
   - Display list of all active workflow sessions (not just current terminal)
   - For each workflow: session ID, agent name, current L1/L2 task, status badge
   - Status badges: running (green), paused (yellow), stopped (gray)
   - Click workflow to expand details: start time, event timeline, current output context
   - Paused workflows highlighted prominently with action buttons
   - Action buttons: Resume, Abort, View Terminal (switches to terminal tab)
   - Auto-refresh every 5s to show live workflow state
   - Empty state: "No active workflows" when no sessions using Temporal
   - Compact design: matches Plan and Logs tab styling
   Tests: Manual test: create workflow sessions, verify Flow tab displays them
   Done when: Flow tab shows all workflow sessions with status and actions

** TODO [#C] Add workflow detail components
   Why: Flow tab needs detailed views for individual workflows
   Change:
   - Create frontend/src/components/WorkflowCard.svelte for list items
   - Create frontend/src/components/WorkflowDetail.svelte for expanded view
   - WorkflowCard: compact single-line display with expand button
   - WorkflowDetail: full timeline, bell events, task history, output snippets
   - Display bell context (last 50 lines of output that triggered pause)
   - Show pause duration and waiting time
   - Add copy button for workflow ID (for debugging with Temporal UI)
   - Link to Temporal UI: "View in Temporal" button (opens localhost:8233)
   Tests: Manual test: expand workflow details, verify all info displayed
   Done when: Flow tab has rich workflow detail views

** TODO [#C] Implement resume actions for paused workflows
   Why: Users need to respond to bell-triggered pauses
   Change:
   - Add POST /api/terminals/:id/workflow/resume endpoint
   - Accept action parameter: "continue" (resume as-is), "abort" (terminate), "handoff" (future)
   - Send ResumeSignal to workflow with chosen action
   - Workflow resumes based on action: continue → unpause, abort → terminate workflow
   - Log resume actions for audit trail
   - Frontend: show resume buttons when workflow is paused
   - Future: "handoff" triggers another agent to take over (defer to later)
   Tests: Manual test: pause via bell, resume via UI, verify workflow continues
   Done when: Users can resume paused workflows

** TODO [#C] Add workflow event history API
   Why: Users and admins need full audit trail of agent sessions
   Change:
   - Add GET /api/terminals/:id/workflow/history endpoint
   - Query Temporal for workflow execution history
   - Return events: task updates, bell events, pause/resume, signals
   - Format as JSON array with timestamps and event types
   - Optional: export as CSV for external analysis
   - Add WorkflowHistory.svelte component to display timeline
   Tests: Manual test: run workflow, view history, verify all events recorded
   Done when: Full workflow history is accessible via API and UI

** TODO [#C] Configure workflow retry and timeout policies
   Why: Workflows need robust error handling and bounded execution
   Change:
   - Add workflow options: execution timeout (24 hours default)
   - Add activity retry policies: exponential backoff, max attempts
   - Add workflow retry policy: retry on transient failures
   - Add heartbeat timeout for long-running activities
   - Configure activity timeouts based on operation (spawn: 30s, read: 5s)
   - Document timeout policies in README
   Tests: Test timeout scenarios; verify retries work correctly
   Done when: Workflows have production-ready error handling

** TODO [#C] Add workflow metrics and monitoring
   Why: Operators need visibility into workflow health
   Change:
   - Add Prometheus metrics for workflows: started, completed, failed, paused
   - Add metrics for activities: execution time, retry count, failure rate
   - Add GET /api/metrics endpoint exposing Prometheus format
   - Log workflow start/stop events at info level
   - Optional: integrate with Temporal's built-in observability
   - Document metrics in README
   Tests: Start workflows, verify metrics appear in /api/metrics
   Done when: Workflow metrics are exposed and documented

** TODO [#C] Document Temporal integration
   Why: Users and contributors need to understand workflow system
   Change:
   - Add "Temporal Workflows" section to README.md
   - Document HITL workflow concept and benefits
   - Document how agent sessions map to workflows
   - Document L1/L2 task tracking and bell-triggered pauses
   - Document resume actions and future handoff capabilities
   - Document local deployment: temporal server start-dev with SQLite
   - Add architecture diagram showing workflow interaction with sessions
   - Link to Temporal docs for advanced usage
   Tests: None (documentation only)
   Done when: Temporal integration is fully documented

** TODO [#C] Add workflow-managed session creation option
   Why: Users should choose whether to use Temporal workflows
   Change:
   - Add "workflow" boolean to POST /api/terminals request
   - If workflow=true, create session with Temporal workflow
   - If workflow=false, create standard session (current behavior)
   - Update agent profiles: add "use_workflow" boolean field
   - UI: checkbox on dashboard "Enable workflow tracking" (per agent or global)
   - Default: workflow disabled (opt-in) to avoid breaking existing usage
   Tests: Create both workflow and non-workflow sessions, verify both work
   Done when: Users can choose workflow mode per session

** TODO [#B] Implement future handoff capability (deferred)
   Why: Bell stops should eventually trigger agent-to-agent handoffs
   Change:
   - Design handoff protocol: paused agent → new agent receives context + task
   - Add HandoffSignal(targetAgentID, context, reason string) to workflow
   - Implement agent selection logic: which agent to handoff to?
   - Create new workflow for target agent, link to original workflow
   - Transfer terminal control or create new terminal for handoff agent
   - This is future work; defer until core HITL is stable
   Tests: Design document and prototype; implementation TBD
   Done when: Handoff design documented (implementation deferred)

* TODO [#B] Enhanced input UX with multiline input box and command history
  Goal: Replace direct PTY keyboard input with a dedicated multiline input box at the bottom of agent pages, featuring browsable command history, future-proof for assisted input features, and independent clipboard handling.
  Notes:
  - Current state: all keyboard input is intercepted by terminalStore.js, only Ctrl+C and Ctrl+V handled externally
  - New approach: dedicated input box outside PTY, commands sent to PTY only on submission (Enter)
  - Input box: 3 lines default height, multiline capable, bottom of agent page (below terminal)
  - History navigation: Ctrl+Up/Down to browse previous commands (like readline but in-app)
  - History storage: in-memory circular buffer + file persistence (reuse OutputBuffer/SessionLogger patterns)
  - File format: logs/input-history/{agentName}-{timestamp}.jsonl (JSON lines, one command per line)
  - History grouping: by agent name when available; fallback to terminal ID for non-agent terminals
  - Future features enabled: search history, AI-assisted input, command review/editing, templates
  - PTY isolation: disable direct PTY keyboard input; input box is the only entry path
  - Backward compat: not required for this L1; prioritize readability and clean UX
  - Use Svelte best practices for multiline input: textarea with proper resize, autosize, or contenteditable
  - History buffer: 1000 commands default (configurable), persist to disk async
  - Navigation: Ctrl+Up (previous), Ctrl+Down (next), Enter (submit), Shift+Enter (newline in multiline)
  - Empty commands not recorded in history (skip whitespace-only)
  Date: 2025-12-31

** DONE [#B] Create input history buffer backend structure
   Why: Need reusable in-memory circular buffer for command history similar to OutputBuffer
   Change:
   - Create internal/terminal/input_buffer.go with InputBuffer struct
   - Similar to OutputBuffer: maxCommands int, entries []InputEntry, mutex for thread-safety
   - InputEntry fields: Command string, Timestamp time.Time
   - Methods: Append(command string), GetAll() []InputEntry, GetRecent(n int) []InputEntry
   - Skip empty/whitespace-only commands in Append
   - Trim whitespace from commands before storing
   - Default capacity: 1000 commands (DefaultInputBufferSize constant)
   - Thread-safe for concurrent access from WebSocket and persistence goroutines
   - Circular buffer behavior: oldest commands dropped when limit reached
   Tests: Unit tests for InputBuffer: append, circular behavior, concurrent access
   Done when: InputBuffer struct exists with tests matching OutputBuffer quality

** DONE [#B] Create input history persistence logger
   Why: Persist command history to disk for durability across restarts
   Change:
   - Create internal/terminal/input_logger.go with InputLogger struct (similar to SessionLogger)
   - File path: logs/input-history/{agentName}-{timestamp}.jsonl
   - One JSON object per line: {"command":"...","timestamp":"..."}
   - Async write via channel (reuse SessionLogger pattern: write channel, flush goroutine)
   - Flush policy: every 1s or after N commands (consistent with SessionLogger)
   - Create logs/input-history/ directory if missing
   - Handle errors gracefully: log warning, continue without persistence if file ops fail
   - Close/flush on session termination
   Tests: Unit tests for InputLogger; verify file creation and content
   Done when: Input history persists to disk asynchronously

** DONE [#B] Integrate input buffer into Session
   Why: Each terminal session needs its own input history
   Change:
   - Add InputBuffer and InputLogger fields to Session struct in internal/terminal/session.go
   - Initialize InputBuffer and InputLogger in newSession() (alongside OutputBuffer/SessionLogger)
   - InputLogger uses same logs/input-history/ directory (configurable via env var)
   - Use agent name for history file prefix when available, fallback to terminal ID otherwise
   - Expose input history via Session methods: RecordInput(command string), GetInputHistory() []InputEntry
   - RecordInput: appends to buffer and writes to logger
   - Handle nil InputLogger gracefully if persistence disabled
   - Add env var: GESTALT_INPUT_HISTORY_PERSIST (default true), GESTALT_INPUT_HISTORY_DIR (default logs/input-history)
   Tests: Session tests verify input recording and retrieval
   Done when: Sessions track and persist input history

** DONE [#B] Add REST API endpoint for input history
   Why: Frontend needs to fetch command history for navigation
   Change:
   - Add GET /api/terminals/:id/input-history endpoint in internal/api/routes.go
   - Query parameters: limit (default 100), since (timestamp/index for pagination)
   - Return JSON array of commands: [{command: string, timestamp: ISO8601}, ...]
   - Read from session.InputBuffer.GetRecent(limit)
   - Timestamps: track command submission time (InputBuffer InputEntry)
   - Handle session not found errors
   - Auth: same as other terminal endpoints (token-based)
   Tests: API tests for input-history endpoint
   Done when: Frontend can fetch command history via REST

** DONE [#B] Create multiline input component
   Why: Need UI component for command input at bottom of terminal page
   Change:
   - Create frontend/src/components/CommandInput.svelte
   - Use <textarea> with rows={3} for 3-line default height
   - Props: terminalId, onSubmit callback, disabled state
   - Styling: match terminal theme (dark background, light text, monospace font)
   - Auto-resize: consider textarea autosize behavior (expand on content, max height)
   - Placeholder: "Type command... (Enter to submit, Shift+Enter for newline)"
   - Submit behavior: Enter key (without Shift) submits, calls onSubmit(value), clears textarea
   - Shift+Enter: inserts newline (standard multiline textarea behavior)
   - Focus behavior: auto-focus on mount, restore focus after submission
   - Styling: border, padding, consistent with terminal shell styling
   Tests: Manual test: type commands, submit, verify clearing and focus
   Done when: CommandInput component renders and submits input

** DONE [#B] Add history navigation to CommandInput
   Why: Users need Ctrl+Up/Down to browse command history
   Change:
   - Maintain history array in component state (fetched from API)
   - Track current history index (starts at -1, meaning no history navigation)
   - Fetch history on mount: call GET /api/terminals/:id/input-history
   - Store fetched history in local state for navigation
   - Keydown handler: detect Ctrl+ArrowUp and Ctrl+ArrowDown
   - Ctrl+Up: navigate backwards (index++), load command into textarea
   - Ctrl+Down: navigate forwards (index--), restore empty or latest command
   - Edge behavior: at oldest command, Ctrl+Up does nothing; at newest, Ctrl+Down restores empty
   - Reset index to -1 after submission (fresh command)
   - Handle empty history gracefully (no navigation)
   Tests: Manual test: submit commands, use Ctrl+Up/Down to navigate
   Done when: History navigation works with Ctrl+Up/Down

** DONE [#B] Wire CommandInput into Terminal.svelte layout
   Why: Input box needs to appear at bottom of terminal page
   Change:
   - Modify Terminal.svelte to add CommandInput below terminal body
   - Layout: CSS Grid with rows: header (auto) / terminal body (1fr) / input (auto)
   - Input area: fixed height based on CommandInput (3 lines default)
   - Pass terminalId prop to CommandInput
   - onSubmit handler: send command to PTY via existing sendData/WebSocket
   - Ensure terminal and input are visually distinct: border/separator between them
   - Responsive: input box should work on mobile (adjust height/font size)
   Tests: Manual test: render terminal with input box, submit commands
   Done when: Input box appears at bottom and sends commands to PTY

** DONE [#B] Send submitted commands to PTY with newline
   Why: Commands from input box need to execute in the shell
   Change:
   - onSubmit handler in Terminal.svelte receives command string
   - Append '\n' to command before sending to PTY (shell needs newline to execute)
   - Use existing terminalStore sendData mechanism: state.sendData(command + '\n')
   - Handle multiline commands: preserve internal newlines, append final newline
   - Record command in session history: POST to /api/terminals/:id/input-history
   - Update local history state in CommandInput after submission
   Tests: Manual test: submit commands, verify execution in PTY, check history
   Done when: Commands from input box execute in shell

** DONE [#B] Add POST endpoint to record input history
   Why: Frontend needs to record commands in backend history
   Change:
   - Add POST /api/terminals/:id/input-history endpoint
   - Request body: {command: string}
   - Call session.RecordInput(command) to store in buffer and persist
   - Return success or error response
   - Validation: reject empty commands (trimmed whitespace check)
   - Auth: same token-based auth as other endpoints
   Tests: API tests for POST input-history endpoint
   Done when: Frontend can record commands via REST

** DONE [#B] Disable direct PTY keyboard input
   Why: Ensure all input flows through CommandInput for a clean, consistent UX
   Change:
   - Remove or gate terminalStore.js key handlers that send keystrokes to PTY
   - Keep copy selection behavior and output rendering intact
   - Ensure Ctrl+C no longer sends to PTY from the terminal canvas
   - Document the new interaction model in README or UI hint text if needed
   Tests: Manual test: typing in terminal canvas does nothing; CommandInput works
   Done when: PTY only receives input from the CommandInput component
   - This is future work; current implementation keeps PTY input for compatibility
   - Add option to disable term.onData handler in terminalStore.js
   - Make input box the sole input method (no direct keyboard to PTY)
   - Requires testing with various shells and use cases
   - Consider escape hatch: Ctrl+Shift+I to toggle direct input mode
   - Document input isolation mode in README when implemented
   Tests: Manual test with input-only mode; verify no direct PTY input
   Done when: PTY input can be optionally disabled (deferred)

** TODO [#C] Add input history search functionality (future)
   Why: Users may want to search through command history
   Change:
   - Add search input box above CommandInput (or modal dialog)
   - Filter history by substring match
   - Show filtered results with highlighting
   - Select result to populate CommandInput
   - This is future enhancement; basic navigation is sufficient initially
   Tests: Manual test search and selection
   Done when: History search is functional (deferred)

** TODO [#C] Add AI-assisted input features (future)
   Why: Enable future features like command suggestions, templates, corrections
   Change:
   - Integration point: CommandInput can call AI APIs for suggestions
   - Examples: command completion, syntax checking, template expansion
   - This is future work enabled by input box architecture
   - Document architecture for extensions in README
   Tests: None (future work)
   Done when: Architecture documented for AI-assisted input (deferred)

** TODO [#C] Add input history cleanup policy
   Why: Prevent unbounded disk usage from command history files
   Change:
   - Reuse session log cleanup logic from persistence.go
   - Cleanup policy: keep last N files per terminal, or files from last 7 days
   - Run cleanup goroutine in Manager (similar to session log cleanup)
   - Make retention configurable: GESTALT_INPUT_HISTORY_RETENTION_DAYS (default 7)
   - Log cleanup actions at info level
   Tests: Create old files, run cleanup, verify deletion
   Done when: Old input history files are cleaned up automatically

** TODO [#C] Document input history system
   Why: Users and contributors need to understand input box and history
   Change:
   - Add "Command Input and History" section to README.md
   - Document input box usage: Enter to submit, Shift+Enter for multiline, Ctrl+Up/Down for history
   - Document history persistence: file format, location, retention policy
   - Document configuration: env vars for history dir, persistence, retention
   - Document REST API endpoints: GET/POST /api/terminals/:id/input-history
   - Document future features: search, AI-assisted input, PTY isolation
   Tests: None (documentation only)
   Done when: Input history system is fully documented

* DONE [#B] Embed all resources into gestalt binary
  Goal: Make gestalt binary fully self-contained by embedding frontend dist/, config/agents/, config/prompts/, and config/skills/ so it can run from anywhere without external files.
  Notes:
  - Use Go 1.16+ embed.FS for embedding files at compile time
  - Embed frontend/dist/ (built frontend assets)
  - Embed config/agents/*.json, config/prompts/*.txt, config/skills/*/ (default configs)
  - External override directory: ./gestalt/ (relative to binary location)
  - Runtime override: if ./gestalt/config/ exists, use it instead of embedded
  - Search order: ./gestalt/config/agents → embedded config/agents (same for prompts, skills)
  - Log which source is used: "using embedded config" or "using external config at ./gestalt/"
  - Update loaders to accept io.FS interface for embedded or real filesystem
  - Keep PLAN.org external (runtime-only, not embedded)
  - --extract-config flag writes all embedded resources to ./gestalt/ (config + frontend dist)
  - Extraction creates: ./gestalt/config/agents/, ./gestalt/config/prompts/, ./gestalt/config/skills/, ./gestalt/dist/
  Date: 2026-01-07

** Update agent loader to support embed.FS
   Why: Agent loader needs to read from embedded filesystem or real filesystem
   Change:
   - Add io.FS parameter to agent.Loader.Load()
   - Use fs.ReadDir and fs.ReadFile instead of os.ReadDir/os.ReadFile
   - Keep backward compatibility: if FS is nil, use os.DirFS as default
   - Update internal/agent/loader.go Load signature and implementation
   - Pass prompts directory as separate FS or combined with agents
   Tests: Unit tests with embed.FS mock; verify existing tests still pass
   Done when: Agent loader works with both embedded and real filesystems

** Update skill loader to support embed.FS
   Why: Skill loader needs to read from embedded filesystem
   Change:
   - Add io.FS parameter to skill.Loader.Load()
   - Use fs.ReadDir, fs.ReadFile, fs.Sub for nested directories
   - Support skills with scripts/, references/, assets/ from embedded FS
   - Keep backward compatibility: if FS is nil, use os.DirFS
   - Update internal/skill/loader.go
   Tests: Unit tests with embed.FS; verify nested directory handling
   Done when: Skill loader works with embedded filesystem

** Create embedded resources in cmd/gestalt/embed.go
   Why: Single place to define all embedded resources
   Change:
   - Create cmd/gestalt/embed.go with //go:embed directives
   - Embed frontend/dist/* as frontendFS (embed.FS)
   - Embed config/agents as agentsFS
   - Embed config/prompts as promptsFS
   - Embed config/skills as skillsFS
   - Export embedded FS variables or getter functions
   - Document each embedded directory in comments
   Tests: Build and verify embedded files are in binary (check binary size)
   Done when: All resources are embedded at compile time

** Update main.go to use embedded or external resources
   Why: Support runtime override of embedded defaults from ./gestalt/ directory
   Change:
   - Check if ./gestalt/config/agents/ exists; if yes, use os.DirFS("./gestalt/config")
   - If not, use embedded configFS from embed.go
   - Log decision: "using embedded config" or "using external config at ./gestalt/config"
   - Pass appropriate FS to agent and skill loaders
   - Check ./gestalt/dist/ for frontend; if exists, use it; else use embedded frontendFS
   - Update findStaticDir to return "./gestalt/dist" if it exists
   - Serve embedded frontend via http.FS if no ./gestalt/dist/
   Tests: Run binary with/without ./gestalt/ directory; verify correct source used
   Done when: Binary prefers ./gestalt/ overrides but falls back to embedded

** Update API static handler to serve embedded frontend
   Why: Serve embedded frontend when no external dist/ directory
   Change:
   - Modify RegisterRoutes to accept embed.FS for frontend
   - If staticDir is empty, check if embedded frontendFS is available
   - Use http.FileServer(http.FS(frontendFS)) for embedded serving
   - Ensure SPA routing works with embedded FS (index.html fallback)
   - Keep existing SPAHandler logic compatible
   Tests: Test static file serving with embedded FS
   Done when: Embedded frontend serves correctly via HTTP

** Add --extract-config CLI flag
   Why: Users may want to customize embedded defaults
   Change:
   - Add --extract-config flag to main.go
   - Extract all embedded resources to ./gestalt/ directory
   - Create: ./gestalt/config/agents/, ./gestalt/config/prompts/, ./gestalt/config/skills/
   - Create: ./gestalt/dist/ (frontend assets)
   - Write all embedded files preserving directory structure
   - Skip if files already exist (or add --force flag to overwrite)
   - Print extraction summary: "Extracted N agents, M prompts, P skills, frontend assets to ./gestalt/"
   - Exit after extraction (don't start server)
   Tests: Run gestalt --extract-config; verify ./gestalt/ structure created
   Done when: Users can extract all embedded resources to ./gestalt/ for customization

** Update Makefile build to ensure frontend is built
   Why: Embedded frontend requires dist/ to exist at build time
   Change:
   - Update make gestalt target to depend on frontend build
   - Add target: make build-frontend (cd frontend && npm run build)
   - Ensure make gestalt runs build-frontend first
   - Document build order in Makefile comments
   - Consider: make gestalt-dev (no embed) vs make gestalt (with embed)
   Tests: make clean && make gestalt; verify binary works standalone
   Done when: make gestalt produces fully self-contained binary

** Document embedded binary usage
   Why: Users need to understand embedded vs external config behavior
   Change:
   - Add "Embedded Resources" section to README.md
   - Document: binary contains default config and frontend
   - Document: ./gestalt/ directory overrides embedded defaults
   - Document: search order: ./gestalt/config → embedded config
   - Document: --extract-config flag to extract all resources to ./gestalt/
   - Document: how to build from source with embedding
   - Show example: copy gestalt binary anywhere and run
   - Show example: gestalt --extract-config, then customize ./gestalt/config/
   Tests: None (documentation only)
   Done when: README explains embedded resources and ./gestalt/ override

** Test standalone binary deployment
   Why: Verify binary truly works outside source tree
   Change:
   - Build binary: make gestalt
   - Copy to /tmp/gestalt-test/ (clean directory)
   - Run from there: ./gestalt (should use embedded resources)
   - Verify: frontend loads, agents/skills available, terminals work
   - Test: ./gestalt --extract-config (creates ./gestalt/ directory)
   - Modify ./gestalt/config/agents/example.json
   - Restart: ./gestalt (should use ./gestalt/config/)
   - Verify: modified config is active
   Tests: Integration test of standalone deployment and override
   Done when: Binary runs with embedded defaults and ./gestalt/ overrides work

* DONE [#B] gestalt-send CLI tool and agent instance management
  Goal: Create a CLI tool for piping stdin to agent terminals (e.g., `cat file | gestalt-send agent-name`), ensure agent profiles have unique names, enforce single-instance agents (only one terminal per agent), and use agent names for tab labels instead of "Terminal 1/2/3".
  Notes:
  - CLI tool: gestalt-send command that reads stdin and sends to agent's PTY via REST API
  - Usage: `cat file | gestalt-send architect` or `echo "command" | gestalt-send copilot`
  - Target agent by name (not terminal ID) for ease of use
  - Agent name uniqueness: enforce at load time in agent.Loader, reject duplicate names
  - Single-instance agents: Manager tracks agent→terminal mapping, prevent duplicate agent starts
  - Tab labeling: use agent.Name instead of generic "Terminal N"
  - API: add POST /api/agents/:name/input endpoint to send data to agent's terminal
  - If agent not running: return 404 or optionally auto-start (configurable)
  - Authentication: gestalt-send uses GESTALT_TOKEN env var (same as server)
  - Server URL: gestalt-send uses GESTALT_URL env var (default http://localhost:8080)
  - CLI flags: --url, --token, --start (auto-start agent if not running)
  - Error handling: clear messages if agent not found, not running, or network errors
  - Build: add cmd/gestalt-send/main.go, build with `make gestalt-send`
  - Install: copy binary to PATH or document usage from repo
  Date: 2025-12-31

** [#B] Enforce unique agent names in agent loader
   Why: Agent names must be unique to support instance management and CLI tool
   Change:
   - Modify internal/agent/loader.go Load() function
   - Track seen agent names during load, detect duplicates
   - If duplicate name found: return error with both file paths
   - Error message: "Duplicate agent name 'copilot' in files: agents/a.json, agents/b.json"
   - Validation happens after all files are parsed but before returning map
   - Use case-sensitive name comparison (names must match exactly)
   - Add unit test for duplicate detection with temp agent files
   Tests: Loader test with duplicate agent names; verify error returned
   Done when: Agent loader rejects duplicate names with clear error

** [#B] Add agent instance tracking to Manager
   Why: Enforce single-instance agents (only one terminal per agent)
   Change:
   - Add field to Manager: agentSessions map[string]string (agentName → terminalID)
   - Update Manager.Create() to check if agent already has a running terminal
   - If agentSessions[agentName] exists: return error ErrAgentAlreadyRunning
   - On session creation: record agentSessions[agentName] = session.ID
   - On session deletion: remove agentSessions[agentName]
   - Add method Manager.GetSessionByAgent(agentName string) (*Session, bool)
   - Handle case where agent profile is nil (non-agent terminals, allow multiple)
   - Thread-safe: protect agentSessions with Manager.mu mutex
   Tests: Manager tests for duplicate agent prevention, cleanup on delete
   Done when: Manager prevents duplicate agent instances

** [#B] Update createTerminal API to handle duplicate agents
   Why: REST API needs to return appropriate error for duplicate agents
   Change:
   - Modify internal/api/rest.go createTerminal handler
   - Catch terminal.ErrAgentAlreadyRunning error from Manager.Create()
   - Return 409 Conflict with message: "Agent 'name' is already running in terminal ID"
   - Include existing terminal ID in error response for frontend
   - Update error type: add Field string to apiError for terminal_id
   - Frontend can use this to switch to existing terminal tab instead of failing silently
   Tests: API integration test for duplicate agent creation
   Done when: API returns 409 for duplicate agents with terminal ID

** [#B] Update frontend to use agent name for tab labels
   Why: Tab labels should show agent name, not "Terminal N"
   Change:
   - Modify frontend/src/App.svelte openTerminalTab() or tab creation logic
   - Currently: `label: terminal.title || Terminal ${terminal.id}`
   - Change to prioritize agent name: if terminal has agent, use agent.name
   - Backend already sets Title from agent.Name in Manager.Create()
   - Verify terminal.title comes from API response correctly
   - Keep fallback for non-agent terminals: "Terminal {id}"
   Tests: Frontend unit test for tab label selection (agent title vs fallback), run `npm test -- tests/app.test.js`
   Done when: Agent terminal tabs display agent name

** [#B] Handle duplicate agent in frontend gracefully
   Why: When duplicate agent detected, switch to existing tab instead of error toast
   Change:
   - Modify Dashboard.svelte createTerminal() handler
   - Catch 409 response from POST /api/terminals
   - Parse terminal_id from error response
   - Find existing tab with that terminal ID and switch to it
   - Show info toast: "Agent 'name' is already running" (not error)
   - Optional: add visual feedback (tab highlight/flash)
   Tests: Frontend unit test for 409 handling (switch to existing tab + info toast), run `npm test -- tests/app.test.js`
   Done when: Duplicate agent creation switches to existing tab

** [#B] Add REST API endpoint for sending input to agent by name
   Why: CLI tool needs to send data to agent without knowing terminal ID
   Change:
   - Add POST /api/agents/:name/input endpoint in internal/api/routes.go
   - Look up agent terminal using Manager.GetSessionByAgent(name)
   - If not found: return 404 "Agent 'name' is not running"
   - Read request body as raw bytes (stdin data)
   - Write to session.input channel (same as WebSocket input)
   - Content-Type: application/octet-stream or text/plain
   - Return 200 OK with bytes written count
   - Auth: require token (same as other endpoints)
   Tests: API integration test for agent input endpoint
   Done when: API endpoint accepts input for agent by name

** [#B] Create gestalt-send CLI binary structure
   Why: Need separate CLI tool for piping data to agents
   Change:
   - Create cmd/gestalt-send/main.go
   - CLI flags: --url (default $GESTALT_URL or http://localhost:8080)
   - CLI flags: --token (default $GESTALT_TOKEN)
   - CLI flags: --start (auto-start agent if not running, future feature)
   - Positional arg: agent name (required)
   - Usage: gestalt-send [flags] <agent-name>
   - Read stdin until EOF using io.Copy or bufio.Reader
   - Basic structure: flag parsing, stdin read, HTTP POST
   - Exit codes: 0 (success), 1 (usage error), 2 (agent not found), 3 (network error)
   Tests: Go unit test for CLI arg parsing/usage errors in cmd/gestalt-send; run `go test ./cmd/gestalt-send`
   Done when: CLI binary structure exists with flag handling

** [#B] Implement stdin-to-HTTP POST in gestalt-send
   Why: Core functionality: pipe stdin to agent terminal via API
   Change:
   - Read stdin: io.ReadAll(os.Stdin) or streaming with bufio
   - Build URL: {baseURL}/api/agents/{agentName}/input
   - Create HTTP POST request with Authorization: Bearer {token}
   - Set Content-Type: application/octet-stream
   - Body: stdin bytes
   - Send request using http.DefaultClient with timeout (30s)
   - Handle responses: 200 (success), 404 (agent not running), 401 (auth), 500 (server error)
   - Print errors to stderr with helpful messages
   Tests: Go unit test with httptest server validating POST payload and exit codes, run `go test ./cmd/gestalt-send`
   Done when: stdin data is sent to agent terminal successfully

** [#B] Resolve agent name or id in gestalt-send
   Why: Allow CLI input to match either agent ID or agent name.
   Change:
   - Query /api/agents and resolve input to agent ID + agent name.
   - If input matches agent ID, use corresponding agent name for /api/agents/:name/input.
   - If input matches agent name, use corresponding agent ID for /api/terminals (auto-start).
   - If input matches both with different agents, return a clear error.
   - Cache agent list for 60s (reuse completion cache dir or in-memory).
   Tests: Go unit test for name/id resolution and ambiguous cases; run `go test ./cmd/gestalt-send`
   Done when: CLI accepts either id or name without ambiguity.

** [#C] Add auto-start option to gestalt-send (optional)
   Why: Convenience feature to start agent if not already running
   Change:
   - Add --start flag to gestalt-send CLI
   - If POST /api/agents/:name/input returns 404 and --start is set:
   - Call POST /api/terminals with agent name to create terminal
   - Retry POST /api/agents/:name/input after short delay (1s)
   - Handle race condition if another process starts agent simultaneously
   - This is optional enhancement; basic version requires agent running
   Tests: Manual test with --start flag
   Done when: Auto-start flag creates agent terminal if missing (optional)

** [#C] Add verbose and debug output to gestalt-send
   Why: Help users diagnose connection and authentication issues
   Change:
   - Add --verbose flag: print HTTP request/response details to stderr
   - Add --debug flag: print full request body preview (first 100 bytes)
   - Show: URL, token (masked), response status, bytes sent
   - Do not print sensitive data (full token) unless --debug explicitly set
   - Use structured output: "Sending N bytes to agent 'X' at URL..."
   Tests: Manual test with --verbose and --debug flags
   Done when: CLI provides helpful diagnostic output

** [#C] Build and install gestalt-send in Makefile
   Why: Users need easy way to build and install CLI tool
   Change:
   - Add gestalt-send target to GNUmakefile
   - Build: go build -o gestalt-send cmd/gestalt-send/main.go
   - Add to default build target (alongside gestalt server)
   - Add install target: copy gestalt-send to /usr/local/bin or ~/.local/bin
   - Document in README: make gestalt-send, sudo make install
   - Consider: version stamping with ldflags (same as server)
   Tests: make gestalt-send; verify binary works
   Done when: gestalt-send builds via Makefile

** [#C] Add shell completion for gestalt-send (optional)
   Why: Improve CLI UX with agent name tab-completion
   Change:
   - Generate bash/zsh completion scripts
   - Completion: fetch agent names from GET /api/agents
   - Cache agent names for 60s to avoid repeated API calls
   - Install completion: gestalt-send completion bash > /etc/bash_completion.d/gestalt-send
   - This is optional enhancement for better UX
   Tests: Manual test tab-completion in bash/zsh
   Done when: Shell completion works for agent names (optional)

** [#C] Document gestalt-send usage and examples
   Why: Users need to understand CLI tool usage patterns
   Change:
   - Add "gestalt-send CLI Tool" section to README.md
   - Document installation: make gestalt-send, copy to PATH
   - Document environment variables: GESTALT_URL, GESTALT_TOKEN
   - Document usage: cat file | gestalt-send agent-name
   - Add examples: piping file contents, command output, multi-line input
   - Example use cases: send logs to agent, feed data for analysis, scripting
   - Document error codes and troubleshooting
   - Document --start flag (if implemented)
   Tests: None (documentation only)
   Done when: gestalt-send is fully documented with examples

** [#C] Add integration test for end-to-end CLI workflow
   Why: Verify complete workflow from CLI to agent terminal
   Change:
   - Create test: start server, create agent terminal, run gestalt-send
   - Verify data appears in terminal output buffer
   - Test error cases: agent not found, wrong token, network errors
   - Use temp config directory with test agent profiles
   - Clean up terminals after test
   Tests: Integration test in cmd/gestalt-send/
   Done when: End-to-end CLI test passes reliably


* DONE [#B] Agent Skills integration
  Goal: Integrate the Agent Skills standard (agentskills.io) into Gestalt to provide agents with discoverable, on-demand capabilities through structured skill packages stored in config/skills/
  Notes:
  - Agent Skills are folders containing SKILL.md (YAML frontmatter + Markdown instructions)
  - Progressive disclosure: load metadata at startup, full instructions on activation
  - Skills can include optional directories: scripts/, references/, assets/
  - Each skill has: name, description (for discovery), license, compatibility, metadata
  - Agents in config/agents/*.json can reference skills via "skills": ["skill-name", ...]
  - Skill metadata injected into agent system prompt for discovery
  - When agent activates a skill, full SKILL.md is provided to the LLM
  - Scripts in skills/ can be executed by the agent
  - Reference files loaded on-demand to save context
  - Validation: skill names must match directory names, required frontmatter fields
  - Security: consider sandboxing script execution, logging, confirmation prompts
  - Integration approach: filesystem-based (agents use shell commands to access skills)
  - Skills are portable, versionable, and shareable across different agent tools
  Date: 2025-12-31

**  [#B] Create skill data structure and parser
   Why: Need to parse SKILL.md frontmatter and validate skill format
   Change:
   - Create internal/skill/ package with Skill struct
   - Fields: Name, Description, License, Compatibility, Metadata (map), AllowedTools ([]string)
   - Fields: Path (skill directory), Content (markdown body after frontmatter)
   - Add YAML frontmatter parser (use gopkg.in/yaml.v3 for minimal dependency)
   - Parse both frontmatter and body content from SKILL.md
   - Validate: name format (lowercase, hyphens, 1-64 chars, no leading/trailing hyphen)
   - Validate: description (1-1024 chars, non-empty)
   - Validate: name matches parent directory name
   - Add optional validation for scripts/, references/, assets/ directories
   - Document skill struct in internal/skill/doc.go
   Tests: Unit tests for parsing valid/invalid SKILL.md files, validation edge cases
   Done when: Skill struct exists with YAML parsing and validation

**  [#B] Implement skill loader from config/skills/
   Why: Load skill packages from filesystem at startup
   Change:
   - Create skill.Loader with Load(dir string) (map[string]*Skill, error)
   - Scan config/skills/*/ directories for SKILL.md files
   - Parse each SKILL.md into Skill struct (frontmatter + body)
   - Use directory name as skill ID, validate against frontmatter name
   - Return map[skillID]*Skill for easy lookup
   - Handle errors: missing SKILL.md, invalid YAML, validation failures
   - If config/skills/ doesn't exist, return empty map (not an error)
   - Log warnings for invalid skills but don't fail entire load
   - Check for optional directories (scripts/, references/, assets/)
   Tests: Unit tests with temp directories; valid/invalid skill structures
   Done when: Loader successfully reads skill packages from directory

**  [#B] Wire skill loader into Manager initialization
   Why: Manager needs access to skills for agent initialization
   Change:
   - Add Skills field to ManagerOptions: map[string]*skill.Skill
   - Load skills in cmd/gestalt/main.go before creating Manager
   - Pass skills to Manager via ManagerOptions
   - Store skills in Manager struct for lookup during terminal creation
   - Add method Manager.GetSkill(name string) (*Skill, bool)
   - Add method Manager.ListSkills() []SkillMetadata (for API)
   Tests: Integration test verifying Manager has skills after init
   Done when: Manager has access to loaded skill packages

**  [#B] Extend agent profiles to reference skills
   Why: Agents need to declare which skills they have access to
   Change:
   - Add Skills field to Agent struct: []string `json:"skills"`
   - Skills field is optional array of skill names
   - Validate skill references during agent load: warn if skill doesn't exist
   - Store resolved skill references in agent for prompt generation
   - Update example agent configs to demonstrate skills usage
   - Example: "skills": ["git-workflows", "code-review", "data-analysis"]
   Tests: Agent loader tests with valid/invalid skill references
   Done when: Agent profiles can declare skill dependencies

**  [#C] Generate skill metadata for agent prompts
   Why: Agents need skill discovery information in system prompt
   Change:
   - Create skill.GeneratePromptXML(skills []*Skill) string function
   - Generate XML format: <available_skills><skill><name>...</name><description>...</description><location>...</location></skill></available_skills>
   - Include absolute path to SKILL.md in <location> for filesystem access
   - Keep metadata concise (~50-100 tokens per skill)
   - Only include skills referenced by the agent (from agent.Skills array)
   - Document XML format for prompt injection
   Tests: Unit tests for XML generation with various skill sets
   Done when: Function generates proper XML for agent system prompts

**  [#B] Inject skill metadata into agent prompts
   Why: Agents must know which skills are available at startup
   Change:
   - Modify prompt injection logic in terminal/session.go
   - After shell starts, before custom prompts, inject skill metadata
   - Generate XML from agent's skill list: GeneratePromptXML(agent.Skills)
   - Write skill metadata as initial prompt content
   - Add delay (100ms) before custom prompts
   - Log skill injection at info level
   - Handle case where agent has no skills (skip injection)
   Tests: Manual test: create agent with skills, verify XML in terminal
   Done when: Skill metadata appears in agent terminal on startup

**  [#C] Add GET /api/skills endpoint
   Why: Frontend and external tools need to query available skills
   Change:
   - Add GET /api/skills REST endpoint
   - Return array of skill metadata: name, description, path, license
   - Optionally filter by agent: GET /api/skills?agent=copilot
   - Include skill directory structure info (has scripts, references, assets)
   - Add unit tests for endpoint
   Tests: GET /api/skills returns skill list with metadata
   Done when: API endpoint exposes available skills

**  [#C] Add GET /api/skills/:name endpoint
   Why: Agents/users may need to read full skill content
   Change:
   - Add GET /api/skills/:name endpoint
   - Return full skill details: metadata + markdown body + directory structure
   - Include list of files in scripts/, references/, assets/
   - Optionally: GET /api/skills/:name/files/:path to read specific files
   - Handle file not found errors gracefully
   Tests: GET /api/skills/:name returns complete skill information
   Done when: API endpoint exposes full skill content

**  [#C] Create example skills in config/skills/
   Why: Provide working examples for users
   Change:
   - Create config/skills/ directory
   - Add example skill: config/skills/git-workflows/SKILL.md
   - Add example skill: config/skills/code-review/SKILL.md
   - Add example skill: config/skills/terminal-navigation/SKILL.md
   - Each example includes: proper frontmatter, clear instructions, references
   - Optional: include example scripts in scripts/ directory
   - Document skill format in README.md
   Tests: Load examples; verify they parse correctly
   Done when: Example skills exist and demonstrate the format

**  [#C] Update frontend to display skills
   Why: Users should see which skills are available
   Change:
   - Add "Skills" section to Dashboard.svelte
   - Fetch skills via GET /api/skills on mount
   - Display skill cards: name, description, associated agents
   - Optional: clicking skill shows full SKILL.md content in modal
   - Show skill count in dashboard status
   - Update UI to show which skills an agent has when creating terminal
   Tests: Manual test skills display in UI
   Done when: Dashboard shows available skills

**  [#C] Document Agent Skills integration
   Why: Users and contributors need to understand skills system
   Change:
   - Add "Agent Skills" section to README.md
   - Document skill directory structure and SKILL.md format
   - Document how to create new skills
   - Document how to assign skills to agents
   - Link to agentskills.io specification
   - Document skill discovery and activation process
   - Add examples of skill usage patterns
   Tests: None (documentation only)
   Done when: Agent Skills system is fully documented

**  [#C] Add skill validation CLI command (optional)
   Why: Help users create valid skills
   Change:
   - Add CLI command: gestalt validate-skill <path>
   - Use internal/skill package to validate skill structure
   - Check frontmatter format, name rules, required fields
   - Check for optional directories and common mistakes
   - Print validation results and suggestions
   - Exit with code 0 (valid) or 1 (invalid)
   - Alternative: document using skills-ref CLI from agentskills.io
   Tests: Manual test with valid/invalid skill directories
   Done when: Users can validate skills before deployment (optional)

**  [#C] Consider script execution security (future)
   Why: Executing skill scripts has security implications
   Change:
   - Document security considerations in README
   - Consider: sandboxing, allowlisting, user confirmation prompts
   - Consider: logging all script executions for auditing
   - Consider: skill signature verification for trusted sources
   - This is future work; initial implementation trusts all skills in config/
   - Add warning in docs about only using trusted skills
   Tests: None (documentation and future planning)
   Done when: Security considerations documented (implementation deferred)

**  [#B] Fix skill prompt injection order and content
   Why: Skill metadata is being injected into terminal output before agent prompts; skill instructions should appear after prompts as a marked Skills section.
   Change:
   - Trace the prompt/skill injection path to confirm where terminal output is written.
   - Adjust ordering so agent prompt(s) run first, then insert a clear "Skills" section containing the full SKILL.md content.
   - Ensure metadata XML stays in the LLM system prompt only (not written to the terminal).
   Tests: Manual check: startup shows agent prompt first, then skills section with SKILL.md content.
   Done when: Terminal startup output order matches expected prompt -> skills section, and XML metadata is not printed to the terminal.

**  [#B] Update available_skills metadata format and stop terminal printing
   Why: Skills should be provided as metadata-only context (name + description), not printed to the terminal.
   Change:
   - Replace the current skill metadata format with the requested <available_skills> block lines (name + description).
   - Ensure the metadata is injected only into the skill tool description/system prompt, never written to the terminal.
   - Keep the UI subtitle for skills in the terminal header.
   - Update tests to cover the new metadata format and ensure no terminal writes.
   Tests: Unit test for metadata formatting; manual check that terminal output no longer prints skills.
   Done when: Skill metadata uses the new format and terminal output stays clean.

* DONE [#B] Terminal history persistence across disconnects
  Goal: Preserve terminal output history when users disconnect and reconnect, allowing them to see what happened while they were away.
  Notes:
  - Current problem: OutputBuffer (1000 lines) exists in memory but xterm.js instance is fresh on reconnect
  - When WebSocket connects, it only receives new output (fire-and-forget broadcast)
  - Users lose scrollback history if they close browser or reload page
  - Existing GET /api/terminals/:id/output endpoint returns buffer lines but frontend doesn't use it
  - Solutions considered:
    1. Simple: Fetch buffer via REST on connect, write to xterm before attaching WebSocket
    2. Enhanced: Persist to disk (logs/sessions/{id}.txt), survive server restarts
    3. Hybrid: In-memory buffer + optional disk persistence (configurable)
  - Decision: Start with solution 1 (REST fetch on connect), then add optional disk persistence
  - Disk format: logs/sessions/{terminalId}-{timestamp}.txt with append-only writes
  - Cleanup policy: keep last N sessions per terminal, or files from last 7 days
  - Performance: async file writes, buffered I/O, don't block terminal operations
  Date: 2025-12-30

** Wire existing /output endpoint into frontend on connect
   Why: Backend already buffers 1000 lines; frontend just needs to fetch and display them
   Change:
   - In terminalStore.js, fetch GET /api/terminals/{id}/output before connecting WebSocket
   - Write buffered lines to xterm using term.write() or term.writeln()
   - Handle edge cases: empty buffer, API errors, slow responses
   - Add loading state: "Loading history..." status message
   - Preserve terminal state: don't clear xterm on reconnect
   - Consider: ANSI escape sequences in buffer may need processing
   Tests: Manual test: connect, type output, disconnect, reconnect → verify history appears
   Done when: Reconnecting shows buffered output from OutputBuffer

** Add optional disk persistence for terminal output
   Why: Survive server restarts and provide longer history than in-memory buffer
   Change:
   - Create internal/terminal/persistence.go with SessionLogger
   - SessionLogger: async writer that appends to logs/sessions/{terminalId}-{timestamp}.txt
   - Hook into Session.broadcastLoop: write chunks to both Broadcaster and SessionLogger
   - Use buffered writer (bufio.Writer) with periodic flush (every 1s or 4KB)
   - Handle file creation errors gracefully: log warning, continue without persistence
   - Add Close() method to flush and close file on session termination
   Tests: Unit test SessionLogger; integration test verifies file contents
   Done when: Terminal output is written to disk asynchronously

** Load persisted history on session reconnect
   Why: Restore history beyond in-memory buffer limit after server restart
   Change:
   - On WebSocket connect, check if session file exists
   - If exists: read last N lines (e.g., 2000) from file
   - Send historical lines to subscriber before live output
   - Handle large files: use tail-like reading (seek to end, read backwards)
   - Combine with in-memory buffer: prefer buffer if available, fall back to file
   - Add GET /api/terminals/:id/history?lines=N endpoint for REST access
   Tests: Restart server, reconnect → verify persisted history loads
   Done when: Reconnect shows persisted history from disk

** Add session file cleanup policy
   Why: Prevent unbounded disk usage from accumulating session logs
   Change:
   - Create cleanup goroutine in Manager: runs hourly
   - Policy: keep last 5 sessions per terminal ID, or files modified in last 7 days
   - Delete oldest files that don't match retention policy
   - Make retention configurable: GESTALT_SESSION_RETENTION_DAYS (default 7)
   - Log cleanup actions at info level
   - Handle concurrent file access: ignore "file not found" errors during cleanup
   Tests: Create old files, run cleanup, verify correct files deleted
   Done when: Old session logs are automatically cleaned up

** Add configuration options for persistence
   Why: Users may want to disable persistence or tune buffer sizes
   Change:
   - Add env vars: GESTALT_SESSION_PERSIST (true/false), GESTALT_SESSION_DIR (default logs/sessions)
   - Add GESTALT_SESSION_BUFFER_LINES (default 1000) for in-memory buffer size
   - Document in README.md under configuration section
   - Make persistence opt-in or opt-out (decide based on disk usage concerns)
   - Add /api/status field showing persistence status
   Tests: Test with persistence disabled; verify no files created
   Done when: Persistence is configurable via env vars

** Optimize file I/O for high-throughput terminals
   Why: Avoid blocking or degrading terminal performance with disk writes
   Change:
   - Use channel-based async writes: SessionLogger has write channel (buffered)
   - Goroutine drains channel and writes to disk
   - If channel fills, drop oldest chunks (lossy under extreme load)
   - Add metrics: dropped chunks counter, flush latency
   - Consider: rotate files after size threshold (e.g., 10MB)
   Tests: Stress test with high output rate; verify no blocking
   Done when: Disk persistence doesn't impact terminal responsiveness

** Update frontend to indicate history loading state
   Why: Users should know when history is being loaded vs live output
   Change:
   - Add status indicator: "Loading history..." during fetch
   - Show visual separator between history and live output (optional)
   - Add timestamp annotations if loading persisted history
   - Handle slow history loads: timeout after 5s, show warning
   - Consider: virtualized scrolling for very long history
   Tests: Manual test with large history buffer
   Done when: Users see clear feedback during history load

* DONE [#B] Org-mode PLAN.org viewer component
  Goal: Add a pleasant, compact Svelte outliner component to visualize PLAN.org with foldable sections, syntax highlighting for TODO/WIP/DONE keywords, priorities, and eventual sidebar integration.
  Notes:
  - Target users: casual users who don't use Emacs org-mode
  - Style inspiration: Emacs org-mode rendering but more polished and user-friendly
  - Must support: folding/expanding headings, keyword highlighting (TODO/WIP/DONE), priority badges ([#A], [#B], [#C])
  - Must be compact: designed for eventual sidebar placement alongside terminals
  - Parser: lightweight custom parser (no external org-mode lib dependencies)
  - Features: collapse/expand all, collapse by level, keyword filtering, search (optional)
  - Interaction: click to expand/collapse, visual hierarchy with indentation
  - Backend: serve PLAN.org via GET /api/plan endpoint (read-only for now)
  - Frontend: new OrgViewer.svelte component, add "Plan" tab to dashboard
  - Future: editing support, sync with file changes, real-time updates
  Date: 2025-12-29

** [#B] Create backend endpoint to serve PLAN.org
   Why: Frontend needs access to PLAN.org contents via API
   Change:
   - Add GET /api/plan endpoint in api/routes.go
   - Read PLAN.org file from project root
   - Return raw text content with text/plain or application/json (wrap in {"content": "..."})
   - Handle file not found gracefully (return empty or error)
   - No auth required initially (read-only public data)
   - Consider: ETag/Last-Modified headers for caching
   Tests: GET /api/plan returns PLAN.org contents
   Done when: API endpoint serves PLAN.org file contents

** [#B] Create org-mode parser for outline structure
   Why: Need to parse org-mode syntax into structured data for rendering
   Change:
   - Create frontend/src/lib/orgParser.js
   - Parse org headings: detect * ** *** heading levels
   - Extract TODO keywords: TODO, WIP, DONE (configurable array)
   - Extract priority: [#A], [#B], [#C] patterns
   - Extract heading text (after keywords/priority)
   - Build tree structure: {level, keyword, priority, text, children, collapsed}
   - Parse body text: lines between headings belong to parent heading
   - Handle edge cases: empty lines, malformed headings, missing keywords
   - Return array of top-level nodes with nested children
   Tests: Unit tests with sample org-mode text; verify tree structure
   Done when: Parser converts org text to structured tree

** [#B] Create OrgViewer Svelte component
   Why: Main UI component for displaying parsed org-mode outline
   Change:
   - Create frontend/src/components/OrgViewer.svelte
   - Accept props: orgText (string) or orgTree (parsed structure)
   - If orgText provided, parse on mount using orgParser
   - Render tree recursively: OrgNode components for each heading
   - Styling: compact vertical spacing, clear hierarchy with indentation
   - Responsive: works in full tab or sidebar (flexible width)
   - Handle empty/loading state gracefully
   Tests: Manual rendering test with sample org-mode content
   Done when: Component renders parsed org-mode structure

** [#B] Create OrgNode component for heading rendering
   Why: Recursive component for each outline node with expand/collapse
   Change:
   - Create frontend/src/components/OrgNode.svelte
   - Props: node (heading data), level (indent depth), onToggle callback
   - Render: expand/collapse icon + keyword badge + priority badge + heading text
   - Expand icon: ▶ (collapsed) or ▼ (expanded), click to toggle
   - Keyword styling: TODO (blue), WIP (yellow/orange), DONE (green/gray), none (default)
   - Priority styling: [#A] (red), [#B] (orange), [#C] (gray/muted)
   - Body text: render in muted color below heading when expanded
   - Children: recursively render child nodes when expanded
   - Indentation: left padding based on level (e.g., level * 1.5rem)
   Tests: Manual test with nested headings, toggle behavior
   Done when: Individual nodes render with proper styling and expand/collapse

** [#C] Add expand/collapse controls
   Why: Users need convenient ways to navigate large outlines
   Change:
   - Add toolbar buttons: "Expand All", "Collapse All"
   - Add level-based collapse: "Collapse to L1", "Collapse to L2"
   - Implement recursive state updates in OrgViewer
   - Persist expand/collapse state in component state (not localStorage yet)
   - Keyboard shortcuts: Space to toggle focused node (optional)
   Tests: Manual test expand/collapse functionality
   Done when: Toolbar controls work correctly

** [#C] Add keyword filtering
   Why: Users may want to focus on TODO/WIP items only
   Change:
   - Add filter dropdown: "All", "TODO only", "WIP only", "DONE only", "TODO+WIP"
   - Filter at render time: hide nodes that don't match filter
   - Show/hide body text based on filter setting
   - Preserve expand/collapse state during filtering
   Tests: Manual test filtering with various keyword combinations
   Done when: Filter dropdown correctly shows/hides nodes

** [#C] Add search functionality (optional)
   Why: Large plans benefit from text search
   Change:
   - Add search input box in toolbar
   - Highlight matching text in headings and body
   - Auto-expand nodes containing matches
   - Clear highlights on search clear
   - Debounce search input (300ms)
   Tests: Manual test search with various queries
   Done when: Search highlights and expands matching nodes

** [#B] Integrate OrgViewer into dashboard
   Why: Users need access to plan viewer in the UI
   Change:
   - Add "Plan" tab to TabBar (after Dashboard, before terminal tabs)
   - Create PlanView.svelte wrapper component
   - Fetch /api/plan on mount, pass to OrgViewer
   - Handle loading and error states
   - Add refresh button to reload plan
   - Style consistent with rest of app
   Tests: Manual test Plan tab in UI
   Done when: Plan tab shows PLAN.org outline

** [#C] Polish styling and responsiveness
   Why: Ensure component is pleasant and usable as specified
   Change:
   - Refine color scheme: match Gestalt design language
   - Ensure compact spacing: maximize information density
   - Test in narrow sidebar width (e.g., 300px)
   - Smooth animations for expand/collapse (CSS transitions)
   - Hover effects on headings
   - Focus states for accessibility
   - Dark mode support (if app has dark mode)
   Tests: Manual visual testing at various widths
   Done when: Component looks polished and works in sidebar

** TODO [#C] Add CSS for compact sidebar layout (future)
   Why: Component should eventually work as sidebar alongside terminals
   Change:
   - Design sidebar layout: resizable splitter between plan and terminals
   - Add sidebar toggle button
   - Persist sidebar width and visibility in localStorage
   - Ensure terminals resize correctly when sidebar shown/hidden
   - This step is future work, not blocking initial implementation
   Tests: Manual test sidebar integration
   Done when: Plan viewer works as collapsible sidebar (defer to later)

* DONE [#A] Comprehensive testing strategy and regression protection
  Goal: Establish robust test coverage for all Gestalt features to prevent regressions and ensure reliability.
  Notes:
  - Current state: 11 test files, ~1939 lines of tests, all tests passing
  - Coverage: agent (excellent), api (good), logging (good), terminal (good), orchestrator (none), cmd (none)
  - Backend: 25 source files, 11 test files (44% file coverage, likely lower line coverage)
  - Frontend: No test infrastructure currently configured
  - Testing philosophy: pragmatic, focus on critical paths and integration points
  - Tools: Go standard testing + table-driven tests, consider testify/assert for readability
  - Frontend tools: Vitest + Svelte Testing Library (matches Vite/Svelte stack)
  - Integration: E2E tests for WebSocket flows, API interactions, terminal lifecycle
  - Strategy: unit tests for logic, integration tests for I/O and state, E2E for user flows
  Date: 2025-12-29

** [#B] Audit and document current test coverage
   Why: Understand what's tested, what's missing, establish baseline metrics
   Change:
   - Run `go test -cover ./...` and document coverage percentages per package
   - Identify untested packages: orchestrator (no tests), cmd/gestalt (no tests)
   - List critical untested code paths: prompt injection, session lifecycle, WebSocket reconnection
   - Document existing test patterns: fakePty, table-driven tests, integration test helpers
   - Create TESTING.md documenting testing approach, conventions, and how to run tests
   - Set coverage targets: aim for 70% overall, 80%+ for critical packages (agent, terminal, api)
   Tests: Document current coverage; no new tests in this step
   Done when: TESTING.md exists with coverage audit and testing guidelines

** [#B] Add missing unit tests for terminal package
   Why: Terminal session/manager is core functionality with some untested paths
   Change:
   - Test session lifecycle: creation, input/output, close, cleanup
   - Test prompt injection: single prompt, multiple prompts, missing files, timing
   - Test output buffer: circular behavior, line extraction, race conditions
   - Test broadcaster: multi-subscriber fanout, slow subscriber handling, close behavior
   - Test shell selection logic: SHELL env var, fallbacks, Windows vs Unix
   - Add table-driven tests for edge cases (empty input, large buffers, concurrent access)
   - Test onair_string detection and prompt injection gating
   Tests: Increase terminal package coverage to 80%+
   Done when: Critical terminal paths have test coverage; go test ./... passes

** [#B] Add unit tests for orchestrator package
   Why: Currently has no tests; future inter-terminal communication depends on it
   Change:
   - Test any existing orchestrator logic (currently minimal/stub)
   - If orchestrator is empty stub, add placeholder test file with package structure
   - Document intended orchestrator responsibilities in doc.go
   - Add tests as orchestrator features are implemented
   Tests: Basic orchestrator test file exists
   Done when: orchestrator package has test foundation ready for future features

** [#C] Add integration tests for cmd/gestalt
   Why: Main entry point has no tests; configuration loading and wiring needs validation
   Change:
   - Test config loading: env vars (PORT, SHELL, TOKEN), defaults
   - Test agent loading integration: valid/invalid agent files, missing prompts
   - Test static file serving: frontend dist directory detection
   - Consider: spin up test server, verify endpoints respond (heavy, may defer)
   - Document why some paths are hard to test (server startup, signal handling)
   Tests: Basic cmd/gestalt test coverage for config and initialization
   Done when: Config loading and agent wiring have test coverage

** [#B] Add WebSocket integration tests
   Why: WebSocket flows are critical but complex; need end-to-end validation
   Change:
   - Test terminal WebSocket: connect, send input, receive output, resize, disconnect
   - Test logs WebSocket: connect, receive log stream, filter by level, disconnect
   - Test auth: token validation, unauthorized access, missing token
   - Test reconnection: connection drop, exponential backoff, auth failure
   - Test concurrent connections: multiple clients to same terminal
   - Use gorilla/websocket test client or real WebSocket connections
   - Mock PTY for deterministic terminal output in tests
   Tests: WebSocket integration tests pass reliably
   Done when: Critical WebSocket paths tested; can detect regressions

** [#B] Setup frontend testing infrastructure
   Why: Frontend has zero tests; UI regressions go unnoticed
   Change:
   - Install Vitest: `npm install -D vitest @testing-library/svelte jsdom`
   - Configure vitest.config.js for Svelte component testing
   - Add test script to package.json: `"test": "vitest run"`
   - Create example test: terminalStore.test.js or api.test.js
   - Document frontend testing approach in TESTING.md
   - Consider: Playwright for E2E UI tests (defer if too heavy initially)
   Tests: npm test runs and passes
   Done when: Frontend test infrastructure is functional

** [#B] Add frontend unit tests for core modules
   Why: Store logic and API client are testable without full component rendering
   Change:
   - Test api.js: apiFetch error handling, buildWebSocketUrl, token handling
   - Test terminalStore.js: state management, WebSocket lifecycle, reconnection logic
   - Test notificationStore.js: add/dismiss/auto-dismiss, toast lifecycle
   - Mock fetch API and WebSocket for deterministic tests
   - Use vi.mock() for module mocking in Vitest
   Tests: Core frontend logic has unit test coverage
   Done when: API client and stores have 70%+ test coverage

** [#C] Add frontend component tests
   Why: UI components need testing but are lower priority than logic
   Change:
   - Test Dashboard.svelte: agent buttons, terminal creation, error display
   - Test TabBar.svelte: tab switching, close button, active state
   - Test Toast.svelte: display, auto-dismiss, dismiss button
   - Test LogsView.svelte: log filtering, refresh, display
   - Use @testing-library/svelte for component testing (render, user events)
   - Focus on behavior, not implementation details
   Tests: Key UI components have test coverage
   Done when: Dashboard and TabBar have basic component tests

** [#B] Add E2E integration test suite
   Why: Validate complete user flows across backend and frontend
   Change:
   - Setup E2E test harness: start server, create test client, cleanup
   - Test flow: start server → create terminal via API → connect WebSocket → send input → verify output
   - Test flow: create agent terminal → verify prompt injection → verify onair_string gating
   - Test flow: trigger log event → verify toast appears → verify log in logs tab
   - Test auth flow: missing token → 401 → provide token → success
   - Consider: Playwright for browser-based E2E (can defer if too heavy)
   - Document E2E test execution in TESTING.md
   Tests: E2E test suite passes reliably
   Done when: Critical user flows have E2E test coverage

** [#C] Add test coverage reporting and CI integration
   Why: Track coverage over time, prevent coverage regressions
   Change:
   - Setup Go coverage reporting: `go test -coverprofile=coverage.out ./...`
   - Setup frontend coverage: configure Vitest coverage (c8 or istanbul)
   - Add coverage thresholds: fail if coverage drops below targets
   - Consider: upload coverage to codecov.io or similar (optional)
   - Document coverage commands in TESTING.md
   - Add CI workflow if using GitHub Actions (run tests on PR/push)
   Tests: Coverage reports generate successfully
   Done when: Coverage tracking is automated and documented

** [#C] Add property-based and fuzz testing (optional)
   Why: Find edge cases that manual test cases miss
   Change:
   - Identify good candidates: agent JSON parsing, prompt name validation, log filtering
   - Use Go testing.F for fuzz testing (built into Go 1.18+)
   - Consider: rapid for property-based testing (external dep, may skip)
   - Add fuzz tests for JSON unmarshaling with malformed input
   - Add fuzz tests for path parsing with unusual characters
   - Document fuzz testing in TESTING.md
   Tests: Fuzz tests run and find no crashes
   Done when: Critical parsing logic has fuzz test coverage (optional)

** [#C] Document testing best practices and conventions
   Why: Maintain test quality as codebase grows
   Change:
   - Extend TESTING.md with best practices: table-driven tests, test naming, mocking
   - Document when to unit test vs integration test vs E2E test
   - Document test fixture patterns: fakePty, test servers, temp directories
   - Add examples of good tests from existing codebase
   - Document how to debug failing tests
   - Document test performance: keep unit tests fast (<10ms), integration tests moderate (<100ms)
   Tests: None (documentation only)
   Done when: TESTING.md has comprehensive testing guidelines

* DONE [#B] Fix agent shell args + toast-to-log parity
  Goal: Allow agent shell strings to include arguments, and ensure every toast is also logged.
  Notes:
  - Current agent shell field appears to be a single string passed to exec without args.
  - Desired: support space-separated args (and optionally quoted args) in the shell string.
  - Ensure frontend toasts also emit structured log entries so they appear in Logs view and /api/logs.
  - Keep behavior minimal and explicit; avoid new dependencies unless required.
** [#B] Support shell string arguments in agent config
   Why: Agents like copilot require a shell/command plus flags in config.
   Change:
   - Parse agent.Shell into command + args (define parsing rules, e.g., shlex-like or simple split)
   - Update session/terminal spawn to accept argv rather than only a single path
   - Update validation and tests for parsing edge cases
   Tests: Unit tests for parsing; go test ./...
   Done when: Agent shell config accepts args and agent launches correctly
** [#B] Log all toast notifications to backend logs
   Why: User-facing toasts must be discoverable in the Logs tab and /api/logs.
   Change:
   - Identify toast creation flow in frontend
   - Ensure each toast emission also creates a log entry (client-side via /api/logs or server-side via logger hooks)
   - Keep log level aligned with toast level
   Tests: Frontend behavior + backend log visibility; go test ./...
   Done when: Every toast is mirrored in backend logs

* DONE [#B] Multi-prompt injection on agent startup
  Goal: Extend agent configuration to support multiple prompts injected sequentially on terminal start.
  Notes:
  - Current: agent has "prompt_file" (string) that references a single file
  - Desired: agent has "prompt" field that can be string OR array of strings
  - Each string is a prompt name (not full path); resolve to config/prompts/{name}.txt
  - Example: "prompt": ["coder", "architect"] → inject coder.txt then architect.txt
  - Backward compatibility for "prompt_file" requires explicit decision
  - Prompts injected sequentially with small delay between each (e.g., 100ms)
  - Empty/missing prompt field means no injection (current default behavior)
  Date: 2025-12-29

** [#B] Confirm prompt_file compatibility decision
   Why: Avoid breaking existing configs without explicit approval
   Change: Decide whether to keep supporting "prompt_file" or remove it
   Tests: None (decision only)
   Done when: Compatibility approach is confirmed

** [#B] Update Agent struct to support prompt array
   Why: Need to accept both single string and array of strings for prompts
   Change:
   - Add new field: Prompts []string `json:"prompt"` to Agent struct
   - Remove PromptFile string `json:"prompt_file"` field entirely
   - Update Validate() to handle new format
   - Update JSON unmarshaling to accept both "prompt": "single" and "prompt": ["multi"]
   - Implement custom UnmarshalJSON if needed for flexible string/array parsing
   Tests: Unit tests for JSON parsing with string, array, empty, nil; validation logic
   Done when: Agent struct accepts prompt field as string or string array

** [#B] Update agent loader to resolve prompt names to paths
   Why: Prompts are stored as names but need to be validated/resolved to file paths
   Change:
   - Add PromptsDir parameter to Loader.Load() (default: "config/prompts")
   - After loading each agent JSON, validate that all prompt names exist as .txt files
   - Keep names in Agent struct; resolve paths during injection (more flexible)
   - Use structured logger to log warning if prompt file doesn't exist
   - Don't fail agent load on missing prompt (graceful degradation)
   - Update loader tests to check prompt file existence validation
   Tests: Unit tests with missing prompt files; verify warnings logged
   Done when: Loader validates prompt names against config/prompts/*.txt

** [#B] Implement sequential prompt injection in session startup
   Why: Multiple prompts need to be injected in order with proper timing
   Change:
   - Locate current prompt injection code (likely in terminal/session.go or manager.go)
   - Replace single prompt file read with loop over agent.Prompts
   - For each prompt name: resolve to config/prompts/{name}.txt, read contents, inject
   - Add configurable delay between prompts (default 100ms) to allow shell processing
   - Use structured logger for warnings if file missing/unreadable, continue with next prompt
   - Consider: inject after shell is ready (existing delay before first prompt)
   - Ensure newlines are properly handled (add \n at end if missing)
   Tests: Manual test with agent using multiple prompts; verify execution order
   Done when: Agent terminals execute all prompts in sequence on startup

** [#C] Update example agent configs to use new format
   Why: Demonstrate new prompt field format and provide working examples
   Change:
   - Update config/agents/*.json to use "prompt" field instead of "prompt_file"
   - Create example with single prompt: "prompt": "coder"
   - Create example with multiple prompts: "prompt": ["coder", "architect"]
   - Keep one example without prompts to show optional nature
   Tests: Load examples; verify they parse and execute correctly
   Done when: Example configs demonstrate new prompt field usage

** [#C] Update documentation for prompt configuration
   Why: Users need to understand new prompt field format and behavior
   Change:
   - Update README.md Agent Profiles section with prompt field documentation
   - Document both formats: "prompt": "single" and "prompt": ["multi"]
   - Document prompt resolution: names → config/prompts/{name}.txt
   - Document injection timing and sequential behavior
   Tests: None (documentation only)
   Done when: README clearly explains prompt field usage

** [#C] Delay initial prompt injection by 1s
   Why: Give shells time to initialize before prompt injection
   Change: Increase the initial prompt delay to 1s before the first prompt
   Tests: Go tests covering prompt injection timing
   Done when: First prompt waits ~1s before injection

** [#C] Inject trailing enter after prompts
   Why: Ensure shell executes prompts cleanly after all injections
   Change: Write a final newline after all prompts are injected
   Tests: Go tests for prompt injection order with trailing enter
   Done when: Prompt injection sends a trailing enter after the last prompt

** [#C] Ensure prompt injection sends terminal enter key
   Why: Some shells/CLI tools may require carriage return to submit input
   Change: Normalize prompt line endings and final enter to use terminal enter semantics
   Tests: Go tests verifying injected input uses the correct enter sequence
   Done when: Injected prompts are accepted by the LLM CLI

** [#C] Increase initial prompt delay to 3s
   Why: Some agents need more startup time before accepting prompt injection
   Change: Increase initial prompt delay from 1s to 3s
   Tests: Go tests covering prompt injection timing
   Done when: First prompt waits ~3s before injection

** [#B] Align injected enter with actual terminal input
   Why: Prompt text appears but is not submitted without manual Enter
   Change: Match injected enter sequence to what the web terminal sends (CR vs CRLF) and adjust prompt normalization
   Tests: Go tests to verify injected bytes match expected enter sequence
   Done when: Prompts submit without manual Enter across agents

** [#C] Delay final enter after prompt injection
   Why: Prompt text appears but enter may be arriving before the CLI is ready
   Change: Add a ~500ms delay before sending the final enter after all prompts
   Tests: Go tests covering prompt injection timing
   Done when: Prompts submit without manual Enter

** [#B] Pace prompt injection to mimic keystrokes
   Why: Prompt text appears but is not submitted; fast bulk writes may be treated differently
   Change: Write prompt content in small chunks with brief delays, then send a delayed enter
   Tests: Go tests for prompt injection ordering and final enter timing
   Done when: Prompts submit without manual Enter across agents

** [#B] Use raw prompt content with typed enter sequence
   Why: Copilot CLI may not accept normalized line endings
   Change: Stop normalizing prompt content; send raw bytes then a simulated enter sequence
   Tests: Go tests verifying raw prompt payload and enter write
   Done when: Copilot accepts injected prompts without manual Enter

** [#A] Gate prompt injection on onair_string output
   Why: Ensure prompts are only injected after the CLI is ready
   Change: Add per-agent onair_string configuration; wait for terminal output to contain it before injecting
   Tests: Go tests simulating output detection and deferred injection
   Done when: Prompt injection waits for onair_string before sending prompts

* DONE [#A] System logging and notification infrastructure
  Goal: Add comprehensive logging system with UI visibility through both toast notifications and dedicated logs tab.
  Notes:
  - Backend warnings (missing prompt files, agent load errors, etc.) must be visible in UI
  - Two-layer approach: ephemeral toasts for immediate feedback + persistent logs tab
  - Backend maintains circular log buffer accessible via REST API
  - Frontend uses Svelte store for notifications with auto-dismiss
  - Toast notifications: auto-dismiss after 3-5s (configurable), support info/warning/error levels
  - Logs tab: persistent view showing all system logs with filtering by level/time
  - WebSocket optional for real-time log streaming (can start with polling)
  - Log levels: DEBUG, INFO, WARNING, ERROR (standard severity)
  Date: 2025-12-29

** [#B] Create backend log buffer and structured logging
   Why: Need centralized log collection that both stdout and API can access
   Change:
   - Create internal/logging package with LogBuffer (circular buffer, thread-safe)
   - LogEntry struct: Timestamp, Level (debug/info/warning/error), Message, Context (map)
   - Default buffer size: 1000 entries (configurable)
   - Create Logger wrapper that writes to both stdout and LogBuffer
   - Replace log.Printf calls with structured logger throughout codebase
   - Logger methods: Debug(), Info(), Warn(), Error()
   - Include contextual fields (e.g., agent_id, terminal_id where relevant)
   Tests: Unit tests for LogBuffer thread-safety, circular behavior, entry limits
   Done when: All backend logging goes through structured logger with buffer

** [#B] Add REST endpoint for log retrieval
   Why: Frontend needs to fetch logs for display in logs tab
   Change:
   - Add GET /api/logs endpoint with query parameters: since (timestamp), level (filter), limit
   - Return JSON array of log entries with timestamp, level, message, context
   - Support pagination: last N entries or entries since timestamp
   - Default: return last 100 entries
   - Add filtering by log level (e.g., ?level=warning returns warning+error only)
   - Consider: HEAD request for log count or latest timestamp (polling optimization)
   Tests: REST endpoint tests with various query parameters
   Done when: Frontend can fetch filtered log history via REST

** [#C] Add WebSocket endpoint for real-time log streaming (optional)
   Why: Real-time log updates provide better UX than polling
   Change:
   - Add GET /ws/logs WebSocket endpoint for log streaming
   - Send log entries as JSON messages when they occur
   - Support client-side level filtering (client sends filter on connect)
   - Reuse existing WebSocket auth pattern (token in query param)
   - Handle subscriber cleanup on disconnect
   - Optional: implement later if REST polling is sufficient initially
   Tests: WebSocket connection test, message delivery test
   Done when: Logs stream to connected WebSocket clients in real-time

** [#B] Create frontend notification store
   Why: Centralized notification state management for toast display
   Change:
   - Create src/lib/notificationStore.js with Svelte writable store
   - Notification object: id, level, message, timestamp, autoClose, duration
   - Methods: addNotification(level, message, opts), dismiss(id), clear()
   - Auto-dismiss logic: setTimeout for toasts, optional permanent notifications
   - Default duration: 5000ms for info, 7000ms for warning, manual for error
   - Unique ID generation (timestamp + counter)
   - Export subscribe() for reactive updates
   Tests: Store tests for add/dismiss/auto-dismiss behavior
   Done when: Notification store manages toast lifecycle

** [#B] Create toast notification component
   Why: Visual display of ephemeral notifications
   Change:
   - Create src/components/Toast.svelte for individual toast
   - Create src/components/ToastContainer.svelte for positioning/stacking
   - Position: top-right or bottom-right corner (configurable)
   - Stack vertically with smooth enter/exit animations (slide + fade)
   - Visual styling: color-coded by level (info=blue, warning=yellow, error=red)
   - Include dismiss button (X) and auto-close progress indicator
   - Support click-to-dismiss
   - Accessibility: ARIA live region for screen readers
   Tests: Manual visual testing; verify animations and auto-dismiss
   Done when: Toasts display and auto-dismiss correctly

** [#B] Create logs tab view
   Why: Persistent access to system logs with filtering and search
   Change:
   - Create src/views/LogsView.svelte as dedicated tab
   - Add "Logs" tab to TabBar (between Dashboard and terminal tabs)
   - Display log entries in scrollable list/table: timestamp, level badge, message
   - Add level filter dropdown (All, Info, Warning, Error)
   - Add auto-refresh toggle (poll every 5s) and manual refresh button
   - Show entry count and latest update time
   - Expand log entry on click to show full context/details
   - Reverse chronological order (newest first)
   - Consider: virtualized scrolling for large log lists
   Tests: Manual testing with various log volumes and filters
   Done when: Logs tab displays backend logs with filtering

** [#B] Wire notifications into existing code paths
   Why: Emit notifications for key user-facing events
   Change:
   - Backend: emit warning logs for missing prompt files, agent load failures
   - Backend: emit info logs for terminal create/destroy, agent startup
   - Frontend: subscribe to notifications in App.svelte
   - Frontend: show toast on terminal connection errors, auth failures
   - Frontend: show toast on API errors (replace inline error text where appropriate)
   - Frontend: poll /api/logs on logs tab mount, display in LogsView
   - Optional: WebSocket log streaming if implemented
   Tests: Trigger various scenarios; verify toasts and logs appear
   Done when: Users see notifications for all important system events

** [#C] Add notification preferences (optional enhancement)
   Why: Users may want to customize notification behavior
   Change:
   - Add settings panel (modal or dedicated view) for notification prefs
   - Toggles: enable/disable toasts, auto-dismiss duration, log level filter
   - Store preferences in localStorage
   - Apply prefs to notification store configuration
   - Default: all notifications enabled
   Tests: Manual testing of preference persistence and application
   Done when: Users can customize notification behavior (optional)

** [#C] Update documentation for logging system
   Why: Developers and users need to understand logging capabilities
   Change:
   - Add "Logging and Notifications" section to README.md
   - Document log levels and when each is used
   - Document /api/logs endpoint and query parameters
   - Document toast notification behavior and auto-dismiss
   - Add screenshot or description of logs tab
   - Document how to add logs in backend code (logger usage)
   Tests: None (documentation only)
   Done when: Logging system is documented in README

* DONE [#B] Agent profiles system
  Goal: Allow customizable terminal configurations for AI agents stored as JSON files in config/agents/.
  Notes:
  - Each agent profile defines: shell/program, initial prompt file, terminal name, LLM type, LLM model
  - Agent profiles live in config/agents/ as JSON files (one per agent)
  - LLM types: copilot, codex, promptline (hardcoded for now)
  - LLM model: "default" for now (future: configurable)
  - Agent selection: via REST API (POST /api/terminals with "agent" parameter)
  - Default behavior: if no agent specified, use current shell-based creation
  - Initial prompt: if specified, write to terminal stdin after spawn
  - UI: one button per agent file, labeled with agent's name attribute
  Date: 2025-12-29

** [#B] Create agent data structure and JSON schema
   Why: Define the agent profile format before loading/using agents
   Change:
   - Create internal/agent/ package with Agent struct
   - Fields: Name (string), Shell (string), PromptFile (string), LLMType (string), LLMModel (string)
   - Add JSON tags for serialization: name, shell, prompt_file, llm_type, llm_model
   - Document schema with example JSON in agent/doc.go
   - Add validation: LLMType must be one of [copilot, codex, promptline]
   - Add validation: required fields (Name, Shell), optional (PromptFile)
   Tests: Unit test JSON marshaling/unmarshaling; validate edge cases
   Done when: Agent struct exists with JSON support and validation

** [#B] Implement agent loader from config/agents/
   Why: Load agent profiles from filesystem at startup
   Change:
   - Create agent.Loader with Load(dir string) (map[string]Agent, error)
   - Scan config/agents/*.json files
   - Parse each JSON file into Agent struct
   - Use filename (without .json) as agent ID
   - Return map[agentID]Agent for easy lookup
   - Handle errors: invalid JSON, validation failures, missing directory
   - If directory doesn't exist, return empty map (not an error)
   Tests: Unit tests with temp directories; valid/invalid JSON files
   Done when: Loader successfully reads agent profiles from directory

** [#B] Wire agent loader into Manager initialization
   Why: Manager needs access to agent profiles for terminal creation
   Change:
   - Add Agents field to ManagerOptions: map[string]agent.Agent
   - Load agents in cmd/gestalt/main.go before creating Manager
   - Pass agents to Manager via ManagerOptions
   - Store agents in Manager struct for lookup during Create
   - Add method Manager.GetAgent(id string) (Agent, bool)
   Tests: Integration test verifying Manager has agents after init
   Done when: Manager has access to loaded agent profiles

** [#B] Extend terminal creation API to accept agent
   Why: Frontend needs to specify which agent to use
   Change:
   - Extend createTerminalRequest to include Agent (optional string)
   - Modify Manager.Create signature: Create(agentID, role, title string) (*Session, error)
   - If agentID empty: use default behavior (current shell, no prompt, title/role as-is)
   - If agentID specified: lookup agent, use agent.Shell, override title with agent.Name
   - Pass agent to Session creation (extend newSession parameters)
   - Store agent reference in Session struct for later use
   Tests: REST API test with/without agent; verify correct shell launched
   Done when: POST /api/terminals accepts "agent" field

** [#C] Implement initial prompt injection
   Why: Agent profiles can specify a prompt file to execute on terminal start
   Change:
   - If agent.PromptFile is not empty, read file contents
   - After PTY starts, write prompt contents to session.input channel
   - Add newline at end if not present
   - Handle errors: file not found, read errors (log warning, continue)
   - Consider delay (50-100ms) after shell spawn before writing prompt
   Tests: Manual test with agent containing prompt file; verify execution
   Done when: Terminal executes prompt commands on startup

** [#C] Store LLM metadata in Session
   Why: Future features (orchestration, AI coordination) need to know terminal's LLM type/model
   Change:
   - Add LLMType and LLMModel fields to Session struct
   - Populate from agent profile during creation
   - Expose in SessionInfo for API responses
   - Extend terminalSummary JSON response to include llm_type and llm_model
   Tests: GET /api/terminals includes LLM metadata
   Done when: Session stores and exposes LLM configuration

** [#C] Add example agent profiles to config/agents/
   Why: Provide working examples for users
   Change:
   - Create config/agents/ directory
   - Add example agent profiles: copilot.json, codex.json, promptline.json
   - Each example uses /bin/bash (or appropriate shell)
   - Document agent profile format in main README.md
   Tests: Load examples; verify they parse correctly
   Done when: Example agent profiles exist and are documented

** [#C] Add GET /api/agents endpoint
   Why: Frontend needs to fetch available agent profiles
   Change:
   - Add GET /api/agents REST endpoint
   - Return array of agent metadata: id, name, llm_type, llm_model
   - Use Manager.Agents map to build response
   - Add unit tests for endpoint
   Tests: GET /api/agents returns agent list
   Done when: API endpoint exposes available agents

** [#C] Update frontend with agent buttons
   Why: Users need UI to spawn terminals with specific agents
   Change:
   - Fetch agents via GET /api/agents in Dashboard.svelte on mount
   - Render one button per agent using agent.name as button label
   - On button click: POST /api/terminals with {"agent": agentID}
   - Open new terminal tab after creation
   - Update terminal tab label to show agent.Name if used
   Tests: Manual test agent buttons in UI; verify correct terminal created
   Done when: Dashboard shows agent buttons; clicking spawns agent terminal

** [#B] Fix terminal tab close freeze and ensure deletion
   Why: Closing a tab freezes the UI and leaves a disconnected session
   Change:
   - Reproduce the close flow in App.svelte/TabBar.svelte
   - Ensure tab close triggers DELETE and removes the tab from UI
   - Fix any stale TerminalView/terminalStore references on close
   - Validate WebSocket shutdown cleanup on close
   Tests: npm run build; go test ./...
   Done when: Closing a tab removes it and the server session cleanly

* DONE [#B] Code quality: maintainability, clarity, and minimalism review
  Goal: Improve code maintainability, modularity, clarity, and minimize dependencies where practical.
  Notes:
  - Focus on making code easier to understand, modify, and extend without breaking things
  - Remove unnecessary complexity and improve separation of concerns
  - Better error handling and resource cleanup patterns
  - Evaluate if dependencies can be reduced (prefer stdlib when sufficient)
  - Document key architectural decisions inline
  - All changes must preserve existing functionality (zero regressions)
  Date: 2025-12-29

** [#C] Backend: improve error handling and resource cleanup
   Why: Several functions ignore errors; goroutine cleanup paths unclear; better patterns improve robustness
   Change:
   - session.Write currently drops errors silently; add error return or log
   - Review session close: ensure all 3 goroutines terminate cleanly on Close()
   - Add context-based cancellation for clean shutdown
   - Audit all defer statements for proper error handling
   - Add error wrapping with context where helpful
   Tests: go test ./...; verify no test regressions
   Done when: Error paths properly handled; goroutine lifecycle is clear and leak-free

** [#C] Backend: evaluate gorilla/websocket dependency
   Why: Minimalism goal; check if golang.org/x/net/websocket or stdlib alternatives sufficient
   Change:
   - Research: does gorilla provide critical features we need? (check origin, control frames, etc)
   - If x/net/websocket is sufficient, migrate to reduce dependencies
   - If gorilla is best choice, document why (e.g., better API, production-ready, control frame handling)
   - Decision: keep or replace, but document the reasoning
   Tests: go test ./...; manual WebSocket connection test if migrating
   Done when: Dependency decision documented; migration complete if chosen

** [#C] Backend: improve modularity in manager and session
   Why: Manager and Session mix multiple concerns; better separation aids testing and future changes
   Change:
   - Extract broadcast/subscriber logic into separate Broadcaster type
   - Consider separating Manager's ID generation, session registry, and lifecycle management
   - Make Session goroutine coordination more explicit (use explicit done channels, context)
   - Add state machine to Session (e.g., connecting → ready → closing → closed)
   - Reduce coupling: Session shouldn't need to know about subscribers; Broadcaster should
   Tests: go test ./...; maintain or improve test coverage
   Done when: Each type has single clear responsibility; easier to modify independently

** [#C] Backend: clarify Windows PTY support and build tags
   Why: Windows returns stub error; status unclear to users/contributors
   Change:
   - Add detailed doc comment in pty_windows.go explaining ConPTY implementation status
   - Document options: implement ConPTY, use github.com/UserExistsError/conpty, or stay stub
   - Add build tag documentation explaining Unix vs Windows behavior
   - If keeping stub, improve error message to guide Windows users
   Tests: Build on Windows; verify error message is helpful
   Done when: Windows support status is crystal clear; path forward documented

** [#C] Backend: refactor API handlers for clarity
   Why: REST handlers mix parsing, validation, auth, business logic; hard to test and modify
   Change:
   - Extract middleware: authMiddleware, loggingMiddleware, jsonErrorMiddleware
   - Create path parsing helpers with unit tests (parseTerminalPath is buried in handler)
   - Centralize validation (e.g., validateTerminalID, validateCreateRequest)
   - Standardize JSON error responses (consistent structure)
   - Consider thin handler layer that delegates to service methods
   Tests: Add unit tests for parsing and validation; go test ./...
   Done when: Handlers are <20 lines; logic is tested; auth/validation centralized

** [#C] Frontend: fix terminal lifecycle to preserve state on tab switch
   Why: Terminal.svelte recreates xterm on every mount; destroys on unmount; loses state
   Change:
   - Move terminal instance ownership to parent or store (don't create in component)
   - Terminal.svelte becomes presentation-only: receives term instance, renders it
   - Preserve WebSocket connections across tab switches or implement reconnection
   - Use CSS display:none for hidden terminals instead of destroying components
   Tests: npm run build; manual tab switching; verify terminal state preserved
   Done when: Switching tabs keeps terminal scrollback and state intact

** [#C] Frontend: remove unused dependencies
   Why: Minimalism; addon-attach is installed but not imported anywhere
   Change:
   - Remove @xterm/addon-attach from package.json (unused)
   - Evaluate @xterm/addon-fit: it's ~10 lines of math; could inline if desired
   - If keeping addon-fit, document why (convenience, maintenance, tested)
   - Check for other unused dependencies
   Tests: npm run build; manual resize test
   Done when: Only necessary deps remain; decision documented if keeping addon-fit

** [#C] Frontend: improve WebSocket error handling
   Why: Connection failures show generic "disconnected"; no retry logic; poor UX
   Change:
   - Add exponential backoff reconnection for WebSocket failures
   - Show user-friendly messages: "Connecting...", "Connection lost, retrying...", "Connected"
   - Handle auth failures (401) differently from network errors
   - Add manual reconnect button after repeated failures
   - Log errors to console for debugging
   Tests: npm run build; manual test with network interruption
   Done when: Users get clear feedback; auto-reconnect works for transient failures

** [#C] Documentation: add architectural inline comments
   Why: Code lacks context on design decisions; onboarding is harder than needed
   Change:
   - Add package doc comments to internal/terminal, internal/api, internal/orchestrator
   - Document goroutine coordination pattern in session.go (who owns what, shutdown order)
   - Explain WebSocket control message protocol in terminal_handler.go
   - Document thread-safety guarantees in Manager (what locks protect what)
   - Add comment explaining why we use fan-out pattern for subscribers
   Tests: None (documentation only)
   Done when: Key patterns and decisions are documented; code is self-explanatory

** [#C] Testing: improve coverage and testability
   Why: Some code paths untested; mocking is hard; no integration tests
   Change:
   - Add tests for parseTerminalPath, validateToken, path parsing edge cases
   - Make Manager testable: inject clock interface for testing timeouts/timestamps
   - Add table-driven tests for shell selection logic
   - Create integration test: spawn terminal, connect WebSocket, send/receive data
   - Document testing approach in README or TESTING.md
   Tests: go test ./...; verify coverage increases
   Done when: Critical paths tested; testing strategy documented

* DONE [#A] Initial project structure with multi-terminal dashboard
  Goal: Set up Gestalt IDE foundation with Go backend, Svelte frontend, and WebSocket-based terminal management system that supports inter-terminal communication.

  Notes:
  - Terminals are not just user-interactive but can read/write to each other
  - AI agents (like Copilot) should be able to monitor and inject commands into terminals
  - Dashboard shows splash page with status + terminal tabs
  - Architecture must be modular from the start to support terminal orchestration
  - Use github.com/creack/pty for PTY management
  - Use gorilla/websocket for WebSocket handling
  - Keep dependencies minimal
  - Decisions confirmed: repo layout = cmd/gestalt + internal, terminal IDs = short incremental, auth = origin checks + token
  - Decisions confirmed: Windows PTY = ConPTY only (no fallback), auth token = Bearer header for REST and WS, Windows shell = system default unless overridden
  - Decisions pending/implicit: shell selection policy on Unix (use $SHELL vs fallback), WebSocket control framing (text JSON for control + binary for data), bell handling (client-side on xterm onBell)
  - Frontend choice: use Vite + Svelte (not SvelteKit) for a lighter integration with Go server

** Set up Go backend structure and dependencies
   Why: Need the server foundation before implementing terminal logic
   Change:
   - Initialize go.mod with module name
   - Decide repo layout (e.g., cmd/gestalt/main.go + internal/{api,terminal,orchestrator})
   - Create main.go with basic HTTP server and config (port, shell command, auth token)
   - Add OS-aware shell default (use $SHELL on Unix; configurable fallback on Windows)
   - Add gorilla/websocket and creack/pty dependencies
   - Create modular package structure:
     - terminal/ - PTY and terminal session management
     - api/ - HTTP/WebSocket handlers
     - orchestrator/ - Inter-terminal communication logic (stub for now)
   Tests: Server starts and responds on port 8080
   Done when: Go project compiles, dependencies resolved, basic server runs

** Implement terminal session manager with inter-terminal awareness
   Why: Core abstraction for managing multiple terminal instances and their communication
   Change:
   - Create terminal/session.go with Terminal session struct
   - Each terminal has: ID, PTY, input/output channels, metadata (including role/purpose)
   - Create terminal/manager.go to track all active sessions
   - Manager provides: Create, Get, List, Delete operations
   - Add hooks for inter-terminal communication (Reader/Writer interfaces or fan-out)
   - Support terminal output broadcast to multiple listeners
   - Define lifecycle rules (close cleanup, optional idle timeout)
   - Decide output buffer size/format for later API (lines vs bytes)
   - Implement incremental ID generator (atomic counter) with string rendering
   Tests: Can create multiple terminal sessions, list them, retrieve by ID
   Done when: Manager can spawn/track terminals with communication hooks

** Implement WebSocket terminal bridge
   Why: Connect browser frontend to backend PTY sessions
   Change:
   - Create api/terminal_handler.go for WebSocket upgrade
   - Implement bidirectional bridge: WebSocket ↔ PTY (binary data frames)
   - Define control message framing for resize (text JSON messages, e.g. {"type":"resize","cols":...,"rows":...})
   - Handle terminal resize events (apply to PTY; SIGWINCH optional)
   - Support multiplexing: one WebSocket can subscribe to terminal output (fan-out)
   - Add basic origin checks (and optional token auth if required)
   - Add endpoints: /ws/terminal/:id for connecting to specific terminal
   Tests: Can connect via WebSocket, send input, receive output
   Done when: WebSocket bidirectionally bridges to PTY with resize support

** Create REST API for terminal management
   Why: Dashboard needs to query status and create/delete terminals
   Change:
   - Create api/routes.go with REST endpoints
   - GET /api/terminals - list all terminals with metadata
   - POST /api/terminals - create new terminal session
   - DELETE /api/terminals/:id - terminate terminal
   - GET /api/status - system status (terminal count, etc)
   - Define response schema (id, title, role, created_at, status)
   - Require token for REST endpoints (Authorization header or query param)
   Tests: Can create/list/delete terminals via REST API
   Done when: All CRUD operations work via HTTP

** Initialize Svelte frontend structure
   Why: Need frontend framework before building UI components
   Change:
   - Use Vite + Svelte (not SvelteKit) for minimal integration with Go server
   - Run `npm create vite@latest frontend -- --template svelte`
   - Install xterm.js and addons: xterm, xterm-addon-fit, xterm-addon-attach
   - Configure Vite to proxy API calls to Go backend (port 8080)
   - Create basic app structure with routing (splash, terminal views)
   Tests: Frontend dev server runs, builds successfully
   Done when: Svelte app runs with xterm.js dependencies installed

** Build splash page dashboard component
   Why: Entry point showing system status and terminal management
   Change:
   - Create Dashboard.svelte component
   - Fetch /api/status and /api/terminals on mount
   - Display: terminal count, system info, list of active terminals
   - Add "New Terminal" button (calls POST /api/terminals)
   - Style with minimal CSS (clean, functional)
   Tests: Dashboard loads, shows correct terminal count, button creates terminal
   Done when: Splash page displays status and can create terminals

** Build terminal tab component with xterm.js
   Why: Display interactive terminals in browser
   Change:
   - Create Terminal.svelte component
   - Initialize xterm.js instance with fit addon
   - Connect to WebSocket /ws/terminal/:id (send resize control JSON on fit)
   - Handle terminal resize on window resize
   - Hook xterm onBell for bell interception/notifications
   - Implement terminal cleanup on component destroy
   Tests: Terminal renders, accepts input, displays output correctly
   Done when: Fully interactive terminal works in browser

** Implement tab switching UI
   Why: Users need to switch between multiple terminals
   Change:
   - Create TabBar.svelte component
   - Maintain array of open terminal tabs (IDs + labels)
   - Switch active terminal on tab click
   - Add close button per tab (calls DELETE /api/terminals/:id)
   - Keep splash page as special "tab 0"
   Tests: Can switch between splash and terminal tabs, close tabs
   Done when: Tab navigation works smoothly

** Wire up complete application flow
   Why: Connect all pieces into working application
   Change:
   - Create App.svelte as main component orchestrator
   - Manage global state: active terminals, current tab
   - Route between splash and terminal views
   - Handle terminal creation → open new tab → connect WebSocket
   - Serve frontend build from Go backend in production
   Tests: Full flow works: splash → create terminal → interact → switch tabs → close
   Done when: Complete application runs end-to-end

** Add basic inter-terminal read capability (foundation)

** Preserve terminal screen buffer across tab switches
   Why: Switching away and back currently wipes the terminal display while the session is still running.
   Change: Rework terminal view lifecycle so xterm DOM/state is preserved or restored on tab reselect (avoid dispose on hide or buffer snapshot/restore).
   Tests: Manual verify tab switching retains visible terminal content; existing go tests still pass.
   Done when: Returning to a terminal shows the same screen contents without requiring a reflow or replay.
   Why: Lay groundwork for terminal orchestration features
   Change:
   - Add GET /api/terminals/:id/output endpoint (recent output buffer)
   - Each terminal maintains circular buffer of recent output (~1000 lines)
   - Document API for reading terminal state (for future AI agent integration)
   - Add metadata field for terminal "role" or "purpose" (future use)
   Tests: Can retrieve recent output from terminal via API
   Done when: API endpoint returns buffered terminal output
